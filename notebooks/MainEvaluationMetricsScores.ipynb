{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indoor-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint ../../../bleurt/BLEURT-20/.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: ../../../bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/essel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets  import load_metric\n",
    "from bleurt import score\n",
    "from parent import parent\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../TrainedNarrators/')\n",
    "from data_utils import *\n",
    "\n",
    "scorer = score.LengthBatchingBleurtScorer('../../../bleurt/BLEURT-20/')\n",
    "metric_bert = load_metric('bertscore')\n",
    "metric_sbleu = load_metric('sacrebleu')\n",
    "metric_meteor = load_metric('meteor')\n",
    "#metric_bleurt = load_metric('bleurt', 'bleurt-large-512')\n",
    "metric_rouge = load_metric('rouge')\n",
    "metric_wer = load_metric('google_bleu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quarterly-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open('../dataset/test set.json'))\n",
    "test_sample = []\n",
    "eval_tables = []\n",
    "for pc in test_data:\n",
    "    test_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))\n",
    "    # eval_tables.append(parseTableStructureForEval(pc,identicals))\n",
    "rtest_sample = []\n",
    "reval_tables = []\n",
    "for pc in test_data:\n",
    "    rtest_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))\n",
    "\n",
    "refs = [[t['narration'].lower() for t in test_sample]]\n",
    "orf = [[normalize_text(r) for r in refs[0]]]\n",
    "reff = [normalize_text(s.strip()).split() for s in refs[0]]\n",
    "trefs = [[normalize_text(r)] for r in refs[0]]\n",
    "from sacrebleu.tokenizers import tokenizer_13a\n",
    "def normalize_text(s):\n",
    "    tokenize_fn = lambda x: tokenizer_13a.Tokenizer13a()(x)\n",
    "    return tokenize_fn(s.strip().lower())\n",
    "# Prepare the table for PARENT score\n",
    "def ParentisePreamble(pc):\n",
    "    mets = []\n",
    "    for m,v in zip(pc['metrics'],pc['values']):\n",
    "        stg = [f'{m}',normalize_text(v).split()]\n",
    "        mets.append(stg)\n",
    "    random.shuffle(mets)\n",
    "    class_labels = pc['classes']\n",
    "    classes_string = 'or '.join(class_labels[:-1])+' or '+class_labels[-1]\n",
    "    classes_string_1 = ', '.join(class_labels[:-1])+' and '+class_labels[-1]\n",
    "    mets.append(['labels',normalize_text(classes_string).split()])\n",
    "    mets.append(['classes',normalize_text(classes_string_1).split()])\n",
    "    ds= pc['dataset_attribute'][0]\n",
    "    if ds =='is_balanced':\n",
    "        ds = 'balance'\n",
    "    else:\n",
    "        ds= 'imbalance'\n",
    "    #mets.append(['dist',normalize_text(ds.replace('is_','')).strip().split()])\n",
    "    if len(class_labels)<3:\n",
    "        mets.append(['mode1',normalize_text('binary').split()])\n",
    "        #mets.append(['mode2',normalize_text('two-way').split()])\n",
    "    else:\n",
    "        if len(class_labels)<3:\n",
    "            mets.append(['mode1',normalize_text('multi-class').split()])\n",
    "            #mets.append(['mode2',normalize_text('four-way' if len(class_labels==4) else 'three-way').split()])\n",
    "    return mets\n",
    "# Compute the table representations for PARENT metric\n",
    "typ=table_rep=[ParentisePreamble(pc) for pc in test_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animated-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brown-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeParentScore(data,table_rep):\n",
    "    predic= [normalize_text(s.strip()).split() for s in data]\n",
    "    #print(len(predic))\n",
    "    precision, recall, f_score = parent(\n",
    "    predic,\n",
    "    reff,\n",
    "    table_rep,lambda_weight=.8,\n",
    "    avg_results=True,\n",
    "        smoothing=.00001,\n",
    "    n_jobs=32,\n",
    "    use_tqdm=False)\n",
    "    #print(precision, recall, f_score)\n",
    "    return precision, recall, f_score\n",
    "\n",
    "\n",
    "def computeMeanParentBS(data,table_rep=table_rep,bs=8):\n",
    "    pre,rec,fs= [],[],[]\n",
    "    for tt in data:\n",
    "        #print(len(tt[f'{bs}']))\n",
    "        #print('ttg ',len(table_rep))\n",
    "        precision, recall, f_score = computeParentScore(tt[f'{bs}'],table_rep)\n",
    "        pre.append(precision)\n",
    "        rec.append(recall)\n",
    "        fs.append(f_score)\n",
    "    results = {'precision':roundN(np.mean(pre)*100,2), \n",
    "               'recall': roundN(np.mean(rec)*100,2), 'f1': roundN(np.mean(fs)*100,2)}\n",
    "    return results\n",
    "def computeMeanBLEURT(data,bs=8):\n",
    "    b_res = []\n",
    "    for tt in data:\n",
    "        gen= [t for t in tt[f'{bs}']]\n",
    "        score=np.mean(scorer.score(references=refs[0], candidates=gen))\n",
    "        b_res.append(score)\n",
    "    return np.mean(b_res)\n",
    "def computeBERTBLEU(data,bs=8):\n",
    "    b_res = []\n",
    "    for tt in data:\n",
    "        gen= [t for t in tt[f'{bs}']]\n",
    "        ss= metric_bert.compute(predictions=[gen],references=[refs],lang='en')\n",
    "        score=ss['f1']\n",
    "        b_res.append(score)\n",
    "    return np.mean(b_res)\n",
    "def computeAutoMetrics(data,bs=8):\n",
    "    b_res = []\n",
    "    m_res = []\n",
    "    r_res = []\n",
    "    r2_res = []\n",
    "    r1_res = []\n",
    "    bleurt_score = computeMeanBLEURT(data,bs)\n",
    "    for tt in data:\n",
    "        gen= [normalize_text(t) for t in tt[f'{bs}']]\n",
    "        score=metric_sbleu.compute(predictions=[gen],references=[orf])\n",
    "        b_res.append(score['score'])\n",
    "        \n",
    "        \n",
    "        # Meteor\n",
    "        score_=metric_meteor.compute(predictions=[gen],references=[orf])\n",
    "        m_res.append(score_['meteor'])\n",
    "        \n",
    "        \n",
    "        # ROUGE\n",
    "        score=metric_rouge.compute(predictions=[gen],references=orf,use_stemmer=True)\n",
    "        score= {key: value.high.fmeasure * 100 for key, value in score.items()}\n",
    "        r_res.append(score['rougeL'])\n",
    "        r2_res.append(score['rouge2'])\n",
    "        r1_res.append(score['rouge1'])\n",
    "        #r_res.append(0)\n",
    "        \n",
    "        \n",
    "    return {'BLEURT':bleurt_score,\n",
    "            'BLEU': np.mean(b_res),\n",
    "            'METEOR':np.mean(m_res)*100,\n",
    "            'rouge1': np.mean(r1_res),\n",
    "            'rouge2': np.mean(r2_res),\n",
    "            'rougeL': np.mean(r_res)}\n",
    "    \n",
    "def computeEvaluationScores(data,bs=8):\n",
    "    # Compute the Parent score\n",
    "    parent_scores = computeMeanParentBS(data,bs=bs)\n",
    "    # Compute BLEU and METEOR score\n",
    "    parent_scores.update(computeAutoMetrics(data,bs=bs))  \n",
    "    return parent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opened-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated texts\n",
    "import copy\n",
    "import json\n",
    "#t5_small_43,t5_small_128,t5_small_456,t5_small_3087,t5_small_1984\n",
    "def loadData(main_path,model_base,seeds =[43,128,456,3087,1984]):\n",
    "    #'../TrainedNarrators/P-NarrationsModels/baselineoutputs_new/t5-small/43/narrations_outputoe.json'\n",
    "    outputs = {}\n",
    "    for model in model_base:\n",
    "        p= main_path+f'/{model}/'\n",
    "        elems = []\n",
    "        for s in seeds:\n",
    "            z= p+f'{s}/narrations_outputoe.json'\n",
    "            d= json.load(open(z,'rb'))\n",
    "            elems.append(d)\n",
    "        outputs[model]= elems\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strategic-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_baseline=loadData('../TrainedNarrators/P-NarrationsModels/baselineoutputs_new/',['t5-small','t5-base','t5-large'],)\n",
    "t5_ef=loadData('../TrainedNarrators/P-NarrationsModels/earlyfusionoutputs_new/',['t5-small','t5-base','t5-large'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "numerous-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_ef = loadData('../TrainedNarrators/P-NarrationsModels/earlyfusionoutputs_new/',['bart-base','bart-large'],seeds =[48,128,456,3087,1984])\n",
    "bart_baseline = loadData('../TrainedNarrators/P-NarrationsModels/baselineoutputs_new/',['bart-base','bart-large'],seeds =[48,128,456,3087,1984])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacterial-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllScores(pack,bs=8):\n",
    "    results = {}\n",
    "    for k,v in pack.items():\n",
    "        print(k)\n",
    "        scores = computeEvaluationScores(v,bs=bs)\n",
    "        results[k] = scores\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defined-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-small\n",
      "INFO:tensorflow:Average batch sequence length: 217.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 209.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 210.42857142857142\n",
      "INFO:tensorflow:Average batch sequence length: 216.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 226.57142857142858\n",
      "t5-base\n",
      "INFO:tensorflow:Average batch sequence length: 236.14285714285714\n",
      "INFO:tensorflow:Average batch sequence length: 229.42857142857142\n",
      "INFO:tensorflow:Average batch sequence length: 233.0\n",
      "INFO:tensorflow:Average batch sequence length: 231.14285714285714\n",
      "INFO:tensorflow:Average batch sequence length: 232.57142857142858\n",
      "t5-large\n",
      "INFO:tensorflow:Average batch sequence length: 229.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 236.0\n",
      "INFO:tensorflow:Average batch sequence length: 240.0\n",
      "INFO:tensorflow:Average batch sequence length: 231.85714285714286\n",
      "INFO:tensorflow:Average batch sequence length: 230.71428571428572\n"
     ]
    }
   ],
   "source": [
    "t5_scores=computeAllScores(t5_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "balanced-frontier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 25.18,\n",
       " 'recall': 44.04,\n",
       " 'f1': 30.99,\n",
       " 'BLEURT': 0.5409001551866531,\n",
       " 'BLEU': 46.305576394625874,\n",
       " 'METEOR': 47.451796627600594,\n",
       " 'rougeL': 29.570000876829624}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores['t5-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "speaking-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-small\n",
      "INFO:tensorflow:Average batch sequence length: 220.0\n",
      "INFO:tensorflow:Average batch sequence length: 230.0\n",
      "INFO:tensorflow:Average batch sequence length: 217.0\n",
      "INFO:tensorflow:Average batch sequence length: 223.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 220.57142857142858\n",
      "t5-base\n",
      "INFO:tensorflow:Average batch sequence length: 238.0\n",
      "INFO:tensorflow:Average batch sequence length: 236.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 237.57142857142858\n",
      "INFO:tensorflow:Average batch sequence length: 239.71428571428572\n",
      "INFO:tensorflow:Average batch sequence length: 234.28571428571428\n",
      "t5-large\n",
      "INFO:tensorflow:Average batch sequence length: 234.71428571428572\n",
      "INFO:tensorflow:Average batch sequence length: 229.85714285714286\n",
      "INFO:tensorflow:Average batch sequence length: 232.14285714285714\n",
      "INFO:tensorflow:Average batch sequence length: 235.71428571428572\n",
      "INFO:tensorflow:Average batch sequence length: 232.14285714285714\n"
     ]
    }
   ],
   "source": [
    "t5_scores_ef=computeAllScores(t5_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metallic-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-base\n",
      "INFO:tensorflow:Average batch sequence length: 238.0\n",
      "INFO:tensorflow:Average batch sequence length: 231.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 239.85714285714286\n",
      "INFO:tensorflow:Average batch sequence length: 237.85714285714286\n",
      "INFO:tensorflow:Average batch sequence length: 236.14285714285714\n",
      "bart-large\n",
      "INFO:tensorflow:Average batch sequence length: 235.14285714285714\n",
      "INFO:tensorflow:Average batch sequence length: 219.85714285714286\n",
      "INFO:tensorflow:Average batch sequence length: 225.42857142857142\n",
      "INFO:tensorflow:Average batch sequence length: 238.42857142857142\n",
      "INFO:tensorflow:Average batch sequence length: 236.57142857142858\n"
     ]
    }
   ],
   "source": [
    "bart_baseline_scores=computeAllScores(bart_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepted-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-base\n",
      "INFO:tensorflow:Average batch sequence length: 241.0\n",
      "INFO:tensorflow:Average batch sequence length: 238.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 235.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 251.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 233.42857142857142\n",
      "bart-large\n",
      "INFO:tensorflow:Average batch sequence length: 236.0\n",
      "INFO:tensorflow:Average batch sequence length: 213.28571428571428\n",
      "INFO:tensorflow:Average batch sequence length: 220.14285714285714\n",
      "INFO:tensorflow:Average batch sequence length: 220.42857142857142\n",
      "INFO:tensorflow:Average batch sequence length: 236.28571428571428\n"
     ]
    }
   ],
   "source": [
    "bart_scores_ef=computeAllScores(bart_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vertical-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results ={'bart_ef':bart_scores_ef,\n",
    "                'bart_baseline':bart_baseline_scores,\n",
    "                't5_baseline':t5_scores,\n",
    "                't5_ef':t5_scores_ef}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "honey-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(model_results,open('../TrainedNarrators/model_results.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "choice-geneva",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bart_ef': {'bart-base': {'precision': 26.42,\n",
       "   'recall': 48.83,\n",
       "   'f1': 33.26,\n",
       "   'BLEURT': 0.5526116153597832,\n",
       "   'BLEU': 45.750068498712366,\n",
       "   'METEOR': 47.82269593463433,\n",
       "   'rouge1': 84.52439522091302,\n",
       "   'rouge2': 59.273807072685926,\n",
       "   'rougeL': 30.407036247518057},\n",
       "  'bart-large': {'precision': 27.33,\n",
       "   'recall': 46.64,\n",
       "   'f1': 33.27,\n",
       "   'BLEURT': 0.512464563548565,\n",
       "   'BLEU': 46.97858229159241,\n",
       "   'METEOR': 45.722011540832966,\n",
       "   'rouge1': 85.210673549098,\n",
       "   'rouge2': 58.38670351473212,\n",
       "   'rougeL': 29.56711238083501}},\n",
       " 'bart_baseline': {'bart-base': {'precision': 25.71,\n",
       "   'recall': 49.26,\n",
       "   'f1': 32.79,\n",
       "   'BLEURT': 0.5471098693609238,\n",
       "   'BLEU': 44.82653964203196,\n",
       "   'METEOR': 47.82754921285556,\n",
       "   'rouge1': 84.58404725577829,\n",
       "   'rouge2': 58.19139514803832,\n",
       "   'rougeL': 29.790561778986614},\n",
       "  'bart-large': {'precision': 26.07,\n",
       "   'recall': 46.74,\n",
       "   'f1': 32.29,\n",
       "   'BLEURT': 0.5129066711664201,\n",
       "   'BLEU': 45.671373721083555,\n",
       "   'METEOR': 46.413390102055864,\n",
       "   'rouge1': 85.19602392209282,\n",
       "   'rouge2': 58.89666180640478,\n",
       "   'rougeL': 29.12470723798412}},\n",
       " 't5_baseline': {'t5-small': {'precision': 26.71,\n",
       "   'recall': 43.91,\n",
       "   'f1': 32.12,\n",
       "   'BLEURT': 0.5552313034534454,\n",
       "   'BLEU': 37.83499039382401,\n",
       "   'METEOR': 39.46466698502225,\n",
       "   'rouge1': 75.4956327760751,\n",
       "   'rouge2': 46.2877683219681,\n",
       "   'rougeL': 31.874865817626947},\n",
       "  't5-base': {'precision': 25.18,\n",
       "   'recall': 44.04,\n",
       "   'f1': 30.99,\n",
       "   'BLEURT': 0.5409001551866531,\n",
       "   'BLEU': 46.305576394625874,\n",
       "   'METEOR': 47.451796627600594,\n",
       "   'rouge1': 85.13247902208256,\n",
       "   'rouge2': 60.02580878695297,\n",
       "   'rougeL': 29.570000876829624},\n",
       "  't5-large': {'precision': 24.91,\n",
       "   'recall': 45.34,\n",
       "   'f1': 31.08,\n",
       "   'BLEURT': 0.5452851737737656,\n",
       "   'BLEU': 45.70102176274635,\n",
       "   'METEOR': 47.11421681503355,\n",
       "   'rouge1': 84.29726927765043,\n",
       "   'rouge2': 59.90159613298905,\n",
       "   'rougeL': 29.371620648487294}},\n",
       " 't5_ef': {'t5-small': {'precision': 27.7,\n",
       "   'recall': 47.73,\n",
       "   'f1': 34.04,\n",
       "   'BLEURT': 0.5615042797327041,\n",
       "   'BLEU': 40.57733052202082,\n",
       "   'METEOR': 43.40056952532363,\n",
       "   'rouge1': 78.9823504404105,\n",
       "   'rouge2': 48.345355221414664,\n",
       "   'rougeL': 31.974881006439226},\n",
       "  't5-base': {'precision': 25.12,\n",
       "   'recall': 45.73,\n",
       "   'f1': 31.33,\n",
       "   'BLEURT': 0.5446521639823914,\n",
       "   'BLEU': 45.457930430656,\n",
       "   'METEOR': 47.75205184684225,\n",
       "   'rouge1': 84.57118976500631,\n",
       "   'rouge2': 59.99163340146011,\n",
       "   'rougeL': 29.78163320034269},\n",
       "  't5-large': {'precision': 25.35,\n",
       "   'recall': 45.65,\n",
       "   'f1': 31.58,\n",
       "   'BLEURT': 0.5462669489383698,\n",
       "   'BLEU': 46.0307056496799,\n",
       "   'METEOR': 47.52666464749858,\n",
       "   'rouge1': 84.56409068706321,\n",
       "   'rouge2': 59.817366028408195,\n",
       "   'rougeL': 29.86431069727356}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-collectible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "treated-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 26.71,\n",
       " 'recall': 43.91,\n",
       " 'f1': 32.12,\n",
       " 'BLEURT': 0.5552313034534454,\n",
       " 'BLEU': 37.83499039382401,\n",
       " 'METEOR': 39.46466698502225,\n",
       " 'rouge1': 75.4956327760751,\n",
       " 'rouge2': 46.2877683219681,\n",
       " 'rougeL': 31.874865817626947}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores['t5-small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sixth-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 27.7,\n",
       " 'recall': 47.73,\n",
       " 'f1': 34.04,\n",
       " 'BLEURT': 0.5615042797327041,\n",
       " 'BLEU': 40.57733052202082,\n",
       " 'METEOR': 43.40056952532363,\n",
       " 'rouge1': 78.9823504404105,\n",
       " 'rouge2': 48.345355221414664,\n",
       " 'rougeL': 31.974881006439226}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores_ef['t5-small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "offshore-accuracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 25.18,\n",
       " 'recall': 44.04,\n",
       " 'f1': 30.99,\n",
       " 'BLEURT': 0.5409001551866531,\n",
       " 'BLEU': 46.305576394625874,\n",
       " 'METEOR': 47.451796627600594,\n",
       " 'rouge1': 85.13247902208256,\n",
       " 'rouge2': 60.02580878695297,\n",
       " 'rougeL': 29.570000876829624}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores['t5-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interim-process",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 25.12,\n",
       " 'recall': 45.73,\n",
       " 'f1': 31.33,\n",
       " 'BLEURT': 0.5446521639823914,\n",
       " 'BLEU': 45.457930430656,\n",
       " 'METEOR': 47.75205184684225,\n",
       " 'rouge1': 84.57118976500631,\n",
       " 'rouge2': 59.99163340146011,\n",
       " 'rougeL': 29.78163320034269}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores_ef['t5-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "instant-development",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t5-small': {'precision': 27.7,\n",
       "  'recall': 47.73,\n",
       "  'f1': 34.04,\n",
       "  'BLEURT': 0.5615042797327041,\n",
       "  'BLEU': 40.57733052202082,\n",
       "  'METEOR': 43.40056952532363,\n",
       "  'rougeL': 0.0},\n",
       " 't5-base': {'precision': 25.12,\n",
       "  'recall': 45.73,\n",
       "  'f1': 31.33,\n",
       "  'BLEURT': 0.5446521639823914,\n",
       "  'BLEU': 45.457930430656,\n",
       "  'METEOR': 47.75205184684225,\n",
       "  'rougeL': 0.0},\n",
       " 't5-large': {'precision': 25.35,\n",
       "  'recall': 45.65,\n",
       "  'f1': 31.58,\n",
       "  'BLEURT': 0.5462669489383698,\n",
       "  'BLEU': 46.0307056496799,\n",
       "  'METEOR': 47.52666464749858,\n",
       "  'rougeL': 0.0}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_scores_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dutch-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from rouge_metric import PerlRouge\n",
    "from rouge_metric import PyRouge\n",
    "temp_dir=tempfile.TemporaryDirectory('exg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "stunning-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = PerlRouge(rouge_n_max=4, rouge_l=True, rouge_w=True,\n",
    "    rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4,stemming=True)\n",
    "def get_rouge(gen,ref):\n",
    "    #score=metric_rouge.compute(predictions=[gen],references=ref,use_stemmer=True)\n",
    "    #score= {key: value.high.fmeasure * 100 for key, value in score.items()}\n",
    "    scores = rouge.evaluate(gen, trefs)\n",
    "    return scores['rouge-l']['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "statutory-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs= 8\n",
    "ss=[]\n",
    "for tt in t5_ef['t5-base']:\n",
    "    gen= [normalize_text(t) for t in tt[f'{bs}']]\n",
    "    \n",
    "    #s = get_rouge(gen,orf)\n",
    "    scores = get_rouge(gen,trefs)\n",
    "    ss.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "thorough-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.279396"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "criminal-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = rouge.evaluate([normalize_text(t) for t in tt['8']], trefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "curious-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge.evaluate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "victorian-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.30862,\n",
       " 'r_conf_int': (0.29218, 0.32722),\n",
       " 'p': 0.30341,\n",
       " 'p_conf_int': (0.28492, 0.32224),\n",
       " 'f': 0.30118,\n",
       " 'f_conf_int': (0.2858, 0.31747)}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "european-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen1.1.txt  gen.1.txt  gen1.txt  gen.txt  ref.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls /tmp/tmplbmiomzmexg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "colored-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = os.path.join(temp_dir.name, 'gen1.1')\n",
    "gg_dir = os.path.join(temp_dir.name, 'gen1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "patient-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "writeToFile(refs[0],ref_dir)\n",
    "writeToFile(tt['8'],gg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aggregate-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "A ROUGE-1 Average_R: 0.72665 (95%-conf.int. 0.72665 - 0.72665)\n",
      "A ROUGE-1 Average_P: 0.71410 (95%-conf.int. 0.71410 - 0.71410)\n",
      "A ROUGE-1 Average_F: 0.72032 (95%-conf.int. 0.72032 - 0.72032)\n",
      "---------------------------------------------\n",
      "A ROUGE-2 Average_R: 0.42936 (95%-conf.int. 0.42936 - 0.42936)\n",
      "A ROUGE-2 Average_P: 0.42194 (95%-conf.int. 0.42194 - 0.42194)\n",
      "A ROUGE-2 Average_F: 0.42562 (95%-conf.int. 0.42562 - 0.42562)\n",
      "---------------------------------------------\n",
      "A ROUGE-L Average_R: 0.70790 (95%-conf.int. 0.70790 - 0.70790)\n",
      "A ROUGE-L Average_P: 0.69567 (95%-conf.int. 0.69567 - 0.69567)\n",
      "A ROUGE-L Average_F: 0.70173 (95%-conf.int. 0.70173 - 0.70173)\n",
      "---------------------------------------------\n",
      "A ROUGE-W-1.2 Average_R: 0.10584 (95%-conf.int. 0.10584 - 0.10584)\n",
      "A ROUGE-W-1.2 Average_P: 0.24866 (95%-conf.int. 0.24866 - 0.24866)\n",
      "A ROUGE-W-1.2 Average_F: 0.14848 (95%-conf.int. 0.14848 - 0.14848)\n",
      "---------------------------------------------\n",
      "A ROUGE-S4 Average_R: 0.40430 (95%-conf.int. 0.40430 - 0.40430)\n",
      "A ROUGE-S4 Average_P: 0.39732 (95%-conf.int. 0.39732 - 0.39732)\n",
      "A ROUGE-S4 Average_F: 0.40078 (95%-conf.int. 0.40078 - 0.40078)\n",
      "---------------------------------------------\n",
      "A ROUGE-SU4 Average_R: 0.45803 (95%-conf.int. 0.45803 - 0.45803)\n",
      "A ROUGE-SU4 Average_P: 0.45012 (95%-conf.int. 0.45012 - 0.45012)\n",
      "A ROUGE-SU4 Average_F: 0.45404 (95%-conf.int. 0.45404 - 0.45404)\n"
     ]
    }
   ],
   "source": [
    "!rouge-metric /tmp/tmplbmiomzmexg/gen1.txt /tmp/tmplbmiomzmexg/gen1.1.txt -n 2 -w 1.2 -U -2 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "nutritional-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "trefs = [[normalize_text(r).split()] for r in refs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "approximate-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
    "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\n",
    "scores = rouge.evaluate_tokenized([normalize_text(t).split() for t in tt['8']], trefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cardiac-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.9173914047876188, 'p': 0.766393450167745, 'f': 0.8351218527714526}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "skilled-instruction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.2977,\n",
       " 'r_conf_int': (0.28131, 0.31582),\n",
       " 'p': 0.29235,\n",
       " 'p_conf_int': (0.27406, 0.3108),\n",
       " 'f': 0.29032,\n",
       " 'f_conf_int': (0.27503, 0.30652)}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "athletic-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference not found for /tmp/tmpyw_2wl4p/hyp/gen.txt\r\n"
     ]
    }
   ],
   "source": [
    "!rouge-metric /tmp/tmplbmiomzmexg/gen.txt /tmp/tmplbmiomzmexg/ref.txt -n 2 -w 1.2 -U -2 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "severe-queens",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['perl', '/home/essel/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/RELEASE-1.5.5/ROUGE-1.5.5.pl', '-a', '-c', '95', '-e', '/home/essel/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/RELEASE-1.5.5/data', '-n', '3', '-r', '1000', '-2', '4', '-U', '-w', '1.2', '-f', 'A', '-p', '0.5', './.rouge_metric/tmpkn78rv4e/config.xml']' returned non-zero exit status 255.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0ab21499084b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{bs}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#s = get_rouge(gen,orf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/perl_rouge.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, hypotheses, multi_references)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mref_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ref'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_references\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_up\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/perl_rouge.py\u001b[0m in \u001b[0;36mevaluate_from_files\u001b[0;34m(self, hypothesis_dir, reference_dir)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         )\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_up\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annotation/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    416\u001b[0m                **kwargs).stdout\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/annotation/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['perl', '/home/essel/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/RELEASE-1.5.5/ROUGE-1.5.5.pl', '-a', '-c', '95', '-e', '/home/essel/anaconda3/envs/annotation/lib/python3.8/site-packages/rouge_metric/RELEASE-1.5.5/data', '-n', '3', '-r', '1000', '-2', '4', '-U', '-w', '1.2', '-f', 'A', '-p', '0.5', './.rouge_metric/tmpkn78rv4e/config.xml']' returned non-zero exit status 255."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "light-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop finished\n",
      "function finished for 0\n",
      "function finished for 1\n",
      "function finished for 4\n",
      "function finished for 7\n",
      "function finished for 6\n",
      "function finished for 5\n",
      "function finished for 9\n",
      "function finished for 8\n",
      "function finished for 2\n",
      "function finished for 3\n"
     ]
    }
   ],
   "source": [
    "@background\n",
    "def your_function(argument):\n",
    "    time.sleep(5)\n",
    "    print('function finished for '+str(argument))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    your_function(i)\n",
    "\n",
    "\n",
    "print('loop finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-progressive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('annotation': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd04aea246828f75a58a93204fce55d322b87a38415c2742fb8a88040418150f4d4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
