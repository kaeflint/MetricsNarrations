{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import sys\n",
    "\n",
    "sys.path.append('../TrainedNarrators/')\n",
    "from data_utils import *\n",
    "from model_utils import setupTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "large-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe('sentencizer')\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acute-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_count= lambda x: len(sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subjective-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import wordpunct_tokenize,word_tokenize\n",
    "# Read the dataset\n",
    "test_data = json.load(open('../dataset/test set.json'))\n",
    "full_data= json.load(open('../dataset/annotation_data_with_augmentations.json'))['data']+test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adult-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open('../dataset/test set.json'))\n",
    "test_sample = []\n",
    "eval_tables = []\n",
    "for pc in test_data:\n",
    "    test_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))\n",
    "    # eval_tables.append(parseTableStructureForEval(pc,identicals))\n",
    "rtest_sample = []\n",
    "reval_tables = []\n",
    "for pc in test_data:\n",
    "    rtest_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "standing-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get task names\n",
    "task_names = [d[\"task_name\"] for d in full_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sunrise-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of unique words\n",
    "mask_met=False\n",
    "processed=[]\n",
    "preambles = []\n",
    "metrics ={1:[],2:[],3:[],4:[],}\n",
    "# apply the preprocessing to the data\n",
    "for idx,pc in enumerate(full_data):\n",
    "    #print(idx)\n",
    "    examples = processInputTableAndNarrations(pc, identical_metrics=identicals, augnment_metrics=False,)\n",
    "    preambles.append(examples['preamble'])\n",
    "    processed.append(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "critical-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-throat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indie-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ML tasks 58\n"
     ]
    }
   ],
   "source": [
    "# Number of anotations per task\n",
    "task_dist = Counter(task_names)\n",
    "print(f'The number of ML tasks {len(task_dist)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nearby-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pk.load(open('../dataset/train_dataset_new.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naval-patio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4529"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elementary-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of annotations submitted: 14\n"
     ]
    }
   ],
   "source": [
    "# Average number of narrations per task\n",
    "mean_annotations = np.average([v for b,v in dict(task_dist).items()])\n",
    "print(f'The average number of annotations submitted: {int(mean_annotations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "productive-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrations = ' '.join([pc['narration'].lower() for pc in processed]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unauthorized-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter(narrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "worthy-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words is: 3548\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of unique words is: {len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "local-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average number of sentences per annotation \n",
    "narr_count = [sent_count(pc['narration']) for pc in processed+test_sample]\n",
    "nn= [idx for idx, pc in enumerate(processed) if sent_count(pc['narration']) ==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "pharmaceutical-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6487362281270252"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(narr_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "formed-holmes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1844, 4: 1403, 5: 446, 6: 194, 2: 579, 7: 110, 8: 53}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter(narr_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-glasgow",
   "metadata": {},
   "source": [
    "### Most of the narrations have about 3 sentences summarizing the performance of the corresponding classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "demanding-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f037e37ac10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(narr_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "major-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMetricsDataChecks(metric_scores, metric_rates, augment=False, identicals={}, nb_metrics=6):\n",
    "    pp = pd.read_json(json.loads(metric_scores))\n",
    "    metric_rates = json.loads(metric_rates)\n",
    "    if augment:\n",
    "        temp_cols = pp.columns.to_list()\n",
    "        random.shuffle(temp_cols)\n",
    "        pp = pp[temp_cols]\n",
    "    metrics = [s.strip() for s in pp.columns.to_list()]\n",
    "    metric_rates = {s.strip(): v for s, v in metric_rates.items()}\n",
    "    values = pp.values.tolist()[0]\n",
    "\n",
    "    metrics_score_string = '<TM> '\n",
    "\n",
    "    # Make sure the ratings of all metrics are provided\n",
    "    #print(metrics, metric_rates.keys())\n",
    "    assert set(metrics) == set(list(metric_rates.keys()))\n",
    "\n",
    "    metrics_info = []\n",
    "    metrics_list = []\n",
    "    values_list = []\n",
    "    rates_list = []\n",
    "    for idx, (m, v) in enumerate(zip(metrics, values)):\n",
    "        mx = m.lower().replace('-score', '').strip()\n",
    "        mx = m.lower().replace(' score', '').strip()\n",
    "        mx = m.lower().replace('score', '').strip()\n",
    "        score_rate = ''\n",
    "        if int(metric_rates.get(m, 0)) in [4, 5]:\n",
    "            score_rate = 'HIGH'\n",
    "        elif int(metric_rates.get(m, 0)) in [3]:\n",
    "            score_rate = 'MODERATE'\n",
    "        else:\n",
    "            score_rate = 'LOW'\n",
    "\n",
    "        metrics_list.append(m.replace('-', '').lower())\n",
    "        values_list.append(f'{roundN(v,2)}%')\n",
    "        rates_list.append(f'{score_rate}')\n",
    "    return [(a,b,c) for a,b,c in zip(metrics_list,rates_list,values_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "every-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a rough estimate of number of models per each task.\n",
    "# Compute the number of unique words\n",
    "mask_met=False\n",
    "taskNames_samples= {}\n",
    "preambles = {}\n",
    "pream = {}\n",
    "# apply the preprocessing to the data\n",
    "for idx,pc in enumerate(full_data):\n",
    "    #print(idx)\n",
    "    tn = pc['task_name']\n",
    "    examples = processInputTableAndNarrations(pc, identical_metrics=identicals, augnment_metrics=False,)\n",
    "    pp = processMetricsDataChecks(pc[\"metrics_values\"],pc[\"imetric_score_rate\"],identicals=identicals)\n",
    "    if tn not in preambles.keys():\n",
    "        preambles[tn]= []\n",
    "        pream[tn] = []\n",
    "        taskNames_samples[tn]= []\n",
    "    preambles[tn].append(examples['preamble'])\n",
    "    taskNames_samples[tn].append(examples)\n",
    "    pream[tn].append(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "continued-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pream['UPS customer service Ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broadband-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "tns={}\n",
    "for tn,elems in pream.items():\n",
    "    po=[]\n",
    "    for p in elems:\n",
    "        po = po+p\n",
    "    tns[tn] = Counter([p[0] for p in list(set(po))]).most_common(1)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automatic-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns['UPS customer service Ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "automotive-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.551724137931035"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([v for v in tns.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-freeze",
   "metadata": {},
   "source": [
    "For this NLG task, the goal is generating analytical sentences based on the evaluation metrics' scores achieved by any given classification model. \n",
    "To generate the dataset for this study, different ML models were trained on a number of classification tasks across different application domains. \n",
    "For each classifier, experts were asked to rate the scores achieved for a given set of metrics. \n",
    "Based on the ratings assigned, metrics' scores, and information on the dataset distribution across the class labels, they were also asked to write analytical statements summarising the classification performance of the corresponding model. \n",
    "A carefully designed pre-processing routine is applied to remove invalid submissions resulting in 612 high-quality data-sentence pairs. The training, validation and test set consists of 582 data-sentence pairs, 30 data-sentence pairs, and 30 data-sentence pairs, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-father",
   "metadata": {},
   "source": [
    "### The dataset contains narrations of models or classifiers trained on 58 different machine learning problems. However, only classification tasks were considered. We leave regression tasks for future work.\n",
    "\n",
    "### Across each classification task, about 6 different model were trained. These models include random forest, support vector machines, gradient boosting, logistic regression, and KNN. \n",
    "\n",
    "### The annotators were asked to summarized the performance of the model based on different combination of metric scores. For simplicity only the most common classification metrics were considered. These are accuracy, precision, AUC, recall, specificity, F1-score and F2-score. This implies that the NLG models trained on this dataset will struggle to produce a valid summary of input with unknown metrics.\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-lunch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
