{
    "1": [
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of",
        "The performance of the model on this classification task as evaluated based on accuracy, precision and AUC achieved 85.33%, 82.59%, 87.1%, 90.46%. These scores were attained despite being trained in an imbalanced dataset with a similar number of samples from #CA and #CB as indicated by comparing these values across different metrics: precision (82.61%), recall score(83.01%) and F1score (60.63%). From these results, we can make the conclusion that this classifier has moderate predictive ability for correctly separating examples belonging to anyof the classes especially those related to class #CA which happens to be about 83.12%. Furthermore looking at the precision score there are concerns regarding whether or not it is effective when assigning such high value labels to test cases considering the moderaly balanced datasets offer some form of support to our claims made here suggesting its prediction capability will likely misclassify only a small percentage of"
    ],
    "2": [
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective at predicting the true class labels for several test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores."
    ],
    "3": [
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels to the test cases/cases with only a few instances misclassified. The model has a very low false positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across all the metrics, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for most of the test cases. The model has a very low false-positive error rate as indicated by the precision and recall scores."
    ],
    "4": [
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples.",
        "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, it also has high F1score and precision score. From these high scores across the various metrics, we can be assured that this model will be very effective and precise at correctly predicting the true label for most of the test cases/samples."
    ],
    "5": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.28%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that this model has a moderate classification performance hence will likely misclassify only a small number of examples drawn randomly from any of the classes."
    ],
    "6": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified."
    ],
    "7": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified."
    ],
    "8": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified."
    ],
    "9": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified."
    ],
    "10": [
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified.",
        "Trained to tell-apart the examples belonging to the class labels #CA and #CB, the model's classification prowess is characterized by the scores 86.49%, 75.29%, 77.04%, and 81.61%, respectively, across the metrics sensitivity, precision, AUC, and accuracy. From these scores, we can conclude that the learning algorithm employed to solve this ML task has a moderately high prediction performance and will be able to correctly classify most test samples with only a few instances misclassified."
    ]
}