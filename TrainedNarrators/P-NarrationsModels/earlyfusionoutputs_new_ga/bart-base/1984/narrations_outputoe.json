{
    "1": [
        "73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration.",
        ".73.28 (accuracy), 48.4(AUC) and 60.39 (precision-score). The model achieves a very high AUC of 94.5, showing that the separation level between its class predictions is quite good. Coupled with an F1score of 83.03 which shows that there would be many examples belonging to #CA examples being misclassified as #CB, one can conclude that only a few samples from #CB will likely get mislabeled as part of #CA. That is, the model has fairly high confidence in its prediction decisions related to the two classes under consideration."
    ],
    "2": [
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        "..73% (accuracy), 48.4%(sensitivity), 66.12% and 48,47% were the evaluation scores achieved by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "3": [
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "4": [
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "5": [
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "6": [
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "7": [
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class.",
        ".73.28 (accuracy), 48.4 (specificity), and F1score (41.47) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either #CA or #CB. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class."
    ],
    "8": [
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels ( #CA, #CB, and #CC ) to test examples. This classifying model demonstrates a moderately high classification ability given the scores attained across the different evaluation/assessment metrics. In fact, these scores strongly indicate that the likelihood of misclassifying any given test observation is quite small which is impressive but not surprising given its distribution in the dataset."
    ],
    "9": [
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Before deployment, steps should be taken to improve the model's precision score hence improving the classification confidence level."
    ],
    "10": [
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples.",
        ".(a) Recall equal to 93.92%, (b) Precision score equal 97.33%, and (c) F1score equal to 88.13% are the evaluation metrics' scores summarizing the ability of the classifier on this binary classification problem or task where the test instances are classified as either #CA or #CB is shown to be moderately high based on the scores across the metrics. This implies that the likelihood of misclassifying test samples is small, which is impressive but not surprising given the data was balanced between the classes. Overall, this model shows a high level of effectiveness in terms of correctly predicting the true labels for several test examples."
    ]
}