{
    "data": [
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.12},\\\"Recall\\\":{\\\"Model A\\\":94.72},\\\"AUC\\\":{\\\"Model A\\\":96.08},\\\"Precision\\\":{\\\"Model A\\\":82.64}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This algorithm employed to solve this binary classification problem is shown to be very effective with accuracy, precision and AUC scores of 89.12%, 94.72% and 96.08%. It has a slightly lower precision score of 82.64%. Overall, 89.12% of predictions are correct and an almost perfect AUC score of 96.08% means the model is highly effective in terms of separating the test observations under the different classes.",
            "task_name": "Bike Sharing Demand",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 1,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":81.15},\\\"AUC\\\":{\\\"Model A\\\":96.38},\\\"Precision\\\":{\\\"Model A\\\":98.02}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "To summarise, this is a good performing model with high accuracy (92.78%) with very high AUC (96.38%), and precision (98.02%). The precision higher than recall (81.15%) implies that the model in general only classifies cases as C2 on only a few occasions. The good thing about this is that, a precision score this high means that 98.02% of identifications predicted as class C2 were actually C2. In other words, the model is very precise and confident with the C2 predictions.",
            "task_name": "Car Acceptability Valuation",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":3,\"AUC\":5,\"Precision\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.90},\\\"Recall\\\":{\\\"Model A\\\":76.19},\\\"F1-score \\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":91.43}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The dataset was a highly imbalanced dataset; therefore scoring 83.12% on the F1-score is a better indicator of overall performance than accuracy. A high accuracy of 95.9% is less impressive because a larger proportion of data belongs to the same class, C1. When predicting whether data was part of the minority class C2, 91.43% of these identifications were correct. Furthermore, judging by the difference between the recall and precision scores, the model displays some sort of bias against the prediction of class C2, which implies that those cases labeled as C2 were actually C2. The F1-score, which is a balance between recall and precision, is only 83.12%.",
            "task_name": "Car Acceptability Valuation",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"F1-score \":3,\"Precision\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.67},\\\"Recall\\\":{\\\"Model A\\\":69.2},\\\"F1-score \\\":{\\\"Model A\\\":68.64},\\\"Specificity\\\":{\\\"Model A\\\":53.25}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> 59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This algorithm is a fairly poor predictor with an overall accuracy of 62.67%. The specificity of the model is barely above 53.25% which means the model has almost zero predictive ability for class C1. The model has marginally improved performance for predicting class C2, as shown with a recall of 69.2% and an F1-score  of 68.64%, but still contributes to an overall poor performance.",
            "task_name": "E-Commerce Shipping",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":1,\"Recall\":2,\"Specificity\":1,\"F1-score \":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.52},\\\"Recall\\\":{\\\"Model A\\\":94.26},\\\"F1-score \\\":{\\\"Model A\\\":92.74},\\\"Precision\\\":{\\\"Model A\\\":94.26}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "On the given multi-class problem, the ML classifier performs very effectively, highlighted with an Accuracy score of 93.52%. Also, the F1-score of 92.74% indicates that the classifier is well balanced. High scores for the F1-score, accuracy and precision (92.74%, 93.52% and 94.26%, respectively) indicate a balanced and effective model at predicting the outcome across all classes.",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5,\"F1-score \":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.52},\\\"Recall\\\":{\\\"Model A\\\":94.26},\\\"F1-score \\\":{\\\"Model A\\\":92.74},\\\"Precision\\\":{\\\"Model A\\\":94.26}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The AI algorithm trained on this multi-class problem (where a given test case or observation is assigned the label C1 or C2 or C3 or C4) was evaluated based on the scores across the metrics: precision, recall, accuracy and F1-score . The algorithm is well balanced as indicated by the Accuracy score of 93.52% and F1-score of 92.74% (Note: the F1-score captures information on the precision and recall of the trained model). Overall, high scores across all the metrics indicate an effective model, good at generating outcomes or predictions across all classes.",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5,\"F1-score \":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":60.36},\\\"F1-score \\\":{\\\"Model A\\\":40.89},\\\"Precision\\\":{\\\"Model A\\\":35.19}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The classifier or algorithm was trained to output the true label of any given test case or observation as either of the following class labels: C1, C2, C3, and C4. Evaluation of the classifier's performance was conducted based on  scores across the metrics: accuracy, precision, and F1-score . It achieved a moderate accuracy of 60.36%, a precision score of 35.19%, and an F1-score  of 40.89%. The low F1-score (Note: this score  captures information on the precision and recall of the trained model)  suggests the model has low recall and precision scores hence will perform not quite well on most classification instances.  In summary, the algorithm is not well balanced as indicated by the Accuracy score and F1-score, suggesting it will not be good at generating the actual label for a large proportion of test observations.",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":3,\"Precision\":2,\"F1-score \":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":86.89},\\\"Precision\\\":{\\\"Model A\\\":89.34},\\\"Accuracy\\\":{\\\"Model A\\\":90.92}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Separating test observations under the following class labels C1, C2, C3, and C4 was the modeling objective used to train the classifier for this task. Evaluations or assessments conducted based on the metrics F2-score, Precision and Accuracy show that the algorithm will be very effective at correctly predicting the true labels for multiple test cases with a marginal likelihood of error. The conclusion above was arrived at based on the scores: accuracy (90.92%), F2-score (86.89%), and precision (89.34%).",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"F2-score\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":86.89},\\\"Recall\\\":{\\\"Model A\\\":89.34},\\\"Accuracy\\\":{\\\"Model A\\\":90.92}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Test observations are classified as one of the following classes C1, C2, C3, and C4. The evaluation or assessment of the trained algorithm's classification ability was done based on the metrics: F2-score, Recall, and Accuracy. According to the scores (that is Accuracy = 90.92%, F2-score = 86.89%, and Recall = 89.34%), the learning algorithm is relatively good at determining the true labels for multiple unseen observations.",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"F2-score\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.29},\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"F1-score \\\":{\\\"Model A\\\":77.15},\\\"Precision\\\":{\\\"Model A\\\":66.45}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "High accuracy and recall scores (96.29% and 91.96%) are overshadowed by a moderate F1-score (77.15%) and a low precision score (66.45%). A low precision of only 66.45% signifies that there is a false positive rate of <preci_diff>, indicating that the model has low predictive ability for class C2. However, there is a very high accuracy of 96.29% indicating a class imbalance and good performance on predicting Class C1.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":2,\"F1-score \":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.29},\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"F1-score \\\":{\\\"Model A\\\":77.15},\\\"Precision\\\":{\\\"Model A\\\":66.45}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The almost perfect accuracy and recall scores (96.29% and 91.96%) are masked by the moderate scores achieved for F1-score (77.15%) and precision score (66.45%). The moderately low precision suggests that there is a false positive rate of <preci_diff>, indicating that the model has low predictive ability for class C2 and is less precise. On the other hand, a very high accuracy of 96.29% on such a class balance dataset demonstrates good performance in terms of  predicting class C1.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":2,\"F1-score \":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.53},\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"AUC\\\":{\\\"Model A\\\":94.60},\\\"Precision\\\":{\\\"Model A\\\":85.86}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Overall, this algorithm has performed well in the task, scoring 86.53% for accuracy, 87.03% for recall, 94.6% for AUC, and 85.86% for precision. The algorithm is well balanced with  very similar recall and precision scores (87.03% and 85.86% respectively) and an almost perfect AUC score of 94.6%, which indicates a very good ability to distinguish between the two classes. The accuracy scores mean that the predictions were correct 86.53% of the time.",
            "task_name": "Bike Sharing Demand",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"AUC\":4,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.09},\\\"F1-score \\\":{\\\"Model A\\\":65.31},\\\"AUC\\\":{\\\"Model A\\\":90.02},\\\"Precision\\\":{\\\"Model A\\\":61.47}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2 ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "On an imbalanced problem such as this, the low F1-score (65.31%) is a true indicator of overall performance than the relatively high accuracy of 85.09%. A relatively low precision of 61.47% means that of the time data belonging to class C2 was predicted incorrectly as C1. 85.09% accuracy is not an indicator of good performance considering that a large amount of the data belongs to the same class, class C1.",
            "task_name": "Annual Income Earnings",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"F1-score \":2,\"AUC\":4,\"Precision\":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.98},\\\"Recall\\\":{\\\"Model A\\\":58.954},\\\"AUC\\\":{\\\"Model A\\\":85.46},\\\"Precision\\\":{\\\"Model A\\\":37.468}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "A high accuracy of 89.98% is devalued by a very low precision and recall, which indicates that the model has very low predictive ability overall. The model was trained on a very unbalanced dataset with the majority of the data from class C1, so an AUC score of 85.46% is not very informative. A poor recall score of 58.95% indicates that the model does not reliably identify class C2 correctly.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":1,\"Recall\":2,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.45},\\\"Sensitivity\\\":{\\\"Model A\\\":74.07},\\\"AUC\\\":{\\\"Model A\\\":87.95},\\\"Precision\\\":{\\\"Model A\\\":86.96}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The classification model performs well with good scores for sensitivity and precision and high accuracy. Overall, the performance was good with a sensitivity of 74.07% and a precision of 86.96% indicating that the model is able to identify a good portion of examples under the minority class (C2), fairly well despite being trained on an imbalanced dataset.",
            "task_name": "Food Ordering Customer Churn Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":4,\"Sensitivity\":4,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"AUC\\\":{\\\"Model A\\\":84.98},\\\"Specificity\\\":{\\\"Model A\\\":95.96}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "In the context of the objectives of the machine learning problem, the model is shown to be very capable at detecting class C1, hence a high specificity. However, it is fairly poor at detecting the other class, C2. From the table, we can say that the model is fairly accurate (71.52%) and has a very high specificity score (95.96%); but a low sensitivity score (59.06%) means that the model is not much better than guessing.",
            "task_name": "Company Bankruptcy Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Specificity\":5,\"Sensitivity\":1,\"AUC\":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.21},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Recall\\\":{\\\"Model A\\\":93.12},\\\"Precision\\\":{\\\"Model A\\\":91.27}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This model has a very high prediction performance; hence it will be very good at generating the true label for several test cases with a marginal misclassification error rate. Not only that the model has high accuracy equal to 93.21%, but it also has very high recall (93.12%) and precision (91.27%). Overall, the ML model employed here is very confident about the final labeling decision for examples from both classes.",
            "task_name": "Airline Passenger Satisfaction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"AUC\":5,\"Recall\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":84.52},\\\"AUC\\\":{\\\"Model A\\\":94.02},\\\"Recall\\\":{\\\"Model A\\\":93.44},\\\"Precision\\\":{\\\"Model A\\\":74.04}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset has 50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The classification model boasts a high accuracy of 84.52% and inferring from the recall and precision scores, the model is slightly better at detecting positives than it was at avoiding misclassifying negatives. A very high recall of 93.44% demonstrates that a high quantity of actual positives was identified. A respectable precision score of 74.04% means that 74.04% of positive predictions were correct.",
            "task_name": "Concrete Strength Classification",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":3,\"AUC\":5,\"Recall\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.44},\\\"Recall\\\":{\\\"Model A\\\":94.44},\\\"AUC\\\":{\\\"Model A\\\":95.67},\\\"Precision\\\":{\\\"Model A\\\":91.07}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Taking all scores into account, this is a very effective model and can correctly identify which class a given test example belongs to. This is because it boasts very high accuracy, recall, AUC, and precision scores of 96.44%, 94.44%, 95.67%, and 91.07%, respectively. It is worthy to note that, 91.07% of all positive class predictions are true, indicating that the model can be trusted in most cases to output the correct label.",
            "task_name": "Real Estate Investment",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"AUC\":5,\"Recall\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.73},\\\"AUC\\\":{\\\"Model A\\\":92.24},\\\"Recall\\\":{\\\"Model A\\\":95.46},\\\"Precision\\\":{\\\"Model A\\\":77.78}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This model performs well on this task with high scores across the board. Specifically, the accuracy score is 83.73%, the AUC score is 92.24% and the recall (sensitivity) score is 95.46%. These high scores tell a story of a model with a high classification performance. This implies that only a small portion of unseen test examples are likely to be misclassified. Overall, this model is effective and performed quite well.",
            "task_name": "Student Job Placement",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Assessment or evaluations conducted with respect to the model's prediction power with respect to this imbalanced classification task show that the model performs extremely poorly when predicting the target class C2; hence the very low precision score of 34.14%. A high accuracy score of 90.46% is only indicative of a highly imbalanced dataset. A recall score of 66.92% is a better indicator that the model is not effective at predicting the target class.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":90.46},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Precision\\\":{\\\"Model A\\\":34.14}}\"",
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":1,\"Recall\":2,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset has 50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The prediction performance scores achieved by the model are all very high and indicate a highly effective learning algorithm. As shown in the table, the accuracy is 95.33%,  recall is 97.94%; AUC is 98.06% and precision is equal to 92.86%. This is a well-balanced model given the identical scores across the metric. In conclusion, the model will likely fail to produce the correct label for only a small number of unseen cases.",
            "task_name": "Advertisement Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.33},\\\"Recall\\\":{\\\"Model A\\\":97.94},\\\"AUC\\\":{\\\"Model A\\\":98.06},\\\"Precision\\\":{\\\"Model A\\\":92.86}}\"",
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"Recall\":5,\"AUC\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Given the scores achieved, this classifier demonstrates almost no predictive ability at all. Trained on an imbalanced dataset, so therefore 65.37% accuracy is not impressive. A precision of 33.06%, recall of 55.4% and an F1-score of 41.41% are all very low scores and indicate this is a very poor classifier.",
            "task_name": "Basketball Players Career Length Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":65.37},\\\"Recall\\\":{\\\"Model A\\\":55.40},\\\"F1-score\\\":{\\\"Model A\\\":41.41},\\\"Precision\\\":{\\\"Model A\\\":33.06}}\"",
            "imetric_score_rate": "{\"Accuracy\":1,\"Precision\":1,\"F1-score\":1,\"Recall\":1}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset has 50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This model has very high accuracy and very high F1-score, indicating an effective and balanced model. With accuracy, recall, F1-score and precision at 91.37%, 92.25%, 91.18% and 90.14% respectively. The number of unseen cases that can be accurately identified is large, given that the misclassification error is only about <acc_diff>%.",
            "task_name": "Used Cars Price-Range Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"Recall\\\":{\\\"Model A\\\":92.25},\\\"F1-score\\\":{\\\"Model A\\\":91.18},\\\"Precision\\\":{\\\"Model A\\\":90.14}}\"",
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"F1-score\":5,\"Recall\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Trained on an extremely unbalanced dataset, an F1-score of 73.22% is an indicator of overall moderately good performance. Since the majority of the data belongs to label C1, an accuracy score of 99.91% is less impressive. A recall of 81.71% means that 81.71% of positive cases were detected.",
            "task_name": "Credit Card Fraud Classification",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.91},\\\"Recall\\\":{\\\"Model A\\\":81.71},\\\"F1-score\\\":{\\\"Model A\\\":73.22},\\\"Precision\\\":{\\\"Model A\\\":66.34}}\"",
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":2,\"F1-score\":3,\"Recall\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This model is able to perform this classification task well, producing very high accuracy, recall, and AUC scores (85.86%, 92.86%, and 91.96%, respectively) but at the cost of poor precision (46.43%). A very high AUC score (91.96%) shows that the model is able to effectively tell-apart the C1 and C2 observations. The balance has been adjusted, sacrificing precision (46.43%) to achieve a very high recall (92.86%). In summary, only about 46.43% of all C2 predictions are correct.",
            "task_name": "Real Estate Investment",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.86},\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"AUC\\\":{\\\"Model A\\\":91.96},\\\"Precision\\\":{\\\"Model A\\\":46.43}}\"",
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":1}"
        },
        {
            "id": 2,
            "task_name": "Airline Passenger Satisfaction",
            "narration": "After the model was trained to tell-apart observations or cases belonging to the different classes, it is shown to have higher confidence at predicting the correct class labels for most test instances. This is based on the model achieving 93.2% (accuracy), 97.91 (for the AUC). Besides, the model has a recall and precision of 93.12 and 91.27 respectively. With such a high accuracy, we can trust the model to have a lower error rate. A similar conclusion made for the high accuracy can be made for the model achieving a near-perfect AUC score.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, AUC, Recall and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Accuracy of 93.205. </li> <li> What is the implication of Model A achieving a AUC of 97.91? </li>",
            "narrative_status": 1,
            "date_approved": "17/09/2021",
            "is_paid": 2,
            "user_ip": "10.212.134.12",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.205},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Recall\\\":{\\\"Model A\\\":93.119},\\\"Precision\\\":{\\\"Model A\\\":91.265}}\"",
            "deleted": false,
            "date_submitted": "17/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "P9CRV-07A98-Q@4Y6_2-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"AUC\":5,\"Recall\":5}"
        },
        {
            "id": 14,
            "task_name": "Vehicle Insurance Claims",
            "narration": "On the task under consideration, the model achieved a precision of 82.46, an accuracy of 85.0%, and moderate recall of 70.15. On the subject of predicting the true of samples drawn from the different classes, the model is shown to be fairly confident as shown by the scores across the metric.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.0},\\\"Recall\\\":{\\\"Model A\\\":70.149},\\\"Precision\\\":{\\\"Model A\\\":82.456}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "A5PKL-4HH2C-TTVVB-14-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"Recall\":3}"
        },
        {
            "id": 15,
            "task_name": "German Credit Evaluation",
            "narration": "Under this machine learning task, the classifier demonstrates a low performance. The scores achieved for the accuracy, sensitivity, AUC, and precision are 69.6, 54.55, 72.19, and 22.79, respectively. With an accuracy of 69.6, we can conclude that the model is somewhat confident about its predictions especially for the samples from the C1 class. Overall, it has a very poor labeling performance when it comes to identifying the C2 examples correctly considering the precision and recall scores.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Sensitivity, AUC and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Accuracy of 69.6. </li> <li> What is the implication of Model A achieving a Sensitivity of 54.545? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":69.6},\\\"Sensitivity\\\":{\\\"Model A\\\":54.545},\\\"AUC\\\":{\\\"Model A\\\":72.189},\\\"Precision\\\":{\\\"Model A\\\":22.785}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "R87UC-@VBBT-9V0AV-15-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Sensitivity\":3,\"Precision\":1,\"AUC\":2}"
        },
        {
            "id": 15,
            "task_name": "German Credit Evaluation",
            "narration": "Under this labeling task, the effectiveness of the classifier is very low, and therefore it will struggle to correctly label most unseen observations or cases. The scores achieved for accuracy, sensitivity, AUC, and precision are 69.6%, 54.55%, 72.19%, and 22.79%, respectively. The accuracy of 69.6 could be attributed to the model being better at identifying  C1 cases than those belonging to C2. When you consider the precision and recall scores, this model has very weak labeling prowess when it comes to separating the C2 examples correctly.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Sensitivity, AUC and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Accuracy of 69.6. </li> <li> What is the implication of Model A achieving a Sensitivity of 54.545? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":69.6},\\\"Sensitivity\\\":{\\\"Model A\\\":54.545},\\\"AUC\\\":{\\\"Model A\\\":72.189},\\\"Precision\\\":{\\\"Model A\\\":22.785}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "R87UC-@VBBT-9V0AV-15-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Sensitivity\":2,\"Precision\":1,\"AUC\":2}"
        },
        {
            "id": 16,
            "task_name": "Water Quality Classification",
            "narration": "The scores achieved across the different metrics under consideration are 67.07 (accuracy), 67.39 (sensitivity), 67.02 (specificity), and an F1-score of 36.47. The model has a very low F1-score indicating that it will likely fail to correctly identify the class of most test cases. Specifically, some examples belonging to class C1 are likely to be misclassified as C2 considering the F1-score, and sensitivity.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Specificity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-5",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.073},\\\"Sensitivity\\\":{\\\"Model A\\\":67.391},\\\"Specificity\\\":{\\\"Model A\\\":67.021},\\\"F1-score\\\":{\\\"Model A\\\":36.471}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "QLHWD-EW5JJ-CT9FU_16-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Sensitivity\":3,\"F1-score\":1,\"Specificity\":3}"
        },
        {
            "id": 16,
            "task_name": "Water Quality Classification",
            "narration": "This model basically will struggle to accurately generate the label for several test cases, especially those belonging to class C2. Given the distribution of the dataset between the classes, the accuracy, specificity, F1-score, and sensitivity scores of 67.07%, 67.02%, 36.47%, and 67.39%, respectively, are less impressive and indicative of a model with poor prediction ability. The accuracy score is dominated by the correct C1 predictions. Overall, this model is less confident with the prediction decisions.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Specificity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-5",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.073},\\\"Sensitivity\\\":{\\\"Model A\\\":67.391},\\\"Specificity\\\":{\\\"Model A\\\":67.021},\\\"F1-score\\\":{\\\"Model A\\\":36.47}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "QLHWD-EW5JJ-CT9FU_16-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Sensitivity\":3,\"F1-score\":1,\"Specificity\":3}"
        },
        {
            "id": 17,
            "task_name": "Bike Sharing Demand",
            "narration": "Following the training of the classifier on the given machine learning problem, the classifier is shown to be effective at correctly predicting the class labels for the majority of the test instances. This is shown by the very high scores achieved across the accuracy, recall, AUC, and precision evaluation metrics. With an AUC of 97.91, the model is nearly perfect in regards to predictions across the majority of the new or unseen cases. The model has a very low error rate as indicated by the accuracy.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li> <li> In a sentence, summarize the implication of the model achieving AUC of 97.91. </li> <li> What is the implication of Model A achieving a Accuracy of 92.085? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.085},\\\"Recall\\\":{\\\"Model A\\\":94.042},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Precision\\\":{\\\"Model A\\\":89.708}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "HEF5C-@EA31-NWMF8-17-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"AUC\":5,\"Recall\":5}"
        },
        {
            "id": 18,
            "task_name": "Vehicle Insurance Claims",
            "narration": "This model has a somewhat low classification performance, achieving an accuracy of 77.01% along with recall and precision scores of 64.1%  and 43.86%, respectively. The model has a higher false-positive rate as shown by the precision score. Finally, the model has a somewhat moderate true-positive rate. All the statements above are based on the fact that out of all the positive class predictions, only 43.86% were actually correct.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Precision of 43.86. </li> <li> What is the implication of Model A achieving a Recall of 64.103? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.01},\\\"Recall\\\":{\\\"Model A\\\":64.103},\\\"Precision\\\":{\\\"Model A\\\":43.86}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "KUEDC-DW2PK-KFE7V-18-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Precision\":2, \"Recall\":2}"
        },
        {
            "id": 19,
            "task_name": "Broadband Sevice Signup",
            "narration": "Evaluating the classification model in the context of this ML task produced the scores: accuracy of 94.73%, a recall of 95.012, and a precision of 93.41. With such high scores across these metrics, the model demonstrates a high level of effectiveness in terms of generating the correct class labels for several test cases. Consequently, this model is precise and the confidence in prediction decisions is also high.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-5",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.732},\\\"Recall\\\":{\\\"Model A\\\":95.012},\\\"Precision\\\":{\\\"Model A\\\":93.406}}\"",
            "deleted": false,
            "date_submitted": "23/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "32BE3-FTM99-57J32-19-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5, \"Recall\":5}"
        },
        {
            "id": 20,
            "task_name": "Insurance Churn",
            "narration": "This model has high accuracy and AUC scores of 89.78 and 85.46, respectively. In contrast, it has a low precision of 37.47% and a low recall equal to 58.95%.  Based on the scores stated above, the model's performance with respect to the C2 class can be described as very low. This implies that most of the correct predictions made by the model are related to the majority class, C1. In summary, only a few examples belonging to C2 can be correctly identified.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.782},\\\"Recall\\\":{\\\"Model A\\\":58.954},\\\"AUC\\\":{\\\"Model A\\\":85.46},\\\"Precision\\\":{\\\"Model A\\\":37.468}}\"",
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":2,\"Recall\":2,\"AUC\":4}",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "DD6U2-DYT3R-F7GCK_20-APC",
            "is_dataset_balanced": 1
        },
        {
            "id": 21,
            "task_name": "Employee Attrition",
            "narration": "This algorithm has a high recall, accuracy, and AUC scores of  94.12, 86.72, and 85.39, respectively. However, it has a lower precision of 32.65%; hence, some of the C2 output predictions may be wrong. To be specific, it has a high performance with respect to the C1 prediction and a low prediction performance for the C2 cases. This implies that the C2 prediction output shouldn't be taken on the face value given that a section of C1's examples can be mislabeled as C2.  In summary, this is a less precise model, especially for the C2 cases.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.719},\\\"Recall\\\":{\\\"Model A\\\":94.118},\\\"AUC\\\":{\\\"Model A\\\":85.389},\\\"Precision\\\":{\\\"Model A\\\":32.653}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.089% belonging to class C2",
            "redeem_code": "YDM6G-EPYQG-5WA8M-21-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":2,\"AUC\":4,\"Recall\":5}"
        },
        {
            "id": 22,
            "task_name": "Used Cars Price-Range Prediction",
            "narration": "Very high accuracy, precision, and recall scores were achieved regarding the given model training objective: 91.37%, 90.14%, and 92.25%, respectively. Based on these metrics, one can conclude that the model is highly effective at generating the correct label for most test instances. This model is quite confident about the labeling decisions, hence can be trusted in most cases to be correct. It is also important to note that, the model has a very low error rate equal to <acc_diff>.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.373},\\\"Recall\\\":{\\\"Model A\\\":92.254},\\\"F1-score\\\":{\\\"Model A\\\":91.183},\\\"Precision\\\":{\\\"Model A\\\":90.138}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "0UH7E-VN2VX-CDL@8-22-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"F1-score\":5,\"Recall\":5}"
        },
        {
            "id": 23,
            "task_name": "Wine Quality Prediction",
            "narration": "The classification model possesses a fairly moderate performance on the given binary modeling problem as indicated by the recall, precision, and accuracy scores. This model can correctly classify a reasonable number of instances. With a precision of about 73.71% and a recall of about 76.21%, the model is shown to have a lower false-positive rate. Finally based on the accuracy score we can conclude that the model correctly classifies about 74.27% of all test cases.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Precision of 73.709. </li> <li> What is the implication of Model A achieving a Accuracy of 74.265? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.27},\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "CV9HD-63TXB-PPEEP-23-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"Recall\":4}"
        },
        {
            "id": 24,
            "task_name": "Hotel Satisfaction",
            "narration": "Based on the accuracy, precision, recall, and AUC, we can say that this classifier has a high performance in terms of predicting the correct class labels. The accuracy score is 82.71%, precision is 84.66%, recall is 77.52%, and AUC is 88.67%. The precision and recall scores show that the classifier is careful about assigning the C2, and therefore, a C2 prediction can be trusted to be correct. This classifier is also good at identifying C1 cases. Overall,  we can conclude that the classifier can be trusted to make a few classification errors considering all the scores above.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Accuracy of 82.705. </li> <li> What is the implication of Model A achieving a AUC of 88.668? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.71},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67},\\\"Precision\\\":{\\\"Model A\\\":84.66}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "7PRR1-G2QAN-W48U9-24-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"Recall\":3,\"AUC\":4}"
        },
        {
            "id": 25,
            "task_name": "Broadband Sevice Signup",
            "narration": "The model has an accuracy of about 94.73% with a precision and recall equal to 95.012% and 93.41%, respectively. The scores achieved demonstrate that the model has similar prediction capability across the different classes, C1 and C2. Only a small proportion of unseen cases will be mislabeled by the model. Overall, we can conclude that the classifier is highly effective at correctly predicting the actual class labels of a majority of test cases.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-5",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.732},\\\"Recall\\\":{\\\"Model A\\\":95.012},\\\"Precision\\\":{\\\"Model A\\\":93.406}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "526U7-A1232-9NM@B_25-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"Recall\":5}"
        },
        {
            "id": 26,
            "task_name": "Tic-Tac-Toe Strategy",
            "narration": "On the task under consideration, the model achieved an AUC score of 73.62, an accuracy of 64.58 with a lower F1-score, and a precision score of 45.16 and 42.86, respectively. The accuracy and AUC scores are dominated by the correct predictions for C1 examples. According to these scores, we can conclude that this classification algorithm has a somewhat lower performance as it will not be able to correctly predict the actual labels of a large number of test examples, especially the unseen cases under C2.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.583},\\\"AUC\\\":{\\\"Model A\\\":73.62},\\\"F1-score\\\":{\\\"Model A\\\":45.161},\\\"Precision\\\":{\\\"Model A\\\":42.857}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "HG1VB-UQANP-GTP8A-26-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Precision\":2,\"F1-score\":2,\"AUC\":3}"
        },
        {
            "id": 27,
            "task_name": "Job Change of Data Scientists",
            "narration": "The classifier's prediction accuracy score in terms of telling-apart the examples belonging to the classes C1 and C2 is 75.75. It has a precision score of 55.23% with a recall of 51.3%. We can conclude that the model is only good at predicting the majority class (C1) and will fail at sorting apart test examples belonging to label C2. The conclusion above is attributed to scores achieved for the precision and recall metrics.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":75.75},\\\"Recall\\\":{\\\"Model A\\\":51.30},\\\"F1-score\\\":{\\\"Model A\\\":53.19},\\\"Precision\\\":{\\\"Model A\\\":55.23}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "B4ENE-DCDUF-PE4TL-27-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":3,\"F1-score\":3,\"Recall\":3}"
        },
        {
            "id": 28,
            "task_name": "Basketball Players Career Length Prediction",
            "narration": "This machine learning model has a prediction accuracy of 70.45% with moderately low recall and precision scores of 59.69 and 62.1%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the model has a low prediction performance in terms of correctly picking out the test observations belonging to the label C2.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F1-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, F1-score and Precision. (Your answer should capture the implications of (1) achieving Recall of 59.69 and (2) achieving a F1-score of 60.87 </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-7",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":70.448},\\\"Recall\\\":{\\\"Model A\\\":59.69},\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":62.10}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "8@346-DMPTW-KXT44_28-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Precision\":2,\"F1-score\":2,\"Recall\":2}"
        },
        {
            "id": 29,
            "task_name": "Mobile Price-Range Classification",
            "narration": "The machine learning model achieved an accuracy of 96.01% and very high recall and precision scores of 96.08 and about 95.98, respectively, on the given classification problem where the training objective is assigning test samples one of the four possible labels (from the classes C1,  C2, C3, and  C4). With such high scores across the different metrics, we can be sure to trust that the model will be able to predict the correct class labels for the majority of new test examples. In summary, it is safe to say the model has near-perfect performance with a very low classification error rate.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Precision-score and Recall-score. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.01},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "1XKE1-AP2MT-Q6KYR-29-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision-score\":5,\"Recall-score\":5 }"
        },
        {
            "id": 30,
            "task_name": "Used Cars Price-Range Prediction",
            "narration": "As shown in the results table, the model has a higher cases labeling performance based on the fact that it achieved a recall of 93.26, accuracy of 92.74%, precision score of 91.97%, and an F1-score of 92.61%. This model has the same prediction confidence or power whenever it outputs any of the two classes. The high prediction performance was expected given that it was trained on a balanced dataset with an identical number of cases under each label. In summary, these results indicate that the model is very effective at correctly classifying the majority of the test examples/cases with a higher confidence level.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Precision and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.736},\\\"Recall\\\":{\\\"Model A\\\":93.256},\\\"F1-score\\\":{\\\"Model A\\\":92.61},\\\"Precision\\\":{\\\"Model A\\\":91.972}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "7RJXK-22FHQ-75UGX_30-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"F1-score\":5,\"Recall\":5}"
        },
        {
            "id": 31,
            "task_name": "Broadband Sevice Signup",
            "narration": "The classifier under consideration has an accuracy of about 93.07% with very high precision and recall scores of 91.75 and 92.97, respectively. The model has very low false-positive and false-negative error rates as indicated by the recall and precision scores. This implies that most of the C1 and C2 predictions made are correct. In summary, we can confidently conclude that this classifier will be very effective at separating cases belonging to any of the different classes.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Recall of 92.966 and (2) achieving a Precision of 91.746. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.073},\\\"Recall\\\":{\\\"Model A\\\":92.97},\\\"Precision\\\":{\\\"Model A\\\":91.75}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "7PDCG-5YHUE-HVGMF-31-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"Recall\":5}"
        },
        {
            "id": 32,
            "task_name": "Vehicle Insurance Claims",
            "narration": "The classification model under consideration has an accuracy of 81.5, recall of 71.74, and a marginal precision score of 57.9%. From the precision and recall scores, some C2 predictions are false, meaning a portion of C1 examples are being misclassified. Considering all the scores above, the model will likely fail at correctly choosing the labels for a number of examples. Some instances assigned to the positive class, C2, are misclassified.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":71.739},\\\"Precision\\\":{\\\"Model A\\\":57.895}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "EBBHG-1BTRP-89TR3-32-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"Precision\":3}"
        },
        {
            "id": 33,
            "task_name": "Credit Risk Classification",
            "narration": "The precision of predictions made by the classifier is equal to 89.95%. It has a specificity score of 92.61%, an F1-score of 86.96%, and an accuracy of 88.89%.  The classifier can generate the correct class labels with a higher level of confidence given the high specificity score and F1-score. In simple terms, the classifier has good prediction performance, only making a few misclassifications.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Precision\\\":{\\\"Model A\\\":89.95}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "KFH@C-TC@DR-GW23H-33-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":5,\"F1-score\":4,\"Specificity\":5}"
        },
        {
            "id": 34,
            "task_name": "Broadband Sevice Signup",
            "narration": "Across the evaluation metrics, the model's classification accuracy is 96.59%, with the precision and recall equal to 95.72% and 96.78%, respectively.  The accuracy score indicates that the model has a lower misclassification error rate. And the precision and recall scores show that the model can correctly tell-apart the C2 cases from the population. Therefore, based on all the scores, we can almost be certain that the model can effectively assign the correct label of any given test case or instance.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of (1) achieving Recall of 96.783 and (2) achieving a Accuracy of 96.585 </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.59},\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Precision\\\":{\\\"Model A\\\":95.72}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "NTF@A-P3PVB-V0KTA-34-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5}"
        },
        {
            "id": 35,
            "task_name": "Bike Sharing Demand",
            "narration": "As shown in the table, the classifier achieved high performance with an accuracy of 86.53%, AUC of 94.5%. Furthermore, it recorded higher scores for recall (87.03%) and precision (85.56%). The results achieved suggest that this classifier can pick out the test examples belonging to each class under consideration with a misclassification rate of about <acc_diff>%.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.53},\\\"Recall\\\":{\\\"Model A\\\":87.031},\\\"AUC\\\":{\\\"Model A\\\":94.495},\\\"Precision\\\":{\\\"Model A\\\":85.561}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0GALK-D6G@P-9UNJW-35-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"AUC\":5,\"Precision\":4}"
        },
        {
            "id": 36,
            "task_name": "Water Quality Classification",
            "narration": "The learning algorithm or model lays claim to the following scores: 61.28% (accuracy), 48.39% (sensitivity), 66.38% (specificity), and F1-score (41.48%). A possible conclusion that can be made with respect to the scores above is that the model will not be effective when it comes to picking out or labeling test cases belonging to the minority class. However, it does moderately well for C1 cases as indicated by the specificity score.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Sensitivity, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Specificity of 66.383 and (2) achieving a Accuracy of 61.28.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":61.28},\\\"Sensitivity\\\":{\\\"Model A\\\":48.387},\\\"Specificity\\\":{\\\"Model A\\\":66.383},\\\"F1-score\\\":{\\\"Model A\\\":41.475}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "U1V2R-EMCEB-DJV7Y_36-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Sensitivity\":2,\"F1-score\":2,\"Specificity\":3}"
        },
        {
            "id": 37,
            "task_name": "Hotel Satisfaction",
            "narration": "The performance of the model on the task under consideration is as follows: Accuracy of 84.38%, AUC equal to 90.03, recall and precision, respectively, equal to 81.80 and 82.27. A possible conclusion one can make about the model's performance on the classification problem is that it can correctly classify a fair amount of test examples from all the class labels. The precision and recall are evidence enough to support this assertion.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, AUC and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. (Your answer should capture the implications of (1) achieving Recall of 81.803 and (2) achieving a AUC of 90.034.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":84.375},\\\"Recall\\\":{\\\"Model A\\\":81.803},\\\"AUC\\\":{\\\"Model A\\\":90.034},\\\"Precision\\\":{\\\"Model A\\\":82.266}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "L9D4R-0Q7RQ-0HNL2_37-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"AUC\":5,\"Precision\":4}"
        },
        {
            "id": 38,
            "task_name": "Broadband Sevice Signup",
            "narration": "According to the results table, the learning algorithm employed on this classification problem has high accuracy, recall, and precision equal to 96.58%, 96.78, and 95.72, respectively. The values of these metrics indicate that this algorithm is very accurate and effective at setting apart the test samples from each label. The high precision and recall scores show that even samples drawn from the minority class can be correctly classified.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Precision of 95.72 and (2) achieving a Recall of 96.78.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.585},\\\"Recall\\\":{\\\"Model A\\\":96.783},\\\"Precision\\\":{\\\"Model A\\\":95.721}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "UMQA9-64MB2-MHKWR-38-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5, \"Precision\":5}"
        },
        {
            "id": 39,
            "task_name": "Printer Sales",
            "narration": "From the results, the classification algorithm gains a very high AUC score and accuracy of 94.31 and 86.67, respectively. Furthermore, the model has a precision of 86.49 with an F2-score of 86.49. The data used to train the model is fairly balanced between the classes under consideration; therefore, it is valid to say this classification algorithm can correctly classify the examples with a higher degree of confidence.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, F2-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, AUC, F2-score and Precision. (Your answer should capture the implications of (1) achieving Accuracy of 86.67 and (2) achieving a F2-score of 86.49.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.667},\\\"AUC\\\":{\\\"Model A\\\":94.31},\\\"F2-score\\\":{\\\"Model A\\\":86.486},\\\"Precision\\\":{\\\"Model A\\\":86.486}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "1HJGU-J8@R9-V83HR-39-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"AUC\":5,\"F2-score\":4,\"Precision\":4}"
        },
        {
            "id": 40,
            "task_name": "Basketball Players Career Length Prediction",
            "narration": "The classifier scored an accuracy of 62.99; an F1-score of 58.11; a recall of 50.0, and a precision equal to 69.36 when it comes to the machine learning task under consideration. The scores achieved are moderately low, meaning its effectiveness in terms of assigning labels to new examples is questionable.  Based on the scores of the metrics, it is valid to conclude that the model might fail to correctly predict the label for the majority of samples, especially those from C2.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.99},\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"F1-score\\\":{\\\"Model A\\\":58.108},\\\"Precision\\\":{\\\"Model A\\\":69.355}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "WQU1A-UTVJU-3WBDP_40-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Recall\":2,\"F1-score\":3,\"Precision\":3}"
        },
        {
            "id": 41,
            "task_name": "Broadband Sevice Signup",
            "narration": "As shown in the table, the classifier possesses an accuracy of 93.07%, a precision of 90.61 with a recall equal to 94.41. According to these values, we can say that the model has a high performance with a very low misclassification error rate. This implies that it will be able to generate the correct or true label for the majority of the test samples.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.073},\\\"Recall\\\":{\\\"Model A\\\":94.41},\\\"Precision\\\":{\\\"Model A\\\":90.609}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "LY0EJ-@NQDW-BQP4W_41-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5}"
        },
        {
            "id": 42,
            "task_name": "Vehicle Insurance Claims",
            "narration": "The accuracy, precision, and recall scores achieved by the model on the task were 85.01%, 82.46, and 70.15, respectively. This model is quite cautious with the cases it labels as C2 when you consider recall score (70.15%) and precision score (82.46%). Overall, based on the scores achieved, we draw the conclusion that the model has a high classification performance and it will be able to correctly classify the majority of samples drawn from the different labels under consideration.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of (1) achieving Precision of 82.46 and (2) achieving a Accuracy of 85.0.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.01},\\\"Recall\\\":{\\\"Model A\\\":70.15},\\\"Precision\\\":{\\\"Model A\\\":82.46}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "DAD3L-QBD48-VNNVB_42-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3, \"Precision\":4}"
        },
        {
            "id": 43,
            "task_name": "Mobile Price-Range Classification",
            "narration": "The accuracy of the classifier employed on this multi-class classification problem is 89.4% with the precision and recall equal to 89.42 and recall equal to 89.57, respectively. This classifier boasts a very high classification prowess, and it can correctly tell apart (distinguish between) cases belonging to C1, C2, C3, and C4. In view of the scores above, we can be certain that it will misclassify only a few test examples.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.4},\\\"Precision-score\\\":{\\\"Model A\\\":89.42},\\\"Recall-score\\\":{\\\"Model A\\\":89.57}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "JJ6YA-54BXC-C47TT-43-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall-score\":5,\"Precision-score\":5}"
        },
        {
            "id": 44,
            "task_name": "Job Change of Data Scientists",
            "narration": "This model has marginal precision, recall, and an F1-score of  42.12, 57.09, and 48.48, respectively. In terms of accuracy, the model achieved 77.66%. Assuming the model decides to predict the label C1 for the majority of unseen samples, one can see that only a small number of examples belonging to the other class can be correctly identified. This is because according to the F1-score and precision, the model has a high misclassification error rate for the C2 examples. Given the distribution of the dataset across C1 and C2, we can draw the conclusion that the accuracy score achieved is dominated by most of the correct C1 predictions.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: F1-score, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.662},\\\"Recall\\\":{\\\"Model A\\\":57.089},\\\"F1-score\\\":{\\\"Model A\\\":48.475},\\\"Precision\\\":{\\\"Model A\\\":42.12}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "C9MWJ-8U1KK-BHXTR-44-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"F1-score\":2,\"Precision\":2}"
        },
        {
            "id": 45,
            "task_name": "E-Commerce Shipping",
            "narration": "For the ML task under consideration, this model achieved a classification performance with an accuracy of 67.09; specificity of 82.92; recall of 82.92 with an F1-score of 67.47%. The high specificity score implies that a large portion of examples under C1 are correctly predicted. From the F1-score, we can deduce that the precision is lower than the recall score; hence some of the C1 examples are mislabeled as C2. In summary, we can see that the model is better at correctly predicting the C1 label than the C2 label.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, Specificity and F1-score </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, Specificity and F1-score. (Your answer should capture the implications of (1) achieving Specificity of 56.02 and (2) achieving a Accuracy of 67.09.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.091},\\\"Recall\\\":{\\\"Model A\\\":82.916},\\\"Specificity\\\":{\\\"Model A\\\":56.025},\\\"F1-score\\\":{\\\"Model A\\\":67.466}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "WBDFR-C88JQ-5NJPW-45-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":4,\"F1-score\":3,\"Specificity\":3}"
        },
        {
            "id": 46,
            "task_name": "Flight Price-Range Classification",
            "narration": "Concerning the ML task, the model achieved a classification performance with an F2-score of 67.48%, a precision of 72.83%, a recall of 68.25, and an accuracy of 77.09%.  The model's confidence when it comes to the positive class predictions is moderately high. Overall based on these evaluation scores, we can see that the model has a moderate performance in terms of predicting the true labels for the majority of the test samples.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, F2-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 77.09 and (2) achieving a Recall of 68.25.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.087},\\\"Recall\\\":{\\\"Model A\\\":68.249},\\\"F2-score\\\":{\\\"Model A\\\":67.478},\\\"Precision\\\":{\\\"Model A\\\":72.834}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belonging to class C1, 39.81% belonging to class C2 and 20.16% belonging to class C3.",
            "redeem_code": "CRJU7-3NWUB-5L075_46-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"F2-score\":3,\"Precision\":3}"
        },
        {
            "id": 46,
            "task_name": "Flight Price-Range Classification",
            "narration": "This is a multi-class classification problem where a given test observation is labeled as either C1 or C2 or C3. The learning algorithm trained on this task scored 89.83% precision score, 91.56% recall score, and 97.15% predictive accuracy. As shown, these scores are all high, suggesting that the classifier can accurately label a large proportion of test cases drawn from any of the three-class labels.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, F2-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 77.09 and (2) achieving a Recall of 68.25.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.15},\\\"Recall\\\":{\\\"Model A\\\":91.56},\\\"Precision\\\":{\\\"Model A\\\":89.83}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belonging to class C1, 39.81% belonging to class C2 and 20.16% belonging to class C3.",
            "redeem_code": "CRJU7-3NWUB-5L075_46-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5}"
        },
        {
            "id": 46,
            "task_name": "Flight Price-Range Classification",
            "narration": "Looking at the metrics scores table, the ML algorithm attained a moderate classification performance with an F2-score equal to 67.48%; a recall of 68.25%, a precision of 72.83%  with an accuracy score of 77.09%. In terms of predicting the true labels for the majority of the test samples from the different labels (C1, C2, and C3), these moderate scores suggest the algorithm employed will likely misclassify only a small portion of all possible test cases or instances.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, F2-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 77.09 and (2) achieving a Recall of 68.25.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.087},\\\"Recall\\\":{\\\"Model A\\\":68.249},\\\"F2-score\\\":{\\\"Model A\\\":67.478},\\\"Precision\\\":{\\\"Model A\\\":72.834}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belonging to class C1, 39.81% belonging to class C2 and 20.16% belonging to class C3.",
            "redeem_code": "CRJU7-3NWUB-5L075_46-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"F2-score\":3,\"Precision\":4}"
        },
        {
            "id": 47,
            "task_name": "Hotel Satisfaction",
            "narration": "The table shows that the model has a classification performance score of 93.87% as its accuracy, 93.15% as the recall score with a precision equal to 92.74%. The model also has a near-perfect AUC score of 98.57%.  We can conclude based on the scores achieved across the different metrics that the model is very effective and can correctly classify the majority of the test samples drawn randomly from any of the classes under consideration. This is evident by the very low false-positive and false-negative rates.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.874},\\\"Recall\\\":{\\\"Model A\\\":93.15},\\\"AUC\\\":{\\\"Model A\\\":98.57},\\\"Precision\\\":{\\\"Model A\\\":92.742}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WUG5Q-BUAKY-AB8PK-47-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":5}"
        },
        {
            "id": 48,
            "task_name": "Hotel Satisfaction",
            "narration": "The prediction accuracy of the model in terms of telling-apart the observations belonging to the classes under consideration is equal to 82.7. Besides, it boasts  AUC, recall, and precision scores of 88.67, 77.52, and 84.66, respectively. With its somewhat moderate accuracy, recall, AUC, and precision scores, we could see the model being good at effectively predicting the correct labels for most of the test examples.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.705},\\\"Recall\\\":{\\\"Model A\\\":77.523},\\\"AUC\\\":{\\\"Model A\\\":88.668},\\\"Precision\\\":{\\\"Model A\\\":84.663}}\"",
            "deleted": false,
            "date_submitted": "25/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "RAEX6-GE6RU-8AN18-48-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"AUC\":4,\"Precision\":4}"
        },
        {
            "id": 49,
            "task_name": "Real Estate Investment",
            "narration": "The predictive accuracy of about 85.78% was achieved by the model on the machine learning task under consideration. Furthermore, the recall, precision, and AUC equal 92.86, 46.43, and 91.96, respectively, as shown in the table. Based on the accuracy, recall, and AUC scores, we could conclude that the model has a relatively high classification performance. However, looking at the precision score, there are concerns about the model having a high false-positive rate. This implies most of the C2 predictions are false.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.78},\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"AUC\\\":{\\\"Model A\\\":91.96},\\\"Precision\\\":{\\\"Model A\\\":46.43}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "@FATG-K7P6D-RT0DW_49-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":2}"
        },
        {
            "id": 50,
            "task_name": "Used Cars Price-Range Prediction",
            "narration": "Based on the results in the table, we can see that the model achieved a recall of 92.25 with the F1-score and precision, respectively, equal to 91.18 and 90.14. Besides, the accuracy of the model is 91.37. The scores achieved across these metrics indicate that the model is very confident about its prediction decisions since it has a very little misclassification error rate.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Recall, F1-score and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.373},\\\"Recall\\\":{\\\"Model A\\\":92.254},\\\"F1-score\\\":{\\\"Model A\\\":91.183},\\\"Precision\\\":{\\\"Model A\\\":90.138}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "EW5L3-RL4C1-XPC0G-50-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"F1-score\":4,\"Precision\":5}"
        },
        {
            "id": 51,
            "task_name": "Annual Income Earnings",
            "narration": "Across the evaluation metric scores, as shown in the table, the model's prediction accuracy is about 85.1%, F1-score of 65.31, an AUC of 90.02%, and precision of 61.47%. Considering the scores and the distribution of the dataset across the class labels, we can say that the model has a somewhat low performance since it might be failing at correctly classifying some of the samples, especially those belonging to class C2.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, F1-score, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.1},\\\"F1-score\\\":{\\\"Model A\\\":65.31},\\\"AUC\\\":{\\\"Model A\\\":90.02},\\\"Precision\\\":{\\\"Model A\\\":61.47}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "0P543-A0TRP-TMDQW-51-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"AUC\":5,\"F1-score\":3,\"Precision\":3}"
        },
        {
            "id": 52,
            "task_name": "Tic-Tac-Toe Strategy",
            "narration": "The classification algorithm employed got a very high accuracy of 93.06%, precision, F1-score, and an AUC score of 79.59%, 88.64%, and 99.29%, respectively. It was trained to assign a label (either C1 or C2) to any given case or observation. A possible conclusion on the overall performance of this model is that it has a fairly high classification performance or capability as it is able to classify the majority of test samples presented.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, F1-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, AUC, F1-score and Precision. (Your answer should capture the implications of (1) achieving Precision of 79.59 and (2) achieving a AUC of 99.29.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.06},\\\"AUC\\\":{\\\"Model A\\\":99.291},\\\"F1-score\\\":{\\\"Model A\\\":88.64},\\\"Precision\\\":{\\\"Model A\\\":79.59}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "KKFGT-F3Q7H-K47@D-52-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"AUC\":5,\"F1-score\":5,\"Precision\":4}"
        },
        {
            "id": 53,
            "task_name": "Vehicle Insurance Claims",
            "narration": "From the results table, we can see that the model's predictive accuracy is equal to about 77.0% with the associated precision and recall scores equal to 64.1% and 43.86, respectively. Judging by the distribution of the data across the labels, it is obvious that the accuracy score is less impressive given that it is dominated by the correct C1 predictions. Based on these metrics' scores, we can see that the model has relatively low performance, especially regarding examples belonging to the class label C2.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-2",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":64.103},\\\"Precision\\\":{\\\"Model A\\\":43.86}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "9NHNK-K9KM2-@YRHN_53-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":3,\"Precision\":2}"
        },
        {
            "id": 54,
            "task_name": "Air Quality Prediction",
            "narration": "The ML model achieved 97.88, 97.7, 97.69, and 97.71 across the accuracy, recall, F1-score, and precision evaluation metrics. We can draw the conclusion that this model will be highly effective at correctly classifying most of the test samples. The confidence level of the prediction decision of any of the classes is high. This model solves the underlying ML task very well.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F1-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, F1-score and Precision. (Your answer should capture the implications of (1) achieving Accuracy of 97.88 and (2) achieving a F1-score of 97.69.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-6",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.88},\\\"Recall\\\":{\\\"Model A\\\":97.702},\\\"F1-score\\\":{\\\"Model A\\\":97.692},\\\"Precision\\\":{\\\"Model A\\\":97.705}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "2LV7N-9XM46-7HR@L-54-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"F1-score\":4,\"Precision\":5}"
        },
        {
            "id": 55,
            "task_name": "Car Acceptability Valuation",
            "narration": "The algorithm's classification performance on this AI problem or task is summarized by the following evaluation scores: (a) An accuracy of 94.51%; (b) An AUC score of 99.1%; (c) A recall of 90.2%; (d) A precision of 91.09%. According to these scores, we can say that this model will be very effective at predicting the true labels of the majority of the test samples or examples with only a little chance of error. In simple terms, the algorithm solves the ML task quite well and will assign the wrong label on a few occasions.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, AUC and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. (Your answer should capture the implications of (1) achieving AUC of 99.1 and (2) achieving a Precision of 91.09.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.509},\\\"Recall\\\":{\\\"Model A\\\":90.196},\\\"AUC\\\":{\\\"Model A\\\":99.099},\\\"Precision\\\":{\\\"Model A\\\":91.089}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "HWWTJ-H72TV-8B22N-55-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":5}"
        },
        {
            "id": 56,
            "task_name": "Credit Risk Classification",
            "narration": "On the ML classification task under consideration, the model achieved has a prediction accuracy, precision, F1-score, and specificity of 88.89%, 86.96, 89.95, and 92.61, respectively. Overall, we can conclude that this model will be somewhat good at predicting the true classes for the examples especially those drawn from the class label C1. However, based on the accuracy score and F1-score we can see that it might not be as good at classifying samples belonging to the class label C2.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.889},\\\"Specificity\\\":{\\\"Model A\\\":92.607},\\\"F1-score\\\":{\\\"Model A\\\":86.957},\\\"Precision\\\":{\\\"Model A\\\":89.947}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "BGENT-06PAP-3Q98Y-56-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Specificity\":5,\"F1-score\":4,\"Precision\":5}"
        },
        {
            "id": 57,
            "task_name": "E-Commerce Shipping",
            "narration": "On the given ML problem/task, the model achieved a recall of 82.92, an accuracy of 67.09, specificity of 56.02 with the F1-score equal to 67.47. The scores above indicate that this model will be less powerful in terms of predicting the true or actual label of the sample drawn randomly from any of the classes. Furthermore, the false positive rate will likely be high as indicated by the marginal F1-score achieved.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-3",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.091},\\\"Recall\\\":{\\\"Model A\\\":82.916},\\\"Specificity\\\":{\\\"Model A\\\":56.025},\\\"F1-score\\\":{\\\"Model A\\\":67.466}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":4,\"Specificity\":2,\"F1-score\":3}"
        },
        {
            "id": 58,
            "task_name": "Ethereum Fraud Detection",
            "narration": "The model attains a recall, AUC, accuracy and precision scores of 93.9%, 98.01%, 95.84% and 87.1%, respectively after being trained on this ML problem. With an almost perfect AUC, AUC, accuracy  and recall  scores,  we can say that  the model will be highly effective at assigning the class labels to several test observations. It has a lower misclassification error.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Recall\\\":{\\\"Model A\\\":93.901},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Precision\\\":{\\\"Model A\\\":87.10}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "6VA5J-WTMVN-RR865_58-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "id": 59,
            "task_name": "Student Job Placement",
            "narration": "Concerning the classification problem, this model netted an AUC score of 92.25 with an accuracy of 83.72. Furthermore, the precision and recall scores, respectively, are 77.78 and 95.46. Judging from the AUC and Recall scores, we can say this model is somewhat effective as it will be able to separate the examples under the class labels. However, it has a misclassification rate close to <acc_diff>.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 83.72 and (2) achieving a AUC of 92.24.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.721},\\\"AUC\\\":{\\\"Model A\\\":92.25},\\\"Recall\\\":{\\\"Model A\\\":95.455},\\\"Precision\\\":{\\\"Model A\\\":77.778}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "N7VPD-0WLQU-0@XN3-59-APC",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "id": 60,
            "task_name": "Australian Credit Approval",
            "narration": "On this problem, the model bagged a recall, accuracy, AUC and  precision scores of 74.6, 84.06, 92.21 and 88.68, respectively. The model has a relatively moderate performance as it is shown to be able to be good at assigning the correct labels to the samples as indicated by the AUC and accuracy. Considering the scores for the precision and recall, it will be safe to say the model has a low false positive rate.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "nb_models": 1,
            "model_name": "Model-1",
            "narrator": 45,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":84.058},\\\"Recall\\\":{\\\"Model A\\\":74.603},\\\"AUC\\\":{\\\"Model A\\\":92.209},\\\"Precision\\\":{\\\"Model A\\\":88.679}}\"",
            "deleted": false,
            "date_submitted": "28/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "KE4YB-@REWA-CB37T_60-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"AUC\":5,\"Recall\":3,\"Precision\":4}"
        },
        {
            "id": 120,
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.705},\\\"Recall\\\":{\\\"Model A\\\":77.523},\\\"AUC\\\":{\\\"Model A\\\":88.668},\\\"Precision\\\":{\\\"Model A\\\":84.663}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "7PRR1-G2QAN-W48U9-24-APC",
            "nb_models": 1,
            "task_name": "Hotel Satisfaction",
            "narration": "Considering accuracy, precision, recall and AUC, we can say that this model has high performance in terms of predicting the correct class labels for most of the test examples. Based on the level of accuracy, we can conclude that this model can be trusted to make some misclassifications.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Accuracy of 82.705. </li> <li> What is the implication of Model A achieving a AUC of 88.668? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"AUC\":4,\"Precision\":4}"
        },
        {
            "id": -35,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.585},\\\"Recall\\\":{\\\"Model A\\\":96.783},\\\"Precision\\\":{\\\"Model A\\\":95.721}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "NTF@A-P3PVB-V0KTA-34-APC",
            "nb_models": 1,
            "task_name": "Broadband Sevice Signup",
            "narration": "Overall, the model's accuracy is 96.58, with precision and recall equal to 95.72 and 96.78, respectively. The classification accuracy and recall scores indicate a low misclassification error rate for the model. Therefore, it is almost certain that the model can effectively predict the correct class for a particular test case or instance.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of (1) achieving Recall of 96.783 and (2) achieving a Accuracy of 96.585 </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5}"
        },
        {
            "id": -36,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.59},\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Precision\\\":{\\\"Model A\\\":95.72}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "NTF@A-P3PVB-V0KTA-34-APC",
            "nb_models": 1,
            "task_name": "Broadband Sevice Signup",
            "narration": "Overall, the accuracy of the model is 96.59, with a precision and recall equal to 95.72 and 96.78, respectively. Classification accuracy and recall results indicate a low misclassification error rate for the model. Therefore, it is almost certain that the model can effectively predict the correct class for any given test observation.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of (1) achieving Recall of 96.783 and (2) achieving a Accuracy of 96.585 </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5}"
        },
        {
            "id": -37,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Precision\\\":{\\\"Model A\\\":89.95}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "KFH@C-TC@DR-GW23H-33-APC",
            "nb_models": 1,
            "task_name": "Credit Risk Classification",
            "narration": "The classifier secured a precision of 89.95, a sensitivity score of 92.61, an F1-score of 86.96 and an accuracy of 88.89. According to these metric scores, the model can generate the correct class labels with a higher level of confidence.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Specificity\":5,\"F1-score\":4,\"Precision\":4}"
        },
        {
            "id": -38,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.889},\\\"Specificity\\\":{\\\"Model A\\\":92.607},\\\"F1-score\\\":{\\\"Model A\\\":86.957},\\\"Precision\\\":{\\\"Model A\\\":89.947}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "KFH@C-TC@DR-GW23H-33-APC",
            "nb_models": 1,
            "task_name": "Credit Risk Classification",
            "narration": "Trained to sort out the examples belonging to the label C2 from that of C1, the model attained a sensitivity score of 92.61, a precision of 89.95, an F1-score of 86.96 and an accuracy of 88.89. Based on these metric scores, one can conclude that the model can generate the correct class labels with a higher level of confidence.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Specificity\":5,\"F1-score\":4,\"Precision\":5}"
        },
        {
            "id": -39,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.583},\\\"AUC\\\":{\\\"Model A\\\":73.62},\\\"F1-score\\\":{\\\"Model A\\\":45.161},\\\"Precision\\\":{\\\"Model A\\\":42.857}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "HG1VB-UQANP-GTP8A-26-APC",
            "nb_models": 1,
            "task_name": "Tic-Tac-Toe Strategy",
            "narration": "For the task under consideration, the model achieved  an AUC score of 73.62, an accuracy of 64.58,  with a lower F1-score and a precision score of 45.16 and 42.86, respectively. Judging on the basis of the scores above, we can conclude that this model has slightly lower performance as it will not be able to accurately predict the actual labels of a large number of test samples.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"AUC\":3,\"F1-score\":2,\"Precision\":2}"
        },
        {
            "id": -40,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.583},\\\"AUC\\\":{\\\"Model A\\\":73.62},\\\"F1-score\\\":{\\\"Model A\\\":45.161},\\\"Precision\\\":{\\\"Model A\\\":42.857}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "HG1VB-UQANP-GTP8A-26-APC",
            "nb_models": 1,
            "task_name": "Tic-Tac-Toe Strategy",
            "narration": "When it comes to the classification task under consideration, the model achieves an AUC score of 73.62, an accuracy of 64.58 with a lower F1-score, and an accuracy score of 45.16 and 42.86, respectively. Based on these metrics' scores, we can conclude that this model has demonstrates lower performance as it is not be able to accurately predict the true labels of multiple test examples.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"AUC\":3,\"F1-score\":2,\"Precision\":2}"
        },
        {
            "id": -28,
            "narrator": 45,
            "model_name": "Model-7",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":70.45},\\\"Recall\\\":{\\\"Model A\\\":59.69},\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":62.10}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "8@346-DMPTW-KXT44_28-APC",
            "nb_models": 1,
            "task_name": "Basketball Players Career Length Prediction",
            "narration": "This model has an accuracy of 70.45% with moderate precision and recall  scores of 62.1% and 59.69%, respectively. Based on the scores of the different metrics under consideration, we can conclude that the model performs slightly poorly in terms of correctly classifying the examples belonging to the class C2 label.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F1-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, F1-score and Precision. (Your answer should capture the implications of (1) achieving Recall of 59.69 and (2) achieving a F1-score of 60.87 </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"Precision\":3 ,\"F1-score\":3}"
        },
        {
            "id": -29,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.01},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.10}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "1XKE1-AP2MT-Q6KYR-29-APC",
            "nb_models": 1,
            "task_name": "Mobile Price-Range Classification",
            "narration": "On the given multi-class ML problem, the goal is to assign a given test case the true label either C1 or C2 or C3 or C4. The classifier or model achieved 96.01% prediction accuracy and high recall and precision scores of about 96.1% and 95.98%, respectively. With such higher scores across the various metrics, we can be assured that the model will be able to predict the correct class labels of most test examples. In other words, it would be safe to say that the model has almost perfect performance with a very marginal classification error rate.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Precision-score and Recall-score. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall-score\":5,\"Precision-score\":5 }"
        },
        {
            "id": -29,
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.03},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "1XKE1-AP2MT-Q6KYR-29-APC",
            "nb_models": 1,
            "task_name": "Mobile Price-Range Classification",
            "narration": "The  model achieved 96.03% accuracy score, a high recall of 96.08% and a precision score of 95.98% on the ML task under consideration. Considering such high scores across these metrics, we can be certain that the model will be able to predict the correct class labels for the majority of test samples. That is,  the model possesses almost perfect performance with a very low classification error rate.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Precision-score and Recall-score. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall-score\":5,\"Precision-score\":5 }"
        },
        {
            "id": -23,
            "narrator": 45,
            "model_name": "Model-2",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.27},\\\"Recall\\\":{\\\"Model A\\\":76.214},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "CV9HD-63TXB-PPEEP-23-APC",
            "nb_models": 1,
            "task_name": "Wine Quality Prediction",
            "narration": "The algorithm earns a relatively moderate performance as reflected in the recall, precision and accuracy scores. This model can correctly classify a reasonable number of cases. With an precision of about 73.71%, the model is shown to have a somewhat low false-positive rate. Finally based on the accuracy score we can conclude that the model correctly classifies about 74.27% of all test cases.",
            "narrative_question": "<li> In not less than two sentences summarize the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. </li> <li> In a sentence, summarize the implication of the model achieving Precision of 73.71%. </li> <li> What is the implication of Model A achieving a Accuracy of 74.27? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"Precision\":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.373},\\\"Recall\\\":{\\\"Model A\\\":92.254},\\\"F1-score\\\":{\\\"Model A\\\":91.183},\\\"Precision\\\":{\\\"Model A\\\":90.14}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "0UH7E-VN2VX-CDL@8-22-APC",
            "nb_models": 1,
            "task_name": "Used Cars Price-Range Prediction",
            "narration": "The accuracy, precision, recall achieved by this model are 91.37, 90.14 and 92.25, respectively. Given the precision and recall, we can also see that the model commands an F1-score of about 91.18%. Based on these metrics' scores, it is valid to conclude that this model will be highly effective in terms of  producing the correct label of most test cases. It has a very low misclassification error rate.",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.10",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5,\"F1-score\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"AUC\\\":{\\\"Model A\\\":94.31},\\\"F2-score\\\":{\\\"Model A\\\":86.49},\\\"Precision\\\":{\\\"Model A\\\":86.42}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "1HJGU-J8@R9-V83HR-39-APC",
            "nb_models": 1,
            "task_name": "Printer Sales",
            "narration": "From the evaluation results, the model holds an AUC score and an accuracy of 94.31% and 86.67%, respectively. In addition, the model has a precision of 86.42% with an F2-score of 86.49%. The data used to train the model is somewhat balanced between the classes under consideration so it is valid to say that this model can properly classify the test samples with greater confidence.",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, F2-score and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, AUC, F2-score and Precision. (Your answer should capture the implications of (1) achieving Accuracy of 86.67 and (2) achieving a F2-score of 86.49.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"AUC\":5,\"Precision\":4,\"F2-score\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-4",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.59},\\\"Recall\\\":{\\\"Model A\\\":96.783},\\\"Precision\\\":{\\\"Model A\\\":95.721}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "UMQA9-64MB2-MHKWR-38-APC",
            "nb_models": 1,
            "task_name": "Broadband Sevice Signup",
            "narration": "The classifier secured high scores for the metrics accuracy, recall and precision. These scores are 96.59%, 96.78% and 95.72%, respectively. The values of these metrics show that this model is very accurate and effective in sorting out examples from various class labels. High precision and recall scores indicate that samples extracted from minority class labels can also be correctly classified.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Precision of 95.72 and (2) achieving a Recall of 96.78.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5 }"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":61.28},\\\"Sensitivity\\\":{\\\"Model A\\\":48.39},\\\"Specificity\\\":{\\\"Model A\\\":66.38},\\\"F1-score\\\":{\\\"Model A\\\":41.48}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "U1V2R-EMCEB-DJV7Y_36-APC",
            "nb_models": 1,
            "task_name": "Water Quality Classification",
            "narration": " 61.28 (accuracy), 48.39 (sensitivity), 66.38 (specificity), and F1-score (41.48) are the evaluation scores attained by the model when trained on this binary classification problem or task where a given test observation or case is assigned the label either C1 or C2. Considering the scores above, it can be concluded that the classifier is not effective enought when separating the test cases that belong to the minority class label.",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Sensitivity, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Specificity of 66.383 and (2) achieving a Accuracy of 61.28.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":2,\"Sensitivity\":2,\"Specificity\":3,\"F1-score\":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-2",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.53},\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"AUC\\\":{\\\"Model A\\\":94.50},\\\"Precision\\\":{\\\"Model A\\\":85.561}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0GALK-D6G@P-9UNJW-35-APC",
            "nb_models": 1,
            "task_name": "Bike Sharing Demand",
            "narration": "As shown in the table, the model achieved high performance with an accuracy of 86.53, an AUC of 94.50. Furthermore, it achieved a high  recall (87.03) and  precision (85.56). The results obtained suggest that this model can segregate test examples from the class under consideration with a misclassification rate of less than <acc_diff>.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall, AUC and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-1",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.721},\\\"AUC\\\":{\\\"Model A\\\":92.25},\\\"Recall\\\":{\\\"Model A\\\":95.46},\\\"Precision\\\":{\\\"Model A\\\":77.778}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "N7VPD-0WLQU-0@XN3-59-APC",
            "nb_models": 1,
            "narration": "On the given classification problem, this classifier achieved an AUC score of 92.25 with an accuracy of 83.72. In addition, the precision and recall scores are, respectively, 77.78 and 95.46. Judging from the AUC and Recall scores, we can make the conclusion that this model is quite effective as it will be able to pick the  true class labels. However, it has a misclassification rate close to <acc_diff>.",
            "task_name": "Student Job Placement",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 83.72 and (2) achieving a AUC of 92.25.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-1",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.72},\\\"AUC\\\":{\\\"Model A\\\":92.25},\\\"Recall\\\":{\\\"Model A\\\":95.46},\\\"Precision\\\":{\\\"Model A\\\":77.78}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "N7VPD-0WLQU-0@XN3-59-APC",
            "nb_models": 1,
            "narration": "On the classification problem under consideration, this model achieved  an accuracy of 83.72 with an AUC score of 92.25. Moreover, the precision and recall scores are 77.78 and 95.46, respectively. Judging from AUC and Recall scores, we can conclude that this model is a little effective as it can differentiate between class labels with the misclassification error rate close to <acc_diff>.",
            "task_name": "Student Job Placement",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving Accuracy of 83.72 and (2) achieving a AUC of 92.25.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":5,\"AUC\":5,\"Precision\":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-1",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Recall\\\":{\\\"Model A\\\":93.902},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Precision\\\":{\\\"Model A\\\":87.10}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "6VA5J-WTMVN-RR865_58-APC",
            "nb_models": 1,
            "narration": "The model got recall, precision, accuracy and AUC scores of 93.9, 87.1, 95.84 and 98.01,  respectively on the given ML problem. Based on near-perfect  AUC, accuracy, and recall scores, we can be sure that the model will be effective in interms of  differentiating examples from the classes with minor misclassification error.",
            "task_name": "Ethereum Fraud Detection",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-1",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Recall\\\":{\\\"Model A\\\":93.90},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Precision\\\":{\\\"Model A\\\":87.10}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "6VA5J-WTMVN-RR865_58-APC",
            "nb_models": 1,
            "narration": "The classifier boasts very high values for the recall, precision, accuracy, and AUC metrics (i.e 93.9, 87.1, 95.84, and 98.01, respectively). Judging by the near-perfect AUC, accuracy, and recall scores, we can be confident that the model will be very effective at predicting the true class labels for the test cases with little chance of misclassification.",
            "task_name": "Ethereum Fraud Detection",
            "narrative_question": "<li> In a sentence, summarize the scores achieved by Model A across the different metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"AUC\":5,\"Precision\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"Specificity\\\":{\\\"Model A\\\":56.03},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "With respect to the machine learning problem being analyzed, the model achieved a prediction accuracy of 67.09%, a specificity of 56.03, a recall of 82.92, and an F1-score of 67.47. From on these scores achieved across the metrics, a valid possible conclusion is that this model will not be as effective at predicting the true label of the sample drawn at random from any of the classes. In addition, it has a high false positive rate as indicated by the marginal F1-score achieved.",
            "task_name": "E-Commerce Shipping",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"F1-score\":3,\"Specificity\":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "An imbalance-trained model has a very low performance score when predicting target class C2, resulting in a very low precision score of 34.14%. A high accuracy score of 90.46% only indicates that the dataset is very unbalanced. A recall score of 66.92% is a better indicator that this model will not be effective in predicting the target class.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":90.46},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Precision\\\":{\\\"Model A\\\":34.14}}\"",
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"1\",\"Recall\":\"2\",\"AUC\":\"4\"}"
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 43,
            "narration": "For this ML problem, the model's recall score is 71.74% and the precision score is 57.9%. In addition, it has an accuracy of 81.5%. Based on the above scores, the model shows fairly moderate classification performance. There is a high probability of misclassifying a large number of test samples extracted from class C2.",
            "metrics_values": "\"{\\\"Accuracy\\\": {\\\"Model A\\\": 81.5 },\\\"Recall\\\": {\\\"Model A\\\": 71.739},\\\"Precision\\\": {\\\"Model A\\\": 57.895}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "JM18F-9N8UX-FM0H6_43-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"2\",\"Recall\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 57.9 and Recall of 71.74. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 36,
            "narration": "The classifier's classification performance is summarized by the following metrics' scores: (a) AUC: 84.46%. (b) Accuracy: 87.11%. (c) Precision: 40.82%. (d) Recall: 83.33%. The lower precision of the model indicates that the model tends to predict the negative class (C1). This is to be expected and remains a challenge when dealing with imbalances in large datasets where <|majority_dist|> of the data belongs to class C1. This bias means that the performance of the model is worse than what an 87.11% reasonably high accuracy or 84.46% AUC suggests.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.816}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 36,
            "narration": "The classifier trained to solve the given ML task achieved the following performance evaluation scores: (a) Precision: 40.82%.  (b) AUC: 84.46%.  (c) Accuracy: 87.11%. (d) Recall: 83.33%. The model's low precision score indicates that the model tends to be good at predicting the negative class (C1). This was to be expected and remains a challenge when dealing with imbalances in large datasets, where <|majority_dist|> of the data belongs to class C1. This bias means that the model performs worse than a reasonably high accuracy of 87.11% or AUC of 84.46% suggests.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.816}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 37,
            "narration": "73.5% for AUC, 72.0% for accuracy, 60.47% for sensitivity, and 32.91% for precision are the evaluation scores achieved by the model on the ML task under consideration. The very low precision with moderate sensitivity, suggests that the model has a bias to predict the positive class, C2, which is also the minority class with <|minority_dist|> of examples in the dataset. Despite this, the model achieves a reasonable AUC of 73.5%, showing some degree of understanding the given machine learning task.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":72.0},\\\"Sensitivity\\\":{\\\"Model A\\\":60.465},\\\"AUC\\\":{\\\"Model A\\\":73.499},\\\"Precision\\\":{\\\"Model A\\\":32.911}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "XGT6Y-BJ0YV-4MV4L_37-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Sensitivity, Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 82,
            "narration": "The scores obtained by the model in the classification question are as follows: (a) 67.09% accuracy. (b) The specificity score is 56.02%. (c) Recall 82.92%. (d) F1-score 67.47%. These results indicate that the model has poor predictive power based on the fact that the dataset was imbalanced. Based on the F1-score  and recall scores, we can see that the precision score of this model is low hence the false positive rate might be higher than expected. Therefore, in most cases, it might not be effective at correctly identify examples under the C2 class.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "WBBV0-6LQXX-RHK19-82-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"3\",\"Recall\":\"4\",\"F1-score\":\"2\",\"Accuracy\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 83,
            "narration": "For this ML task, evaluation of the  model's performance produced the scores 55.56% for the precision with a moderate F1-score of 60.87%. Furthermore, it scored 66.91% for the  accuracy metric. Based on the scores above, the model is relatively less confident in terms of its prediction decision for the majority of the test cases. ALso from  the precision score, it is valid to say the model will have a somewhat high false positive rate than expected.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":55.56},\\\"Accuracy\\\":{\\\"Model A\\\":66.91}}\"",
            "deleted": false,
            "date_submitted": "13/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "AF0DK-KVV7A-P7F3F-83-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, F1-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 66.91 and F1-score of 60.87. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 82,
            "narration": "The scores achieved by the classifier on this artificial intelligence (AI) problem  are:   67.09% (accuracy), recall/sensitivity score of 82.92%, Specificity score of 56.02%,  and a moderate F1-score of 67.47%. Based on the fact that the model was trained on an imbalanced dataset, these results indicate the model has a close to weak predictive power. From the recall and F1-score, we can make the conclusion that this model has a low precision hence will have a some instances falling under the false positive category. Therefore in most cases, it will fail  to correctly identify the examples belonging to the minority class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "WBBV0-6LQXX-RHK19-82-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"3\",\"Recall\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 78,
            "narration": "For this classification problem, the trained model was evaluated according to their scores across the following evaluation metrics:  Recall, Precision, F1-score, and Accuracy. For the accuracy, the model attained 96.53%, for the precision it scored 91.43% with the recall score equal to 80.03%. From to the precision and recall scores, we can verify that the model has F1-score of about 85.33%. For a model trained on an imbalanced dataset, these scores are quite impressive. It has a lower false-positive rate (as shown by comparing the precision and recall scores) hence the confidence in prediction decisions related to the minority class label C2, is very high.  The accuracy is usually not important when dealing with such severely imbalanced data, however, it offers some form of support to the claims made here about the confidence level of the model's output predictions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":80.03},\\\"F1-score\\\":{\\\"Model A\\\":85.33},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":96.53}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "LVLQW-HA20W-DX54K-78-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 64,
            "narration": "The ML model has an accuracy of 89.74% with an AUC score of about 89.13%. As a model trained on an imbalanced dataset, irrespective of the high scores across the AUC and accuracy, the metrics of higher interest when analysing the model's prediction power for this problem are: the sensitivity (also known as the recall) and the precision scores. For these two metrics, the model achieved 65.22% (precision) and 78.95% (sensitivity).   Judging by these scores, it ok to conclude that it performed moderately well at classifying examples/samples from both class labels. There is some sort of a fair balance between its recall (sensitivity)  and precision which indicate how good and useful the model could be.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.13},\\\"Accuracy\\\":{\\\"Model A\\\":89.74},\\\"Precision\\\":{\\\"Model A\\\":65.22},\\\"Sensitivity\\\":{\\\"Model A\\\":78.95}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "WP0XW-UW7C1-210RB-64-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Sensitivity and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 55,
            "narration": "From the evaluation metrics table shown, the classication model trained on the given ML task scored 62.98% (accuracy), 50.01% (recall or sensitivity),  and 69.36% (precision). From the recall and precision, we can verify that the model has  an F1-score of 58.11%. Even though the model was trained on an imbalanced data, we can say that the model might find it difficult to accurately or correctly identify the labels for test cases drawn randomly from any the class labels. According to the accuracy, its performance is not that different from the dummy model always assigning the same class label C1 to any given test sample/case.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.36},\\\"Recall\\\":{\\\"Model A\\\":50.01},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Accuracy\\\":{\\\"Model A\\\":62.98}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "9V2TG-4J0M5-UHY68_55-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"2\",\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, F1-score, Accuracy and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 50.0 and Accuracy of 62.98. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 54,
            "narration": "For the accuracy metric, the model achieved the score of 69.2%,  AUC of 74.06%, Sensitivity(sometime refered to as the Recall) is 51.85%, and a very low precision score of 35.44%. Due to the fact the model being trained on an imbalanced dataset, only the recall and precision scores are important and judging by the scores attained, it is safe to say this model performs poorly on the classification problem. It has a very high false positive  rate hence will find it difficult to correctly classify input test samples/examples related to the class label C2.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44},\\\"Sensitivity\\\":{\\\"Model A\\\":51.85}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "RE@@2-LBJH8-L6R22_54-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Water Quality Classification",
            "id": 51,
            "narration": "For this machine learning classification task, the model was trained on an imbalanced dataset and the model achieved a Specificity  score of 76.21%, Sensitivity  score equal to 81.25% and F1-score of 63.72%. Besides, it has an Accuracy of 77.44%, Based on the F1-score, specificity and recall we can say the model has a moderate classification performance hence can misclassify some test samples especially those drawn from the class label C2. From the Recall and F1-score, we can estimate the precision score as somewhat low hence the low confidence in the C2 predictions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.44},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "B4PHL-6Y4AH-VUJ0G-51-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Specificity, Sensitivity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 63.72 and Sensitivity of 81.25. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 118,
            "narration": "Regarding the ML problem under study, the model scored highly across all evaluation metrics. For precision, it scored 95.98%, 96.0% for accuracy score, and 96.08% for recall (sensitivity) score. It is fair to say that the performance of this model is very impressive and the chances of misclassification of the majority of test cases is very low.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Broadband Sevice Signup",
            "id": 116,
            "narration": "On this imbalanced classification problem, this model has an accuracy of 96.58%,  a precision score and a recall score equal to 95.72% and 96.78%, respectively. Based on the scores obtained, we can conclude that the classification performance of this model is very high and will be very effective in predicting the labels correctly for most test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Precision\\\":{\\\"Model A\\\":95.72},\\\"Accuracy\\\":{\\\"Model A\\\":96.58}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "Y7FKM-JE0EL-KY8G3-116-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 115,
            "narration": "The scores obtained by the model on this ML classification problem are: recall (94.12%), accuracy (86.72%), AUC (85.39%) and precision (32.65%). On this kind of ML problem with imbalanced dataset, these scores are lower than expected indicating how poor the model is in terms of correctly picking the correct class labels for most test cases related to the C2 label. The above conclusion or assertion can be drawn only by looking at the recall and precision score together with information on the distribution of the data in the two class labels.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.39},\\\"Accuracy\\\":{\\\"Model A\\\":86.72},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":32.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "MD6TR-AYUX6-@H3RX_115-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Recall\":\"4\",\"AUC\":\"3\",\"Precision\":\"1\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 86.72 and Recall of 94.12. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Airline Passenger Satisfaction",
            "id": 114,
            "narration": "Trained on a somewhat balanced dataset, the model scores 93.2% (accuracy), 93.12% (recall), 97.91% (AUC), and 91.26% (precision score). These results/scores are very impressive as it can be concluded or asserted that this model is almost perfect with high confidence in its prediction decisions across the majority of test cases. In short, only a few test cases are likely to be misclassified, as indicated by the high scores across the precision, recall, and accuracy metrics.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Accuracy\\\":{\\\"Model A\\\":93.2},\\\"Recall\\\":{\\\"Model A\\\":93.12},\\\"Precision\\\":{\\\"Model A\\\":91.26}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
            "redeem_code": "L3800-W0KMY-C14ET_114-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 93.2 and Recall of 93.12. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 110,
            "narration": "The classification performance of the algorithm with reference to the objectives of the given machine learning objective can be summarized as follows: low precision (45.61%), recall (81.25%), and accuracy (81.5%). On such imbalanced dataset, we can conclude that the classification performance of the model is moderately low as the difference between recall and precision indicates that there is a high false positive rate. Hence the predictions related to the  label C2 should be taken with precausion.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":81.25},\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WN6X6-PL20R-937TG-110-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"2\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 37,
            "narration": "Evaluating the performance of the model on this classification task produced the scores: 72.0% for accuracy, 60.47% for sensitivity, 73.5% for AUC, and 32.91% for precision. The very low precision with moderate sensitivity, suggests that the model will likely misclassify samples from C1 as C2 (which is also the minority class with <|minority_dist|> of examples in the dataset). Despite this, the model achieves a reasonable AUC score showing some degree of understanding the classification objective under consideration.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":72.0},\\\"AUC\\\":{\\\"Model A\\\":73.5},\\\"Sensitivity\\\":{\\\"Model A\\\":60.47},\\\"Precision\\\":{\\\"Model A\\\":32.91}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "XGT6Y-BJ0YV-4MV4L_37-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Sensitivity, Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Air Quality Prediction",
            "id": 119,
            "narration": "The classification model has an accuracy of 86.5%, a recall score of about 77.42%, a precision score of 98.36% with an F1-score of 86.64%. The model is shown to be effective at producing the correct class labels for the test cases as indicated by the precision and recall score.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.5},\\\"Precision\\\":{\\\"Model A\\\":98.36},\\\"Recall\\\":{\\\"Model A\\\":77.42},\\\"F1-score\\\":{\\\"Model A\\\":86.64}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "KQPWC-5KAHK-RMBQC_119-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Attrition",
            "id": 108,
            "narration": "On the given ML classification task, The evaluation metrics achieved were as follows: recall (aka sensitivity) score of 83.33; a low precision score of 40.82%; AUC score equal to 84.46%; accuracy: 87.11%. Despite the moderate AUC and accuracy scores, the judgment about the overall performance of the model is based on the recall and precision scores it achieved on the given ML task. From these scores, it is obvious that the model will occasionally misclassify some proportion of samples belonging to C1 as C2 (i.e moderate to high false positive rate).",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":84.46},\\\"Accuracy\\\":{\\\"Model A\\\":87.11},\\\"Precision\\\":{\\\"Model A\\\":40.82},\\\"Recall\\\":{\\\"Model A\\\":83.33}}\"",
            "deleted": false,
            "date_submitted": "17/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "T71EF-PFMTF-PLK9N_108-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Recall\":\"4\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall and Accuracy? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "122.178.27.145",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 27,
            "narration": "An accuracy of 89.12%, with the precision and AUC scores, respectively equal to 82.64% and 96.08% are the scores achieved on the machine learning problem by the classifier. Furthermore, its sensitivity (recall) score is 94.72% indicating the model predicts C2 on many occasions, of which 82.64% (precision score) are correct. The scores show that the model has a very high prediction performance, hence will be able to correctly classify test samples from both class labels C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.12},\\\"Recall\\\":{\\\"Model A\\\":94.718},\\\"AUC\\\":{\\\"Model A\\\":96.082},\\\"Precision\\\":{\\\"Model A\\\":82.642}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0N5G6-CUE9C-BRK8X-27-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and Accuracy? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 15,
            "narration": "The classification model under evaluation boasts an accuracy of 74.27%, a recall (sensitivity) and precision of 76.21% and 73.71%, respectively. The model has a fairly moderate prediction performance as shown by the precision and recall scores. The model is fairly confident when you consider the prediction decisions made for the test samples from the class C1 and the class C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.27},\\\"Recall\\\":{\\\"Model A\\\":76.214},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "TNVHT-JLLKB-056M7-15-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":4,\"Precision\":4}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and Accuracy? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "45.42.190.62",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 8,
            "narration": "The following are the performance metrics scores achieved by the classifier on this binary classification task: Precision score of 55.66%, Accuracy score of 66.91, and F1-score of 60.87% as the performance evaluation scores on this ML task. The model is shown to be fairly good at correctly classifying the majority of test cases as indicated by the precision and accuracy scores.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":66.912},\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":55.556}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "JELP8-2WY1B-LA9J6_8-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"F1-score\":3,\"Precision\":3}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Precision? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "103.245.188.94",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 1,
            "narration": "The table shown contains the scores achieved by the model across the different metrics for the ML problem/task under consideration. For labeling accuracy, the model achieved 75.49% and 77.56% for the recall. Besides, it has a good precision score of 74.65%. According to these values, we can make the conclusion that this classifier will likely be moderately precise in terms of accurately predicting labels for a number of test cases related to any of the classes.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":75.49},\\\"Recall\\\":{\\\"Model A\\\":77.561},\\\"Precision\\\":{\\\"Model A\\\":74.648}}\"",
            "deleted": false,
            "date_submitted": "04/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "9R2WQ-A@0UB-KFBKF_1-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Precision\":4}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of ((1) achieving Accuracy of 75.49 and (2) achieving a Precision of 74.65.) </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 1,
            "narration": "The classifier trained to solve the given classification problem was evaluated based on its scores across the following metrics: accuracy, recall, and precision. For accuracy, the model achieved 75.49% and 77.56% for recall with a moderate precision score of (74.65%). Considering these values, we can draw the conclusion that this model can correctly differentiate between the new examples or cases belonging to any of the classes with a close to moderate chance of misclassification.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":75.49},\\\"Recall\\\":{\\\"Model A\\\":77.561},\\\"Precision\\\":{\\\"Model A\\\":74.648}}\"",
            "deleted": false,
            "date_submitted": "04/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "9R2WQ-A@0UB-KFBKF_1-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"Precision\":3}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (Your answer should capture the implications of ((1) achieving Accuracy of 75.49 and (2) achieving a Precision of 74.65.) </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 0
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 11,
            "narration": "The machine learning algorithm trained on this classification task was evaluated and it achieved a low F1-score of 48.54% with a very low precision of 37.12% and a moderate recall (i.e. the prediction sensitivity) score of 70.12%. The accuracy score of 81.13% is not that impressive as the dummy model assigning the majority class C1 to any given input can achieve close to this performance. The model's overall classification performance is very poor since it achieved lower values/scores for both the precision and F1-score. In summary, confidence in the model's prediction decision related to the minority label C2 is low and should be taken with caution.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.13},\\\"Recall\\\":{\\\"Model A\\\":70.12},\\\"F1-score\\\":{\\\"Model A\\\":48.54},\\\"Precision\\\":{\\\"Model A\\\":37.12}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "N800B-GM71M-BX592_11-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":1,\"Accuracy\":3,\"F1-score\":2,\"Recall\":3}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. You should consider the implications of the model's score across each metric. </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "69.117.241.194",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 147,
            "narration": "This model achieves recall, accuracy, AUC, and precision scores of 79.52%, 86.76%, 90.67%, and a very low 32.16% respectively. A high AUC of 90.67% implies that this model has a good ability to tell apart  samples belonging to the two classes. However, it has high false-positive predictions judging based on  scores achieved for precision and recall.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":32.16},\\\"Recall\\\":{\\\"Model A\\\":79.52},\\\"AUC\\\":{\\\"Model A\\\":90.67},\\\"Accuracy\\\":{\\\"Model A\\\":86.76}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"4\",\"AUC\":\"4\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 157,
            "narration": "On this machine learning classification problem, the model has an an accuracy of 87.74, AUC score of 96.34 with a precision score of 79.22%, and a recall of 95.31%. Based on the recall and precision scores, we can see that the model tends to misclassify a fair number of cases belonging to C1 as C2. Overall, the accuracy and AUC scores suggest the model can accurately identify the true label for a large number of test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"AUC\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":95.31}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "YN6TQ-47EPE-L3662-157-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"5\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Printer Sales",
            "id": 19,
            "narration": "With regards to the model classification objective under consideration, the model has a very high AUC score of 91.07%, a fairly high F2-score of 83.85% with moderate scores for the accuracy (81.33%), and precision (72.97%). From the precision and F2-score, we can estimate that the sensitivity score is high. The high F2-score indicates that the model has a low false-negative rate implying the majority of examples associated with C2 are not being misclassified as C1. However, there would be instances where the prediction output of C2 will be wrong.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.333},\\\"AUC\\\":{\\\"Model A\\\":91.07},\\\"F2-score\\\":{\\\"Model A\\\":83.851},\\\"Precision\\\":{\\\"Model A\\\":72.973}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "67ND1-MG89T-731YD-19-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":3,\"F2-score\":4,\"AUC\":5}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and F2-score? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "193.203.233.44",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Printer Sales",
            "id": 19,
            "narration": "A score of 81.33% for the accuracy, a score of 91.07% for AUC, 83.85% for F2-score and 72.97% for the precision score summarize the prediction performance of classifier trained on this classification objective. The model is shown to be somewhat effective with its prediction decisions. From these scores, we can conclude that this model has a moderate performance and will likely mislabel some test cases belonging to the different classes. The misclassification or mislabeling rate is about <acc_diff>%.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.333},\\\"AUC\\\":{\\\"Model A\\\":91.07},\\\"F2-score\\\":{\\\"Model A\\\":83.851},\\\"Precision\\\":{\\\"Model A\\\":72.973}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "67ND1-MG89T-731YD-19-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":3,\"F2-score\":4,\"AUC\":5}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and F2-score? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "193.203.233.44",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 20,
            "narration": "The performance of the model on this machine learning classification objective as evaluated based on F1-score, accuracy, AUC and precision evaluation metrics. It achieves Accuracy 66.3%, 85.11%, 90.07%, 85.17%, and 63.95%, respectively. These scores are somewhat high indicating that this model is might be effective and can accurately identify most of the test cases with small margin of error. Furthermore, the precision score and F1-score tell us that the output prediction decision relating to C2 might be less accurate.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.11},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95}}\"",
            "deleted": false,
            "date_submitted": "06/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "W4N@N-WAJG1-J38KY-20-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":5,\"F1-score\":3,\"Accuracy\":3,\"Precision\":3}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and AUC? </li>",
            "narrative_status": 2,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "172.219.207.73",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 149,
            "narration": "This model evaluated based on Accuracy, Precision, F1-score and recall scored 75.75%, 55.23%, 63.19% and 51.3%, respectively The scores achieved across the different metrics indicate that this model has a very poor classification performance. Accuracy (75.75%) is only marginally higher than the proportion of the majority class, and precision (55.23%), F1-score (53.19%) and recall (51.3%) are all only marginally better than random choice.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":53.19},\\\"Accuracy\\\":{\\\"Model A\\\":75.75},\\\"Recall\\\":{\\\"Model A\\\":51.3},\\\"Precision\\\":{\\\"Model A\\\":55.23}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "FF36V-0HUPK-26A2Y_149-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"3\",\"F1-score\":\"1\",\"Recall\":\"1\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 152,
            "narration": "The algorithm boasts a very high accuracy of 91.56% with an F1-score of 75.49. The F1-score was computed based on the recall and precision scores of 83.12% and 69.15%, respectively. The accuracy is high but the F1-score is lower than expected. This is not surprising since the precision is lower than the recall, suggesting that the model is making mistakes by giving false positive predictions.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.15},\\\"Accuracy\\\":{\\\"Model A\\\":91.56},\\\"F1-score\\\":{\\\"Model A\\\":75.49},\\\"Recall\\\":{\\\"Model A\\\":83.12}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "EV3YY-JMX87-D9D6G-152-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "2.25.71.194",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 147,
            "narration": "This model achieves recall, accuracy, and precision scores of 77.52%, 82.7%, and 84.66% respectively. These scores support the conclusion that the model is fairly effective in telling apart the examples belonging to the C1 and C2 classes",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 146,
            "narration": "This model achieves recall, accuracy, and precision scores of 77.52%, 82.7%, and 84.66% respectively. A high AUC of 88.67% implies that this model has a good ability to distinguish the positive class and negative class examples, whereas the recall and precision mean that of all members of the target class, this model was able to correctly identify 77.52% of them, of which 84.66% are correctly identified.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":88.67},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Precision\\\":{\\\"Model A\\\":84.66}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "N/A",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 0,
            "date_approved": "01-01-1970",
            "is_paid": 0,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 175,
            "narration": "Overall the model is not considered good as many of the metrics such as F1-score  at 48.48 and precision at 42.12 are considered low, although recall and accuracy are marginally better. We can not considered the resulting classifcation trustworthy and maybe due to the imbalance in data. Although the accuracy of the model is fairly high, this might be a product of the significant skew we are seeing in C1 cases over C2 at <|majority_dist|> and <|minority_dist|> respectively. F1-scores at 48.48% and precision at 42.12 is considered low and worse than classification by random chance. Accuracy of the model at 77.66 is similar to the datasets imbalance split and might not be suggestive of the true accuracy of the model.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":48.48},\\\"Precision\\\":{\\\"Model A\\\":42.12},\\\"Accuracy\\\":{\\\"Model A\\\":77.66},\\\"Recall\\\":{\\\"Model A\\\":57.09}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "51R9M-@28V8-@W9QU-175-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"2\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 0,
            "date_approved": "01-01-1970",
            "is_paid": 1,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 161,
            "narration": "This model performs very well as indicated by the scores of all the evaluation metrics. The dataset used for modeling was balanced supporting no sampling biases by the model. Consequently, the values of 95.67% for the accuracy, precision at 94.16% and recall equal to 97.32% all paint an image of the model is performing very well at classifying C1 and C2  instances/cases accurately and precisely. The AUC at 98.79% suggests an extremely high accuracy in the models predictions of class assignment and is suggestive that the model has a very strong classification ability.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":98.79},\\\"Recall\\\":{\\\"Model A\\\":97.32},\\\"Accuracy\\\":{\\\"Model A\\\":95.67},\\\"Precision\\\":{\\\"Model A\\\":94.16}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "JMLR9-VHXR2-3J88N_161-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 161,
            "narration": "This model has a very high classification performance on the given ML problem or task as shown by the scores achieved across all the evaluation metrics (AUC, recall, accuracy, and precision). The dataset used for modeling was balanced supporting no sampling biases by the model. Hence, the values of 96.92% for the accuracy, precision at 96.82% and recall equal to 92.35% all paint an image of the model is performing very well at classifying C1 and C2  instances/cases accurately and precisely. The AUC at 91.79% suggests an extremely high accuracy in the models predictions of class assignment and is suggestive that the model has a very strong classification ability.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":91.79},\\\"Recall\\\":{\\\"Model A\\\":92.35},\\\"Accuracy\\\":{\\\"Model A\\\":96.92},\\\"Precision\\\":{\\\"Model A\\\":96.82}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "JMLR9-VHXR2-3J88N_161-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 161,
            "narration": "This model has a very low classification performance than was perhaps expected on the given ML problem or task as shown by the scores achieved across all the evaluation metrics (recall, accuracy, AUC, and precision). The dataset used for modeling was balanced supporting no sampling biases by the model. However, the values of 62.35% for the accuracy, precision at 18.81% and recall equal to 61.48% all paint an image of the model is performing poorly at classifying C1 and C2  instances/cases accurately and precisely. The AUC at 73.69% cast a shadow of moderate accuracy in the models predictions of class assignment. Finally, predictions from this model accepted be taken with caution.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":73.69},\\\"Recall\\\":{\\\"Model A\\\":61.48},\\\"Accuracy\\\":{\\\"Model A\\\":62.35},\\\"Precision\\\":{\\\"Model A\\\":18.81}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "JMLR9-VHXR2-3J88N_161-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"1\",\"AUC\":\"3\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 163,
            "narration": "Considering the ML task under consideration, all metrics' scores are very high, with recall equal to 91.48 and precision score at 91.06% suggesting a very low false positive and false negative rates. Besides, the accuracy achieved was 91.37%. The model's dataset has balanced split suggesting that the resulting high scores for the evaluation metrics observed can accurately suggest that the model is productive in classifying cases into C1 or C2. The values of the accuracy, and F1-score combined are suggesting that the model will consistently assigning  less than <acc_diff>% of the samples into the wrong category/class.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.06},\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"F1-score\\\":{\\\"Model A\\\":91.26},\\\"Recall\\\":{\\\"Model A\\\":91.48}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "HAHGR-74BFK-H33HK_163-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 163,
            "narration": "Considering the ML task under consideration, all metrics' scores are moderately high as expected from training a model on a somewhat balanced dataset. The accuracy achieved was 89.18% with a recall value of  84.23% and precision score at 81.83% show that this model has a low false positive rate. However more can be done to improve the model's performance further before deployment.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":81.83},\\\"Accuracy\\\":{\\\"Model A\\\":89.18},\\\"Recall\\\":{\\\"Model A\\\":84.23}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "HAHGR-74BFK-H33HK_163-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 172,
            "narration": "According to the scores table shown, the model scores a very high AUC of 94.5, whilst also achieving high values for recall, accuracy,  and precision with values of  87.03, 86.53, and 85.56, respectively. The AUC score shows that the separation of the model's class predictions is high. Coupled with a recall of 87.03, which shows that the model must have a relatively low number of false negatives, we can conclude that the model performs well (there is more room for improvement given that the dataset for the classification problem is perfectly balanced).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.56},\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"AUC\\\":{\\\"Model A\\\":94.5},\\\"Accuracy\\\":{\\\"Model A\\\":86.53}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0FT39-A7RGT-VWLX6-172-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 94.5 and Recall of 87.03. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 172,
            "narration": "This classification model trained to assign either C1 or C2 for test cases scores a  high AUC of 88.35, coupled with high values for recall, precision  and accuracy with values of  89.46%, 88.76%, and 87.41%, respectively. The AUC and accuracy scores indicates that the test observation separating ability of the model's class predictions is high. Furthermore, the recall and precision show that the model must have a relatively low false negative rate. Based on all the above, we can conclude that the model performs well.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.76},\\\"AUC\\\":{\\\"Model A\\\":88.35},\\\"Accuracy\\\":{\\\"Model A\\\":87.41},\\\"Recall\\\":{\\\"Model A\\\":89.46}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0FT39-A7RGT-VWLX6-172-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 94.5 and Recall of 87.03. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Student Job Placement",
            "id": 174,
            "narration": "On the ML task, the model is fairly productive at sorting out the test cases into their respective classes with a precision score of 92.59 and accuracy at 88.37 suggesting that the model is able to group the majority of test samples correctly under their respective class and with the 89.29% recall rate of actual positives into the correct categories this is further verified. The conclusion above is further supported by the high AUC score achieved, 96.53%.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.53},\\\"Recall\\\":{\\\"Model A\\\":89.29},\\\"Accuracy\\\":{\\\"Model A\\\":88.37},\\\"Precision\\\":{\\\"Model A\\\":92.59}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "JJR1M-EVD0F-JN84U-174-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 92.59 and Accuracy of 88.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 92,
            "narration": "Trained on an imbalanced dataset, the model scores 93.04% (accuracy), 81.85% (recall), and a low precision score of 23.69%. Since the majority of the data belongs from the class C1, the performance is not  impressive. In an imbalanced dataset such as this, a large number of test cases are likely to be misclassified as C2 (which is also the minority class) as indicated by the scores achieved for the precision and recall.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":81.85},\\\"Accuracy\\\":{\\\"Model A\\\":93.04},\\\"Precision\\\":{\\\"Model A\\\":23.69}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "M@R8U-71VBP-KWJML-92-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 92,
            "narration": "'The model performs relatively well on this classification task with high scores for the accuracy and recall metrics. It has an accuracy score of 91.84% and  recall (84.71%) with a moderate precision score of 65.18% and 85.16% indicate a somewhat strong ability to disinguish between the test examples under the two class labels.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":84.71},\\\"Accuracy\\\":{\\\"Model A\\\":91.84},\\\"Precision\\\":{\\\"Model A\\\":65.18}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "M@R8U-71VBP-KWJML-92-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 92,
            "narration": "'The model performs relatively well on this classification task with high scores for the accuracy and recall metrics. It has an accuracy score of 91.84% and  recall (84.71%) with a moderate precision score of 65.18% and 85.16% indicate quite a strong ability to tell apart the unseen cases under the two class labels.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":84.71},\\\"Accuracy\\\":{\\\"Model A\\\":91.84},\\\"F1-score\\\":{\\\"Model A\\\":86.46}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "M@R8U-71VBP-KWJML-92-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.98},\\\"Recall\\\":{\\\"Model A\\\":58.954},\\\"AUC\\\":{\\\"Model A\\\":85.46},\\\"Precision\\\":{\\\"Model A\\\":37.468}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The scores achieved by the model are not that impressive. Accuracy (89.98%), precision (37.41%) and recall (58.95%) are only marginally higher than expected indicating how poor the performance is. A relatively low precision score of 38.47% signifies that <preci_diff> of the time data belonging to class C1 was predicted incorrectly as C2.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":1,\"Recall\":2,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.98},\\\"Recall\\\":{\\\"Model A\\\":58.954},\\\"AUC\\\":{\\\"Model A\\\":85.46},\\\"Precision\\\":{\\\"Model A\\\":37.468}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The values achieved by the model are not so impressive. Accuracy 89.98% is  only slightly higher than expected, which suggests how poor the performance is. A relatively low precision and recall values of 37.41% and 58.95%, respectively, allude that for some classification instances, the data for class C1 was incorrectly predicted as C2. This suggests a lower confidence in the  prediction decisions of the model.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":1,\"Recall\":2,\"AUC\":4}"
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 41,
            "narration": "The classification model or algorithm obtained very high values for AUC, recall, precision, and accuracy (that is 98.59, 97.33, 94.81, and 96.0, respectively). These scores show that the model has a very confidence in its prediction decisions. This implies that it can correctly classify a greater number of test cases belonging to the different classes considered under this classification task.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Recall\\\":{\\\"Model A\\\":97.333},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Precision\\\":{\\\"Model A\\\":94.81}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "1CC3F-2YAR6-@HWD0_41-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 97.33 and Accuracy of 96.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "House Price Classification",
            "id": 185,
            "narration": "The machine learning model scores 85.42%, 87.23%, 86.28%, and 83.67% for the F1-score, precision, accuracy, and recall metrics as shown in the table. We can confirm that this model is well balanced, since it has very similar values in all metrics. This model is likely to misclassify only a few test cases, so its prediction decisions can be reasonably trusted.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.23},\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":85.42},\\\"Accuracy\\\":{\\\"Model A\\\":86.28}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "956XH-E1ATW-PAMVM-185-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "House Price Classification",
            "id": 185,
            "narration": "As shown in the metrics table, the model scores 85.42%, 87.23%, 86.28%, and 83.67%, respectively across the metrics: the F1-score, precision, accuracy, and sensitivity metrics on the ML task under consideration. We can verify that this model is very well balanced based on the fact that it has very similar values in all metrics. Furthermore, this model is likely to misclassify only a few test cases, hence, its prediction decisions can be reasonably trusted.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":85.42},\\\"Accuracy\\\":{\\\"Model A\\\":86.28}, \\\"Precision\\\":{\\\"Model A\\\":87.23},}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "956XH-E1ATW-PAMVM-185-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Sensitivity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "House Price Classification",
            "id": 31,
            "narration": "Trained on this classification task, the classifier has a prediction accuracy of 79.41 with the  recall (that is sensitivity) and precision  scores of  72.41% and 89.36%, respectively. From the recall and precision scores, we compute that the F1-score is equal to 80.01%. Since the model has been trained on a balanced dataset, we can say that it has reasonably moderate classification performance and can fairly identify the correct class labels for the test cases of both class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.412},\\\"Recall\\\":{\\\"Model A\\\":72.414},\\\"F1-score\\\":{\\\"Model A\\\":80.01},\\\"Precision\\\":{\\\"Model A\\\":89.362}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "RGBGM-8UPQT-B2YR4_31-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Tic-Tac-Toe Strategy",
            "id": 32,
            "narration": "When trained in the context of the classification objective, the model achieves the scores of 79.59% for the precision and 88.64% as the F1-score. In addition, it has very high AUC and Accuracy scores, respectively equal to 99.29% and 93.06%. Judging based on all scores achieved, the model proves to have a rather high prediction performance on this classification task and will be able to correctly identify most test cases even those from the minority class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.056},\\\"AUC\\\":{\\\"Model A\\\":99.291},\\\"F1-score\\\":{\\\"Model A\\\":88.636},\\\"Precision\\\":{\\\"Model A\\\":79.592}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "2VK9M-WNQYE-25K76-32-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"AUC\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and AUC. (Your answer should capture the implications of achieving AUC of 99.29 and Precision of 79.59.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 33,
            "narration": "Given the distribution of the dataset across the class labels, the model achieved a classification performance of 94.51% for accuracy, 99.1% for the AUC metric. In addition, the recall (sensitivity) score and the precision score achieved are 90.2% and 91.1%, respectively.  The model in general performs very well on this ML classification problem. This conclusion is strengthened by the model's balanced prediction decisions across the two classes with similar precision and recall values of 91.1% and 90.2% respectively, which was achieved despite the <|majority_dist|>/<|minority_dist|> imbalance in the dataset for the different classes.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.509},\\\"Recall\\\":{\\\"Model A\\\":90.20},\\\"AUC\\\":{\\\"Model A\\\":99.099},\\\"Precision\\\":{\\\"Model A\\\":91.10}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "EDTU9-KNAVK-GEGTB_33-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 91.09 and Recall of 90.2. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Cab Surge Pricing System",
            "id": 34,
            "narration": "After training the model on the AI task, it recorded the scores  85.75, 86.21, and 94.18, when evaluations were conducted based on the metrics accuracy, recall, and precision respectively. The accuracy is somewhat similar to the recall, and  dissimilar to the precision which is substantially higher than expected. This suggests that the precision metric dominates the accuracy measure rather than recall. However based on the scores achieved on this ML task, we can conclude that the model will be effective and precise with its prediction decisions for several test examples/samples.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.75},\\\"Recall\\\":{\\\"Model A\\\":86.21},\\\"F1-score\\\":{\\\"Model A\\\":90.019},\\\"Precision\\\":{\\\"Model A\\\":94.18}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
            "redeem_code": "T8NA3-GUQL1-W48VA-34-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 83.74 and Accuracy of 83.99. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "2.25.71.194",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 35,
            "narration": "The prediction performance of the classifier is epitomized by the evaluation metric scores:  74.19% for the accuracy, 91.11% for recall, 53.25% for precision, and finally, 91.09% AUC. Eventhough it was trained on a balanced dataset, the model tends to frequently predict the C2 class as indicated by the low precision score and the very high recall score. This makes the model less useful than it would be when considering the accuracy and AUC scores achieved.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.194},\\\"Recall\\\":{\\\"Model A\\\":91.111},\\\"AUC\\\":{\\\"Model A\\\":91.092},\\\"Precision\\\":{\\\"Model A\\\":53.247}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "UV7@U-RGNLU-D71VG-35-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision, Accuracy and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 91.11 and Precision of 53.25. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 37,
            "narration": "Evaluation metric values of 72.0% for accuracy, 73.5% for AUC, 60.47% for recall and 32.91% for precision were achieved by the model on this classification task as shown in the table. The model shows a reasonable AUC of 73.5% indicating some level of understanding the ML task. However, the very low precision of 32.91% with a moderate sensitivity (recall) of 60.47% suggests that the model has a bias towards predicting the positive class, C2, which is also the minority class with <|minority_dist|> of examples in the dataset. This implies that the model is less precise with its prediction output decisions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":72.0},\\\"AUC\\\":{\\\"Model A\\\":73.499},\\\"Precision\\\":{\\\"Model A\\\":32.911},\\\"Recall\\\":{\\\"Model A\\\":60.465}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "XGT6Y-BJ0YV-4MV4L_37-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Recall\":\"2\",\"Precision\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Sensitivity, Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 39,
            "narration": "In the matter of the metrics Accuracy, Precision, recall and F1-score, the model scored or achieved 93.88%, 67.66%, 99.69%, and 80.61%, respectively. With such scores for the F1-score, precision and recall,  this model has a moderate classification performance. It can successfully produce the correct label for most test cases with some misclassified instances.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":99.687},\\\"F1-score\\\":{\\\"Model A\\\":80.608},\\\"Accuracy\\\":{\\\"Model A\\\":93.88},\\\"Precision\\\":{\\\"Model A\\\":67.66}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "P6L66-M@4H6-6YK@M-39-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"3\",\"F1-score\":\"4\",\"Recall\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, F1-score and Recall. (Your answer should capture the implications of achieving Accuracy of 93.88 and Precision of 67.66.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 41,
            "narration": "For the given ML classification task, the model's performance was evaluated based on the AUC, Recall, Precision and Accuracy scores. The model has a very high scores across all boards (i.e 98.59 (AUC), 97.33% (Recall), 94.81% (precision) and 96.09% (accuracy)) and is shown to be very confident with the prediction decisions made. This implies that it can correctly classify several test cases belonging to the any of the two classes. This performance is not surprising since the dataset is perfectly balanced between the classes C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.09},\\\"Recall\\\":{\\\"Model A\\\":97.333},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Precision\\\":{\\\"Model A\\\":94.81}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "1CC3F-2YAR6-@HWD0_41-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 97.33 and Accuracy of 96.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 41,
            "narration": "The test cases labeling performance of the ML algorithm is very impressive considering the fact that it scores 97.33%, 94.81%, 96.01% and 98.59%, respectively, across the evaluation metrics recall, precision, accuracy, and AUC. From these scores achieved, we can make the conclusion that this model will be very effective at correctly labelling the examples belonging to the different classes, C1 and C2, under consideration. Furthermore, the precision score and recall score shows that the likelihood of misclassifying any given test observation is unsurprisingly marginal.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.01},\\\"Recall\\\":{\\\"Model A\\\":97.333},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Precision\\\":{\\\"Model A\\\":94.81}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "1CC3F-2YAR6-@HWD0_41-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 97.33 and Accuracy of 96.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 44,
            "narration": "Surprisingly, the model achieved almost perfect scores for the recall (99.29) and accuracy (97.99%). Furthermore, it also has high  F1-score and precision score. From these high scores across the evaluation metrics, the model is shown to be effective and it can confidently generate the true label for a large proportion of the test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":99.294},\\\"Accuracy\\\":{\\\"Model A\\\":97.994},\\\"F1-score\\\":{\\\"Model A\\\":88.172},\\\"Precision\\\":{\\\"Model A\\\":79.355}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "J6R3B-UNXYA-37HMB_44-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 44,
            "narration": "Unsurprisingly, the classifier achieved near perfect scores for the recall (99.19%) and accuracy (85.92%). Despite these high scores, its F1-score  and precision scores are lower than expected and judging by this, the algorithm is shown to be less precise when assigning class labels to some test cases. In summary, it has higher false positive rate than anticipated given its high recall score and the low precision score ",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":99.194},\\\"Accuracy\\\":{\\\"Model A\\\":85.92},\\\"F1-score\\\":{\\\"Model A\\\":56.029},\\\"Precision\\\":{\\\"Model A\\\":39.23}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "J6R3B-UNXYA-37HMB_44-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Real Estate Investment",
            "id": 46,
            "narration": "This model has an accuracy of 95.11%, recall of 94.12%, AUC of 96.12% and precision score of 85.71% as its classification performance on this ML task/problem. Based on the high scores across the metrics, the model is almost certain to make just few mistakes (i.e. low misclassification error/rate). Overall, the performance is very impressive given that the dataset was imbalanced.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.11},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":94.12}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "K7LMJ-BDK1T-DNDKJ-46-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Water Quality Classification",
            "id": 169,
            "narration": "Sensitivity, specificity and  accuracy scores of 48.39%,  66.38%, and 61.28%, respectively, indicate how poor the model's performance  is on this ML task. This is further confirmed by the F1-score of 41.38%. The accuracy and specificity scores should not be misinterpreted as the model being good and are a little high due to class imbalances.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":66.38},\\\"F1-score\\\":{\\\"Model A\\\":41.48},\\\"Sensitivity\\\":{\\\"Model A\\\":48.39},\\\"Accuracy\\\":{\\\"Model A\\\":61.28}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "4KDQP-Y10KK-43A6X-169-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"1\",\"Accuracy\":\"2\",\"F1-score\":\"1\",\"Specificity\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Water Quality Classification",
            "id": 169,
            "narration": "Sensitivity, specificity and  accuracy scores of 79.12, 88.55%, and 85.15%, respectively, indicate how good the classifier is on the given ML problem. This is further supported by the F1-score of 75.13%. Overall, from the F1-score  and sensitivity scores, we can see that the false positive rate is very low.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":88.55},\\\"F1-score\\\":{\\\"Model A\\\":75.13},\\\"Sensitivity\\\":{\\\"Model A\\\":79.12},\\\"Accuracy\\\":{\\\"Model A\\\":85.15}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "4KDQP-Y10KK-43A6X-169-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 193,
            "narration": "On this imbalanced classification task, the model scores 72.4%, 58.62%, 75.2% , and 43.04%, respectively, on the metrics accuracy, sensitivity/recall, AUC score, and precision.  Overall, the model has a lower prediction performance than expected based on its low scores for the precision and sensitivity scores. Besides, the accuracy  is not better than the alternative model that constantly assigns the majority class label C1 to any given test instance/case.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Precision\\\":{\\\"Model A\\\":43.04},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"Accuracy\\\":{\\\"Model A\\\":72.4}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "RLKHJ-28UMN-VLWUW_193-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Sensitivity\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy, AUC and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 192,
            "narration": "The performance of the model is very notable achieving the scores 99.16%, 100.0%, 89.12% and 95.08%, respectively, across the metrics AUC, specificity, sensitivity/recall and accuracy. From these scores achieved on the given ML problem, the model has a very low chance to misclassify test cases  and given that the specificity is a 100.0%, we are certain that it can accurately sort out almost all the test examples related to the negative class label C1.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Sensitivity\\\":{\\\"Model A\\\":89.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.08}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "L0YXQ-@C9RJ-2@UAL-192-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 50,
            "narration": "With reference to the machine learning classification objective under consideration, the model scored: (a)  83.15% representing the Accuracy of the predictions made on the test dataset. (b) Recall of 79.36%. (c) 79.41% is the F2-score. (d) Precision score of 79.71%.  These scores indicates that the model has a high classification performance and will be able to correctly classify several test samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.71},\\\"Accuracy\\\":{\\\"Model A\\\":83.15},\\\"Recall\\\":{\\\"Model A\\\":79.36},\\\"F2-score\\\":{\\\"Model A\\\":79.41}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "X0DG2-168@U-76E11_50-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F2-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, F2-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 50,
            "narration": "Regarding the machine learning classification task under consideration, the algorithm possesses the scores 87.44%, 84.97%  and 80.51%, respectively, on the metrics  Accuracy, Recall, and Precision. From the precision and recall scores, we can verify that the F2-score is equal to 84.34%.  These scores indicates that the model  will be able to correctly classify several test samples with only a few misclassify test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.51},\\\"Accuracy\\\":{\\\"Model A\\\":87.44},\\\"Recall\\\":{\\\"Model A\\\":84.97},\\\"F2-score\\\":{\\\"Model A\\\":84.34}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "X0DG2-168@U-76E11_50-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F2-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, F2-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 95,
            "narration": "For this classification problem, accuracy, recall, F2-score and precision are the evaluation metrics employed to assess the performance of  the model. With respective to the precision, recall and F2-score,  the classifier scored 76.77%, 74.53% and 74.57%, respectively. Besides, the  accuracy scored by the model is 80.23%. The model performs quite well in terms of accurately predicting the true label for test cases related to the class labels under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "RTUJ1-JBLJR-EH6C4-95-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Recall and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Attrition",
            "id": 189,
            "narration": "The learning algorithm recorded the scores: very low recall score of 28.76%, accuracy of 55.47%, AUC score of 76.92 and a high precision score of 89.8% on the machine learning classification problem.  Interestingly,  the confidence in predictions of C2 is high as shown by precision and recall scores. Overall, looking at the scores, we can say its performance is somehow poor as it will likely fail to correctly identify several test examples from both classes especially those  related to C1.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":76.92},\\\"Recall\\\":{\\\"Model A\\\":28.76},\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"Accuracy\\\":{\\\"Model A\\\":55.47}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "CDMRJ-AQ1NH-8H1XM_189-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Recall\":\"1\",\"Precision\":\"4\",\"Accuracy\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 28.76 and AUC of 76.92. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 188,
            "narration": "The classifier or algorithm scores 81.32%, 55.66%, 64.61% and 48.88% across the following evaluation metrics: accuracy, F1-score, recall and precision, respectively on this ML classification task. Judging by the scores, this model is shown to be less impressive at correctly pick out the test cases belonging to the minority class label C2. The confidence for predictions of C2 is very low given the many false positive prediction decisions (simply by looking at the recall and precision scores). With the dataset being imbalanced, the accuracy score is of less importance here, however, even judging based on the score it can be said that the model is only a little better than the dummy classifier.  Infact, there is more room for improvement for this model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.32},\\\"F1-score\\\":{\\\"Model A\\\":55.66},\\\"Recall\\\":{\\\"Model A\\\":64.61},\\\"Precision\\\":{\\\"Model A\\\":48.88}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "RXKE9-LH36N-LKDDX-188-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"2\",\"Recall\":\"3\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "House Price Classification",
            "id": 185,
            "narration": "As shown in the table, the recorded performance scores are 86.28%, 85.42%, 87.23%, and 83.67%, respectively, based on the accuracy, F1-score's metric, precision, and recall. This model has very similar scores on all metrics, implying that it is well balanced. However, the model is likely to misclassify some test instances.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"Precision\\\":{\\\"Model A\\\":87.23},\\\"F1-score\\\":{\\\"Model A\\\":85.42},\\\"Accuracy\\\":{\\\"Model A\\\":86.28}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "956XH-E1ATW-PAMVM-185-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 183,
            "narration": "The recorded evaluation scores of the model are 64.55%, 60.4%, 72.54%, and 65.14%, respectively, based on the metrics Precision, F1-score, Specificity, and Accuracy. With the data being acutely imbalanced, this model is shown to have a poor classification performance across a large number of test instances or samples. The precision and F1-score show that the model has a moderate classification performance when it comes to classifying examples belonging to the class label C2, however, looking at the accuracy score, there is little confidence in the model's prediction output decisions. Furthermore, even the dummy model constantly assigning label C1 for any given test example/instance will easily outperform this model in terms of the specificity and accuracy scores.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.4},\\\"Specificity\\\":{\\\"Model A\\\":72.54},\\\"Precision\\\":{\\\"Model A\\\":64.55},\\\"Accuracy\\\":{\\\"Model A\\\":65.14}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "JAP17-X9Q05-GRHAH_183-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"3\",\"Accuracy\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Specificity and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Specificity and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 183,
            "narration": "The scores 84.18%, 87.48%, 93.28%, and 91.33%, respectively, are the evaluation scores secured by the classifier on the basis of the metrics Precision, F1-score, Specificity, and Accuracy on when trained on this binary machine learning problem. On this very imbalanced dataset, this model is shown to have a good classification performance across a large number of test instances or samples. The precision and F1-score show that the model has a high performance with regards to examples belonging to the class labels C1 and C2. Its prediction confidence is fairly high and will only make few misclassification errors.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":87.48},\\\"Specificity\\\":{\\\"Model A\\\":93.28},\\\"Precision\\\":{\\\"Model A\\\":84.18},\\\"Accuracy\\\":{\\\"Model A\\\":91.33}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "JAP17-X9Q05-GRHAH_183-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"F1-score\":\"4\",\"Specificity\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Specificity and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Specificity and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 76,
            "narration": "Trained on this disproportionate dataset, the classifier achieved a sensitivity (recall) score of 80.01% and a precision score of 86.96%. In addition, the AUC score is 94.73% and the accuracy score is 93.16%. The model has relatively high predictive performance, as indicated by precision and recall (sensitivity)  scores. In essence, the model has a low false positive rate hence  there is a lower likelihood of misclassifying most test instances.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":86.96},\\\"AUC\\\":{\\\"Model A\\\":94.73},\\\"Sensitivity\\\":{\\\"Model A\\\":80.01},\\\"Accuracy\\\":{\\\"Model A\\\":93.16}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "JCJNF-MQA@Y-RPXJ1_76-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Sensitivity\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Sensitivity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 76,
            "narration": "For this imbalanced classification task, the classifier achieved a sensitivity score of 83.48% and a precision score of 85.12%. On top on this, the accuracy score equal to 91.48% and the AUC score is 93.81%. Overall, the model has relatively high predictive performance and is quite effective, as shown by precision and recall (sensitivity)  scores. In addition, the model has a low false positive rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.12},\\\"AUC\\\":{\\\"Model A\\\":93.81},\\\"Sensitivity\\\":{\\\"Model A\\\":83.48},\\\"Accuracy\\\":{\\\"Model A\\\":91.48}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "JCJNF-MQA@Y-RPXJ1_76-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Sensitivity\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Sensitivity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 75,
            "narration": "Looking at the table shown, the models achieved 95.84% and 98.01% accuracy scores and AUC, respectively, on the ML classification problem. Additionally, it scored 87.1% for precision and 93.9% for the recall/sensitivity suggesting that the model is likely to have a high F1-score. These scores across the metrics are indicative of how good the model is at differentiating precisely between the cases under each class.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Precision\\\":{\\\"Model A\\\":87.1},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Recall\\\":{\\\"Model A\\\":93.9}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "91QCH-3A85T-FNENX-75-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 69,
            "narration": "For this classification problem, the model was trained to assign test cases to any of the following class labels: C1, C2, C3, and C4. The classifier achieves the classification performance of 89.42% (precision score), 89.57% (recall or sensitivity),  and 89.4% (for accuracy). Judging based on the scores above, we conclude that this model has high predictive confidence and can correctly predict the true label for several test cases/samples. In summary, it does very well on this ML problem.",
            "metrics_values": "\"{\\\"Precision-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":89.4},\\\"Recall-score\\\":{\\\"Model A\\\":89.57}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "3DT9X-UA4TB-QQMUW-69-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision-score\":\"5\",\"Accuracy\":\"5\",\"Recall-score\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 75,
            "narration": "This is a binary or two-way classification problem, where the classifier is trained to assign the test cases/instances one of the following classes C1 and C2. Looking at the table shown, the classifier performs very well on the task. Specifically,  it boasts scores of 95.84% and 98.01% with respect to accuracy and AUC, respectively. Additionally, it scored 87.1% for precision and 93.9% for recall/sensitivity suggesting that the classifier has a high F1-score. The evaluation scores across the metrics are indicative of how good the model is at correctly choosing the label for new or unseen examples.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Precision\\\":{\\\"Model A\\\":87.1},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Recall\\\":{\\\"Model A\\\":93.9}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "91QCH-3A85T-FNENX-75-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 106,
            "narration": "For this binary or two-way labeling problem, the classifier is trained to assign test cases to the class label either C1 or C2. With a larger proportion of the dataset belonging to class C1, the model evaluated based on the following metrics precision, F1-score, accuracy, and recall, respectively, achieved 63.37%, 73.56%, 99.92%, and 87.67%. According to the scores, one can conclude that the performance of the model is not impressive. The accuracy score indicates that this model is not that different from the dummy model that always assigns C1 to any given input example. Here, only the precision, recall, and F1-score are important for assessing the usefulness of the model. From the scores for these metrics, we can conclude that this model has moderate false-positive predictions and that the prediction output of C2 might need further investigation.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":73.56},\\\"Precision\\\":{\\\"Model A\\\":63.37},\\\"Accuracy\\\":{\\\"Model A\\\":99.92},\\\"Recall\\\":{\\\"Model A\\\":87.67}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "R632M-@BR@0-QWQQ0_106-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, F1-score, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 63.37 and Recall of 87.67. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 103,
            "narration": "In terms of correctly labeling test observations as either C1 or C2, the model trained on this ML task bagged the scores 91.11%,  84.78%, 84.91%, and 77.59%, respectively, across the metrics AUC, accuracy, precision, and recall. The dataset used for training was fairly balanced between the two classes. From the scores above, we can conclude that this model is very effective and confident with the majority of its prediction decisions. The model outperforms the dummy model that always assigns C1 to any given input sample by a larger margin.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"Accuracy\\\":{\\\"Model A\\\":84.78},\\\"AUC\\\":{\\\"Model A\\\":91.11}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 128,
            "narration": "Under this multi-class classification problem, the trained model  assigns one of the following labels C1, C2 and C3 to the test instances. The accuracy of the model is somewhat high, with recall, and precision following marginally behind, however, overall the model's performance can be considered fairly high in classifying a several test samples.  The model has overall very good performance with achieving high F2-score indicating that as recall or accuracy is weighted more significantly. This is indicative that the model is good at determining correct class labels most of the time. The precision of 76.77 is below the 80.23 of accuracy, albeit very close together, however suggesting the model is struggling to perform well on the precision metric and may provide an avenue for improvement.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "4@61G-707H5-L5GCQ-128-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Recall, Accuracy and F2-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F2-score of 74.57 and Precision of 76.77. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 118,
            "narration": "On the classification task under consideration, the classifier assigns test instances to either class label C1 or C2 or C3 or C4. Across all the evaluation metrics under consideration, the model got high scores. Specifically, for the accuracy, it scored 96.0%, 95.98% for the precision score and 96.08% recall score.  It is fair to conclude that the classification performance/power of this model is quite impressive and the likelihood of misclassifying any given  test example is only marginal.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 113,
            "narration": "The performance evaluation scores based on accuracy, recall, precision, and AUC achieved by the ML algorithm on the given classification problem are 92.78%, 81.15%, 98.02%, and 96.38%, respectively when classifying test samples as either C1 or C2. Given the disproportionate dataset, these results/scores are very impressive. With such high precision and recall scores, the classification performance of the learning algorithm can be simply summarized as almost perfect, since only a few samples may be misclassified. Overall, this is a very confident model whose predictive decision is related to the two labels C1 and C2 are usually correct.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Precision\\\":{\\\"Model A\\\":98.02},\\\"Recall\\\":{\\\"Model A\\\":81.15},\\\"AUC\\\":{\\\"Model A\\\":96.38}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "H@PTU-6AXJA-Q9Q5R_113-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 111,
            "narration": "With reference to the given classification problem (where a given input sample is classified under either class C1 or class C2), the model attains impressive scores across all the metrics under consideration. Specifically, the recall score is equal to 94.12%, the accuracy score is 98.42%, precision score is 91.43% and finally, the F1-score achieved is equal to 92.75%. Judging by these scores attained, it is fair to conclude that this model can accurately choose the true labels for several of the test cases with marginal  misclassification error. In essence, the F1-score, recall score and precision score indicate the model's classification confidence of output predictions related to label C2 is very high.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "J@PN2-LPKE4-NMUMQ_111-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 110,
            "narration": "The classifier is trained to assign test cases a class label either C1 or C2. The performance of the classifier can be summarized as recall (81.25%), low precision (45.61%), and accuracy (81.5%). Given the imbalanced dataset, we can conclude that the classification performance of the model is relatively poor than expected, as the difference between precision and recall shows a high false positive rate. Therefore, the predictive confidence related to the C2 label is low.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Recall\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WN6X6-PL20R-937TG-110-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"2\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 110,
            "narration": "For this ML problem, the classifier assigns test cases to either class label C1 or C2. The model's label-prediction ability can be summarized as recall (87.12%), precision (85.34%), and accuracy (89.23%). Given the nature of the dataset, we can say that the prediction performance of the algorithm is relatively high.  Difference between precision and recall shows a low false positive rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.341},\\\"Recall\\\":{\\\"Model A\\\":87.12},\\\"Accuracy\\\":{\\\"Model A\\\":89.23}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WN6X6-PL20R-937TG-110-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 109,
            "narration": "The algorithm's classification ability when it comes to this binary classification problem is demonstrated by the scores: 60.32% (precision), 66.18% (accuracy), and 62.3% (F1-score). From these scores, we can confirm that the prediction ability of the classifier is moderate and  that a significant number of test cases are likely to be misclassified.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":62.3},\\\"Accuracy\\\":{\\\"Model A\\\":66.18}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 109,
            "narration": "On this binary classification problem where the test instances are classified as either C1 or C2, the classification performance can be summarized by the scores: 65.18% (precision), 69.42% (accuracy), and 64.13% (F1-score). From these scores, the classification power of the model can be said to moderate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":65.18},\\\"F1-score\\\":{\\\"Model A\\\":64.13},\\\"Accuracy\\\":{\\\"Model A\\\":69.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 107,
            "narration": "The metrics used to evaluate or assess the performance of the model on this binary classification task were: Precision, AUC, F1-score and Accuracy scores.  The classifier has an accuracy score of  85.11%  with an AUC score equal to  90.07%. Also, the precision and F1-score are 63.95% and 66.23%, respectively. From the  F1-score, we can estimate that the sensitivity score will likely be identical to the precision score, therefore judging that, the model has a somewhat low false positive classification rate is a valid statement. Overall, this model achieved a moderate performance since it can accurately classify a decent number of test cases/instances.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"Accuracy\\\":{\\\"Model A\\\":85.11}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "@6Q1G-9P3P4-QFPND_107-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, AUC, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 107,
            "narration": "Under this ML task, the classifier trained on the imbalanced dataset assigns the class label C1 or C2 to any given test example. Performance evaluations or assessment was conducted based on the metrics Precision, F1-score, AUC, and Accuracy scores.  For the accuracy and AUC, the classifier scored 96.43%  and  97.22%, respectively. On top of this, it has  89.63% as the precision score and an F1-score of 92.34%.  Overall, this model achieved a high classification performance since has demonstrated that it can accurately classify several test cases/instances.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.34},\\\"Precision\\\":{\\\"Model A\\\":89.63},\\\"AUC\\\":{\\\"Model A\\\":97.22},\\\"Accuracy\\\":{\\\"Model A\\\":96.43}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "@6Q1G-9P3P4-QFPND_107-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"5\",\"F1-score\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, AUC, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 107,
            "narration": "Training this classifier on this imbalanced dataset problem to assign the class label C1 or C2 to any given test example achieved the following evaluation scores as shown in the table. For the AUC and accuracy, the classifier attains the scores  97.22% and 96.43%, respectively. In addition, it scored  89.63% as the recall metric score with the F1-score equal to 92.34%.  Judging by the scores, this model achieved a fairly high classification performance hence it can accurately classify several test cases/instances with only few instances misclassified.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.34},\\\"Recall\\\":{\\\"Model A\\\":89.63},\\\"AUC\\\":{\\\"Model A\\\":97.22},\\\"Accuracy\\\":{\\\"Model A\\\":96.43}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "@6Q1G-9P3P4-QFPND_107-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"AUC\":\"5\",\"F1-score\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, AUC, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "The prediction performance on this binary classification task as evaluated based on the Accuracy, Precision, and Recall are 74.26%, 73.71%, and 76.21%, respectively.  These scores indicates that the model has a moderate performance and  can accurately separate some of the test instance with small likelihood of error.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "Classifying test cases as either C1 or C2, the model achieves the classification performance: Accuracy equal to 90.11%, Precision equal to 85.48%, and Recall score equal to 85.19%. Overall, this classifier is shown to be effective in terms of  differentiating accurately between several test instances/cases with higher confidence in the prediction decisions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":85.19},\\\"Accuracy\\\":{\\\"Model A\\\":90.11},\\\"Precision\\\":{\\\"Model A\\\":85.48}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "By assigning the class labels C1 and C2, the classification performance attained by the classifier is: Accuracy 90.11%, precision 85.48%, and F2-score 83.22%. Overall, this classifier has been shown to be effective with higher confidence in it predictive decisions. This conclusion is mostly based on the precision and F2-score.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":83.22},\\\"Accuracy\\\":{\\\"Model A\\\":90.11},\\\"Precision\\\":{\\\"Model A\\\":85.48}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"5\",\"F2-score\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 129,
            "narration": "For this binary classification task, the model's performance as evaluated was 84.06% for accuracy, 74.6% for recall, 88.68% for precision, and 92.21% for the AUC. This model is fairly effective with such an accuracy score on this somewhat balanced dataset providing a good indicator of performance. Besides, scoring 88.68% (precision) and 74.6% (recall)  imply that the false positive rate is low, hence only a few new cases (belonging to C1) will be misclassified as C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.68},\\\"Accuracy\\\":{\\\"Model A\\\":84.06},\\\"AUC\\\":{\\\"Model A\\\":92.21},\\\"Recall\\\":{\\\"Model A\\\":74.6}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 129,
            "narration": "The model's performance on the given ML problem is: it has an accuracy of about 84.06% with the AUC, Recall, and F1-score, respectively, equal to 91.41%, 82.19%, and 80.68%. With the model achieving these scores on this balanced dataset, it is somewhat valid to conclude that it can accurately identify the correct class labels for many test instances. This implies that there will be misclassification instances of some test examples, especially those difficult to pick out.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":82.19},\\\"Accuracy\\\":{\\\"Model A\\\":84.06},\\\"AUC\\\":{\\\"Model A\\\":91.41},\\\"F1-score\\\":{\\\"Model A\\\":80.68}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 129,
            "narration": "The following are the scores achieved by the given model on this binary classification task: (1) accuracy equal to 83.96% (2) Sensitivity (recall score) is 75.19% with a precision score of 68.65% (3) Specificity of 83.68% and (4) AUC score equal to 83.68%.  It could be concluded that the classification performance is high and this model is shown to be able to correctly identify cases belonging to the class label C1 about 83.68% of the time (based on the specificity score). Furthermore, since the difference between  sensitivity and precision is not that high, the model demonstrates its ability to correctly identify a moderate amount of test instances belonging to the positive class C2.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.19},\\\"Accuracy\\\":{\\\"Model A\\\":83.96},\\\"AUC\\\":{\\\"Model A\\\":89.51},\\\"Specificity\\\":{\\\"Model A\\\":83.68},\\\"Precision\\\":{\\\"Model A\\\":68.65}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"Specificity\":\"4\",\"AUC\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The dataset used to train the model was balanced between classes C1 and C2. The predictability of the model is high as shown by the scores achieved across the metrics: recall, accuracy, AUC, and precision. From these scores, it can be ruled that the chance/likelihood of misclassification is quite small which is impressive but not surprising given the distribution of the dataset across the class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.33},\\\"Recall\\\":{\\\"Model A\\\":87.97},\\\"AUC\\\":{\\\"Model A\\\":95.96},\\\"Precision\\\":{\\\"Model A\\\":88.58}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The ML algorithm's performance on this binary classification task is quite impressive. For example, it scored recall and precision scores of 94.73%, and 95.14%, respectively, implying that confidence in its prediction decisions is very high. The above argument is further supported by the almost perfect accuracy and AUC scores (95% and 98.98%, respectively).",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.73},\\\"AUC\\\":{\\\"Model A\\\":98.98},\\\"Accuracy\\\":{\\\"Model A\\\":95.0},\\\"Precision\\\":{\\\"Model A\\\":95.14}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The classifier in the context of this classification problem where is was trained to assign one of the following classes: C1 and C2 to different test instances scored an accuracy,  AUC, recall, and precision scores equal to 95.0%, 98.98%, 94.73%, and 95.14%, respectively implying that it is a very effective model. These scores indicate that the likelihood of this model misclassifying samples is very marginal. However, the scores were expected since the dataset was perfectly balanced between the two classes C1 and C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.73},\\\"AUC\\\":{\\\"Model A\\\":98.98},\\\"Accuracy\\\":{\\\"Model A\\\":95.0},\\\"Precision\\\":{\\\"Model A\\\":95.14}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "Evaluation of the model's classification capability showed that it demonstrates a relatively high classification performance judging by the scores achieved across the evaluation metrics: AUC, recall, precision, and accuracy as shown in the table. The balance between the recall (88.96%) and precision (89.81%) scores goes to show that the chance of misclassifying samples from C1 as C2 is very low; hence the confidence in prediction decisions related to the class label C2 is very high.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":88.96},\\\"AUC\\\":{\\\"Model A\\\":94.45},\\\"Accuracy\\\":{\\\"Model A\\\":89.17},\\\"Precision\\\":{\\\"Model A\\\":89.81}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "From the table, the model shows signs of learning the features required to accurately and correctly segregate the test samples belonging to each of the two-class labels under consideration. Overall, with an accuracy of 89.17%, precision of 89.81%, recall/sensitivity score of 88.96%, and AUC score of 94.43%, we can be sure that the likelihood of misclassifying a given test sample is very low. It has low false positive and false negative rates which is a very good sign of a model ready for deployment.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":88.96},\\\"AUC\\\":{\\\"Model A\\\":94.45},\\\"Accuracy\\\":{\\\"Model A\\\":89.17},\\\"Precision\\\":{\\\"Model A\\\":89.81}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The performance evaluation metrics scores achieved by the model on this binary classification task were: (a) Accuracy equal to 86.67%. (b) AUC score of 90.93%. (c) Recall (sensitivity) score equal to 86.01%. (d) a precision score equal to 84.25%. (e) F2-score of 85.57%. Since there is a class imbalance problem, only the F2-score, precision, and recall scores are important metrics to accurately assess how good the model is on this classification task. From these scores, the performance of the model can be summarized as high, which implies that even the examples under the minority class label C2 can be accurately selected with a high level of certainty.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.57},\\\"Recall\\\":{\\\"Model A\\\":86.01},\\\"AUC\\\":{\\\"Model A\\\":90.93},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"Precision\\\":{\\\"Model A\\\":84.25}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The classification performance scores achieved by the model on this binary classification task are as follows: (1) AUC score of 95.42%, (2) Accuracy equal to 90.83%, (3) Recall of 89.78%, (4) Precision score equal to 90.21% with the F2-score equal to 89.86%. With such an imbalanced classification dataset, accuracy and AUC scores are less important metrics to correctly evaluate and assess how good the model is, on this ML task/problem. Consequently, based on the other metrics (i.e., precision, recall, and F2-score), the classification capability of the model can be summarized as high, indicating that the examples under the minority class label (C2) can be accurately separated with a high level of confidence.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":89.86},\\\"Recall\\\":{\\\"Model A\\\":89.78},\\\"AUC\\\":{\\\"Model A\\\":95.42},\\\"Accuracy\\\":{\\\"Model A\\\":90.83},\\\"Precision\\\":{\\\"Model A\\\":90.21}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "Evaluated based on the precision, recall, accuracy, AUC, and F2-score metrics, the model achieved the scores 52.84%, 61.76%, 65.83%, 88.1%, and 49.66%, respectively. These scores are quite lower than expected. The classification accuracy (which was expected to be high but was only marginally higher than the alternative model that constantly assigns C1 to any given test input) indicates the model will not be able to correctly classify instances from both class labels. The above conclusion is further supported by the moderately lower F2-score.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":49.66},\\\"Recall\\\":{\\\"Model A\\\":61.76},\\\"AUC\\\":{\\\"Model A\\\":88.1},\\\"Accuracy\\\":{\\\"Model A\\\":65.83},\\\"Precision\\\":{\\\"Model A\\\":52.84}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F2-score\":\"2\",\"Recall\":\"3\",\"AUC\":\"4\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "Evaluated based on the recall (sometimes referred to as sensitivity), precision, accuracy, AUC, and F2-score metrics, the model achieved the scores 88.31%, 80.86%, 85.71%, 95.45%, and 85.71%, respectively. These scores are relatively higher than expected given the class imbalance. The precision and sensitivity scores allude to the fact that the model has a very low false-positive rate. This implies the likelihood of C1 examples being misclassified as C2 is lower, which is a good sign that this model is able to accurately learn the distinguishable attributes that indicate the true class labels for the majority of the test cases. The above assertion is further supported by the moderately high F2-score together with the AUC and accuracy scores.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":88.31},\\\"AUC\\\":{\\\"Model A\\\":95.45},\\\"Accuracy\\\":{\\\"Model A\\\":85.83},\\\"Precision\\\":{\\\"Model A\\\":80.86}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "These scores across the metrics accuracy, AUC, recall, precision, and F2-score are high even though the dataset was imbalanced with the majority of the data belonging to class label C1. The precision of 80.86% and sensitivity score of 88.31% suggests that the model has low false positive and false negative rates. This shows that the chance of a C1 example being misclassified as C2 is lower, which is a good sign any model which is able to accurately capture/learn the important features required to predict the true class labels for several the unseen test instance. This is further supported by the high F2-score together with the accuracy and AUC scores.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":88.31},\\\"AUC\\\":{\\\"Model A\\\":95.45},\\\"Accuracy\\\":{\\\"Model A\\\":85.83},\\\"Precision\\\":{\\\"Model A\\\":80.86}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "On this balanced classification task, the model trained to identify the test cases as either C1 or C2 achieved an accuracy of 88.13%; a specificity score equal to 90.36%; a sensitivity (sometimes referred to as the recall score) of 85.07%, and finally, an F2-score of about 85.59%. The specificity score suggests that a large number of samples under the class label C1 are accurately identified. There is also a clear balance between sensitivity and precision scores (as shown by the F2-score) which indicates a low false-positive rate. In summary, the confidence level of the model's output decisions is high, hence will make only a few misclassification errors.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.59},\\\"Sensitivity\\\":{\\\"Model A\\\":85.07},\\\"Specificity\\\":{\\\"Model A\\\":90.36},\\\"Accuracy\\\":{\\\"Model A\\\":88.13}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Sensitivity\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "On this balanced labeling problem, the model was trained to accurately identify the test instances/examples as either C1 or C2. Evaluated based on the accuracy, sensitivity, F2-score, and specificity, it scored 90.67%, 90.48%, 89.91%, and 90.81%, respectively. The Specificity and Sensitivity (also referred to as the recall) scores demonstrate that several samples under the class label C1 are correctly identified as C1.  The model has a low false positive rate given the clear balance between the sensitivity and precision scores (judging based on the F2-score achieved). Overall, the prediction confidence level of the model on this ML task is high showing that it will make only misclassify a small number of test instances.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":89.91},\\\"Sensitivity\\\":{\\\"Model A\\\":90.48},\\\"Specificity\\\":{\\\"Model A\\\":90.81},\\\"Accuracy\\\":{\\\"Model A\\\":90.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Sensitivity\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The specificity score of 80.85%, sensitivity score of 90.2%, accuracy score of 84.0%, and F2-score equal to 85.5% are the evaluation metrics scores summarizing the ability of the classifier on this binary classification task or problem. From the F2-score, Specificity, and Sensitivity scores, we can conclude that the number of C1 being misidentified as C2 is moderately higher than expected given that the dataset is balanced. Before deployment, steps should be taken to improve the precision score of the model, which will boost the confidence level of the model's output prediction decisions.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.5},\\\"Sensitivity\\\":{\\\"Model A\\\":90.2},\\\"Specificity\\\":{\\\"Model A\\\":80.85},\\\"Accuracy\\\":{\\\"Model A\\\":84.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"3\",\"Sensitivity\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The classifier's false-positive and false-negative rates are very low given that it scored almost perfect scores across the metrics F2-score, sensitivity, accuracy, and specificity as shown in the table. These scores suggest that the model is effective and can accurately assign class labels for several test cases with only a small margin of misclassification error.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":95.24},\\\"F2-score\\\":{\\\"Model A\\\":94.64},\\\"Sensitivity\\\":{\\\"Model A\\\":95.24},\\\"Accuracy\\\":{\\\"Model A\\\":94.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Sensitivity\":\"5\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "As shown in the table, this model achieved a near-perfect score across F2-score, sensitivity, accuracy, and specificity, indicating very low positive and false-negative rates. The scores show that the model is effective and that class labels can be accurately assigned to a large number of test cases with a small margin of misclassification errors. In other words, there is high confidence about its classification or labeling decisions.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":95.24},\\\"F2-score\\\":{\\\"Model A\\\":94.64},\\\"Sensitivity\\\":{\\\"Model A\\\":95.24},\\\"Accuracy\\\":{\\\"Model A\\\":94.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Sensitivity\":\"5\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The model achieves the scores 94.64%, 95.24%, 94.67%, and 95.24%, respectively, across the metrics F2-score, sensitivity, accuracy, and specificity as shown in the table. These scores suggest that the incidence of false positives and false positives is very low demonstrating that the model is effective and can accurately assign class labels to several test instances with a marginal misclassification error margin.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":95.24},\\\"F2-score\\\":{\\\"Model A\\\":94.64},\\\"Sensitivity\\\":{\\\"Model A\\\":95.24},\\\"Accuracy\\\":{\\\"Model A\\\":94.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Sensitivity\":\"5\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "A specificity score of 80.85%, a sensitivity score of 90.2%, an accuracy score of 84.0%, and an F2-score of 85.5%  summarize the classification performance of the classifier on this machine learning task. From the F2-score, specificity and sensitivity, we can assert that the number of C1 instances misclassified as C2 is somewhat higher than expected, given the well-balanced dataset. Before you deploy this model into production, steps should be taken to improve the model's precision score hence improving the classification confidence level of the model.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.5},\\\"Sensitivity\\\":{\\\"Model A\\\":90.2},\\\"Specificity\\\":{\\\"Model A\\\":80.85},\\\"Accuracy\\\":{\\\"Model A\\\":84.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"3\",\"Sensitivity\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The performance evaluation metric scores achieved by the model in this binary classification ML task are (a) 86.67% accuracy score. (b) 90.93% AUC score. (c) 86.01% recall (sensitivity) score. (d) 84.25% precision score. (e) 85.57% F2-score. Since there is a disproportionate between the number of samples belonging to class label C1 and label C2, only F2-score, the recall, and precision scores are important indicators of how good the model is. These scores are high as shown in the table demonstrates that the model can accurately classify several test cases with high certainty.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":85.57},\\\"Recall\\\":{\\\"Model A\\\":86.01},\\\"AUC\\\":{\\\"Model A\\\":90.93},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"Precision\\\":{\\\"Model A\\\":84.25}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "As shown in the table, the classifier boasts a perfect score for the recall metric (i.e., 100%) with accuracy and AUC scores equal to 58.0% and 77.33%, respectively. On the surface, by just looking at the recall, one might assume this model will be very effective at correctly choosing the true class labels. However, the very low scores for precision and consequently the F1-score can't be ignored. With the model scoring just 13.7% for precision coupled with the low accuracy, this model can't be trusted to identify the correct labels for several test cases considering the fact that it has a high false-positive rate.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":24.1},\\\"Recall\\\":{\\\"Model A\\\":100.0},\\\"AUC\\\":{\\\"Model A\\\":77.33},\\\"Accuracy\\\":{\\\"Model A\\\":58.0},\\\"Precision\\\":{\\\"Model A\\\":13.7}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 55% of the data belonging to class C1 and 45% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"F1-score\":\"2\",\"Recall\":\"5\",\"AUC\":\"3\",\"Precision\":\"1\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "With the dataset being almost balanced between the two class labels, the model achieved the scores 82.75, 82.69, 90.16, 82.67, and 82.66, respectively, on the metrics accuracy, recall, AUC, precision, and F1-score. On this ML classification task, these scores are high which suggests that the model has a good understanding of the task. This demonstrates that it can accurately identify the true labels for a good proportion of the test cases.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":82.66},\\\"Recall\\\":{\\\"Model A\\\":82.69},\\\"AUC\\\":{\\\"Model A\\\":90.16},\\\"Accuracy\\\":{\\\"Model A\\\":82.75},\\\"Precision\\\":{\\\"Model A\\\":82.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 55% of the data belonging to class C1 and 45% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"5\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "This model achieved the scores: 88.1% for the accuracy, 87.92% for the recall/sensitivity, 93.93% for the AUC, and the precision score equal to 88.14%. From the recall and precision, the F1-score can be estimated as equal to 87.97%. These scores suggest that this model on this classification task can accurately identify the correct classes for several test cases. Besides, from the precision and recall, we can conclude that only a few samples belonging to label C1 will be misclassified as C2 and vice-versa.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.92},\\\"F1-score\\\":{\\\"Model A\\\":87.97},\\\"AUC\\\":{\\\"Model A\\\":93.93},\\\"Accuracy\\\":{\\\"Model A\\\":88.1},\\\"Precision\\\":{\\\"Model A\\\":88.14}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 55% of the data belonging to class C1 and 45% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"5\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The evaluation metrics employed to assess the performance of the classifier on this binary classification problem are accuracy, AUC, recall, precision, and F1-score. From the table, the model boasts an accuracy of 83.39% with an AUC score equal to 86.11%. In addition, it has identical scores for the precision, recall, and F1-score which are equal to 83.36%, 83.37%, and 83.33%, respectively. Judging based on the scores, the model demonstrates a high level of classification prowess in the sense that it can generate the correct class label for several test instances with high confidence and a marginal likelihood of misclassification.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":83.33},\\\"Recall\\\":{\\\"Model A\\\":83.37},\\\"AUC\\\":{\\\"Model A\\\":86.11},\\\"Accuracy\\\":{\\\"Model A\\\":83.39},\\\"Precision\\\":{\\\"Model A\\\":83.36}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 51.2% of the data belonging to class C1 and 48.8% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "This model is trained to assign a given sample the class label of either C1 or C2  achieved the classification performance as summarized in the table. It has an accuracy of 74.67, an AUC score of 82.64%, a recall (sometimes referred to as sensitivity or true positive rate) score of 74.04%, and a high precision score of 81.22%. F1-score estimated from the precision and recall scores is equal to 72.93%. These scores suggest the model will be somewhat effective at assigning the true labels to the test cases. Its confidence in the C2 prediction is high as shown by the precision and recall scores. However, there is more room for improvement especially with respect to the accuracy, and recall scores,  given that a number of test samples might be misclassified.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":72.93},\\\"Recall\\\":{\\\"Model A\\\":74.04},\\\"AUC\\\":{\\\"Model A\\\":82.64},\\\"Accuracy\\\":{\\\"Model A\\\":74.67},\\\"Precision\\\":{\\\"Model A\\\":81.22}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 51.2% of the data belonging to class C1 and 48.8% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The scores achieved on this classification task by the model are  (a) Prediction accuracy equal to 82.0%. (b) Precision score equal to 79.95%. (c) Recall score equal to 78.23%. (d) F2-score of 78.49%. The underlying dataset has a disproportionate amount of data belonging to the different classes hence the accuracy will not be a good assessor of the performance of the model. Therefore based on the  precision, recall, and F2-score, the model can be considered as having a fair understanding of this binary classification problem. These scores suggest that it can generate the true labels for several test instances with only a moderate level of misclassification.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":78.23},\\\"F2-score\\\":{\\\"Model A\\\":78.49},\\\"Accuracy\\\":{\\\"Model A\\\":82.0},\\\"Precision\\\":{\\\"Model A\\\":79.95}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The evaluation scores attained on this classification task by the model are as follows: The Sensitivity score of 78.23%, the Precision score equal to 79.95%, the Accuracy equal to 82.0%, and the F2-score of 78.49%. The underlying dataset is disproportionate between the two classes, therefore, judging the performance of the model based on only the accuracy score  is not very intuitive. Therefore based on the other metrics (that is recall, precision, and F2-score), the model demonstrates a fair understanding of this binary classification problem. These scores indicate that it can identify the correct labels of several test instances with only a few misclassifications.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":78.23},\\\"Accuracy\\\":{\\\"Model A\\\":82.0},\\\"F2-score\\\":{\\\"Model A\\\":78.49},\\\"Precision\\\":{\\\"Model A\\\":79.95}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Sensitivity\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "Despite the disproportionate amount of data between the two class labels C1 and C2, the classification algorithm employed scored 87.78% AUC, 82.67% accuracy, a precision score of 80.44%, and 79.89% F2-score. From the accuracy and AUC score, the model outperforms the dummy model that constantly assigns C1 to any given test instance/case. This associated with such high scores for the precision and F2-score suggests there is a moderate confidence level in the model's output prediction decisions.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":87.78},\\\"F2-score\\\":{\\\"Model A\\\":79.89},\\\"Accuracy\\\":{\\\"Model A\\\":82.67},\\\"Precision\\\":{\\\"Model A\\\":80.44}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "For this classification problem, despite the disproportionate amount of data between the class labels C1 and C2, the model achieved the scores: 82.67% accuracy, 87.78% AUC score, a precision of 80.44%, and 79.78% Specificity. From the accuracy and AUC score, the model is shown to outperform the alternative model that constantly assigns C1 to any given test instance. The above assertion coupled with the moderately high scores for the precision and Specificity suggests the model is quite confident with its output prediction decisions.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":87.78},\\\"Accuracy\\\":{\\\"Model A\\\":82.67},\\\"Precision\\\":{\\\"Model A\\\":80.44},\\\"Specificity\\\":{\\\"Model A\\\":79.78}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Specificity\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "On this imbalanced classification task, the trained model reached an accuracy score of 87.33%, a sensitivity score of 73.47%, a specificity score of 94.06%, and a precision score of 85.71%. The model has low false positive and negative rates suggesting that the likelihood of misclassifying examples belonging to any of the two classes is moderately low. Overall, the model is quite effective and confident with its prediction decisions for a significant portion of the test cases.",
            "metrics_values": "\"{\\\"Sensitivity \\\":{\\\"Model A\\\":73.47},\\\"Accuracy\\\":{\\\"Model A\\\":87.33},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":94.06}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Specificity\":\"4\",\"Sensitivity \":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.98},\\\"Recall\\\":{\\\"Model A\\\":58.954},\\\"AUC\\\":{\\\"Model A\\\":85.46},\\\"Precision\\\":{\\\"Model A\\\":37.47}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The performance of the classifier on this case labeling task as evaluated based on the precision, AUC, accuracy, and recall was 37.47%, 85.46%, 89.98%, and 58.95%, respectively. Out of the few C2 predictions, only about 37.47% were correct, meaning some of them actually belonged under the label C1. The classifier is less precise and confident about the generated labels, especially C2.",
            "task_name": "Insurance Churn",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":1,\"Recall\":2,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.21},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Recall\\\":{\\\"Model A\\\":93.12},\\\"Precision\\\":{\\\"Model A\\\":91.27}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "As shown in the table above, the prediction accuracy of the ML algorithm is 93.21%. It has AUC and precision scores respectively equal to 97.91 and 91.27, and its sensitivity (recall) score is 93.12%. The algorithm has a very low false-positive error rate as indicated or shown by the recall and precision scores. In essence, we can confidently conclude that this algorithm will be highly effective at choosing which class a given test case belongs to.",
            "task_name": "Airline Passenger Satisfaction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":5,\"AUC\":5,\"Recall\":5}"
        },
        {
            "task_name": "Insurance Churn",
            "id": 28,
            "narration": "For the given binary classification task, the model achieved the following metrics: (a) AUC: 87.58%. (b) Accuracy: 89.91%. (c) Precision: 45.01%. (d) Recall: 58.09%. From the accuracy score, we can see that the model is significantly better than the alternative model that always labels any given test observation as C1. Overall, this model has a moderately low classification performance as the precision and recall scores suggest that it will likely fail to correctly identify the class label of most test cases.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.914},\\\"Recall\\\":{\\\"Model A\\\":58.086},\\\"AUC\\\":{\\\"Model A\\\":87.581},\\\"Precision\\\":{\\\"Model A\\\":45.013}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "V4QTB-B204H-J9VHF-28-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"3\",\"Recall\":\"2\",\"Accuracy\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 89.91 and AUC of 87.58. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "House Price Classification",
            "id": 31,
            "narration": "Trained with reference to the goal of this classification task, the classifier  got a prediction accuracy of 79.41% with the precision and recall scores equal to 89.36% and 72.41%, respectively.  The F1-score derived from the precision and recall is equal to about 80.01%. Based on the scores across the different metrics under consideration, we can conclude that the model performs relatively well in terms of correctly picking out the test cases belonging to the class labels C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.412},\\\"Recall\\\":{\\\"Model A\\\":72.414},\\\"F1-score\\\":{\\\"Model A\\\":80.01},\\\"Precision\\\":{\\\"Model A\\\":89.362}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "RGBGM-8UPQT-B2YR4_31-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "House Price Classification",
            "id": 31,
            "narration": "The machine learning model trained on this machine learning task secured an accuracy eqaul to 79.41% with the associated precision and recall scores equal to 89.36% and 72.41%, respectively when evaluated based on the test set (consisting of observations not seen in the training and validation datasets). From the recall and precision scores, we can confirm that the F1-score is 80.01%. Judging by the accuracy and F1-score alone, it is fair to conclude that this model can accurately distinguish between several of the test examples with marginal misclassification error.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.412},\\\"Recall\\\":{\\\"Model A\\\":72.414},\\\"F1-score\\\":{\\\"Model A\\\":80.01},\\\"Precision\\\":{\\\"Model A\\\":89.362}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "RGBGM-8UPQT-B2YR4_31-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 33,
            "narration": "The machine learning model trained on the given task achieves very high performance across all metrics, with an accuracy of 94.51, AUC of 99.1, recall of 90.20 and precision, respectively. The very high precision score of 91.1% shows that the model is almost certain to make just few mistakes (i.e. low misclassification error/rate). Overall, the performance is very impressive given that it was trained on such an imbalanced dataset.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.51},\\\"Recall\\\":{\\\"Model A\\\":90.20},\\\"AUC\\\":{\\\"Model A\\\":99.1},\\\"Precision\\\":{\\\"Model A\\\":91.1}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "EDTU9-KNAVK-GEGTB_33-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 91.09 and Recall of 90.2. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 33,
            "narration": "The performance assessment scores across the evaluation metrics are as follows: (a) AUC: 99.1%. (b) Accuracy: 94.51%. (c) recall: 90.2%. (d) Precision: 91.1%. These results/scores are very impressive given that the dataset was imbalanced. The very high accuracy score implies that the classifier performs better than random guessing. In conclusion, with such high precision and recall scores, the classification performance of this algorithm can be simply summarized as almost perfect as only a small number of samples of C1 are likely to be misclassified as C2 (i.e. the model has a very low false-positive rate).",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.51},\\\"Recall\\\":{\\\"Model A\\\":90.20},\\\"AUC\\\":{\\\"Model A\\\":99.1},\\\"Precision\\\":{\\\"Model A\\\":91.1}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "EDTU9-KNAVK-GEGTB_33-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 91.09 and Recall of 90.2. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 36,
            "narration": "The performance of the model on this binary classification task as evaluated based on the precision, AUC, accuracy, and recall are 40.82%, 84.46%, 87.11%, and 83.33%, respectively. These scores were achieved on an imbalanced dataset. From the precision and recall scores, we can estimate that the classification algorithm has a moderate F1-score. However, the very low precision score of the model shows that the model will find it difficult to correctly classify some test samples from both classes.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.82}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 36,
            "narration": "The classification capability of the algorithm with reference to this binary classification problem where the test instances are classified as either C1 or C2 is: Accuracy (87.11%), Recall (83.33%), AUC (84.6%), and a low Precision (40.82%). Given the fact that the data was severely imbalanced, this algoritm is shown to have a moderately high false-positive rate. Overall, the classifier shows signs of difficulty in terms of  correctly classifying test samples from both class labels under consideration.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.82}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 30,
            "narration": "The scores 69.36%, 50.0%, 58.11 and 62.98% across the evaluation metrics precision, recall, F1-score, and accuracy, respectively, were achieved by the classifier when trained on this classification task. Judging by the scores achieved, we can conclude that this model has a lower performance as it is not be able to accurately predict the actual labels of multiple test examples. Furthermore, the accuracy score is only marginally higher than the dummy model constantly assigning the majority class label C1 to any given test case.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.985},\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Precision\\\":{\\\"Model A\\\":69.36}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "D3BDR-19LTL-PGNEG-30-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 62.98 and Recall of 50.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 30,
            "narration": "The model scores according to the evaluation metrics are: 61.99% (accuracy), 50.0 (recall) and 69.36% (precision). From the recall and precision, we can confirm that the F1-score is 58.11%. Even though the model was trained on an imbalanced dataset, these scores are lower than expected. With such low scores for precision and recall,  it might not be effective at correctly identify a large number of examples belonging to both class labels, C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":61.99},\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Precision\\\":{\\\"Model A\\\":69.36}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "D3BDR-19LTL-PGNEG-30-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 62.98 and Recall of 50.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 43,
            "narration": "The classifier attained an accuracy of 81.5% with the precision and recall equal to 57.9% and 71.74%, respectively. Based on these metrics' scores, we can conclude that this classifier will likely struggle at differentiating between the examples belonging to the different class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":71.739},\\\"Precision\\\":{\\\"Model A\\\":57.895}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "JM18F-9N8UX-FM0H6_43-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 57.9 and Recall of 71.74. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 43,
            "narration": "The model attained the following evaluation scores in relation to the metrics under consideration: (a) Accuracy equal to 81.5%. (b) Recall (sensitivity) score of 71.74%. (c) Precision score with 57.9%. From these scores, we can make the conclusion that this model will likely misclassify some proportion of samples belonging to both class labels. However, the model demonstrates a moderate classification performance despite the class imbalance.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":71.74},\\\"Precision\\\":{\\\"Model A\\\":57.895},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "JM18F-9N8UX-FM0H6_43-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 57.9 and Recall of 71.74. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Real Estate Investment",
            "id": 46,
            "narration": "The accuracy achieved by the model is 95.11% with a sensitivity score equal to 94.12%, the AUC score of 96.12%, and precision score equal to 87.71%. These scores support the conclusion that this model will be highly effective at telling-apart the examples drawn from the different class labels (i.e. C1 and C2) under consideration. Furthermore, the performance is very impressive given the fact that it was trained on such an imbalanced dataset.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.11},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":94.12}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "K7LMJ-BDK1T-DNDKJ-46-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Real Estate Investment",
            "id": 46,
            "narration": "The ML model evaluated based on the accuracy, recall, precision and AUC scores 95.11%, 94.12, 85.71 and 96.12%, respectively. These scores are very higher than expected indicating how good the model is in terms of correctly predicting the true class labels for the majority of the test cases. Overall, we can confidently conclude that this model will likely misclassify only a small number of test samples.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.11},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":94.12}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "K7LMJ-BDK1T-DNDKJ-46-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 54,
            "narration": "The table shows that the model achieved an AUC score of 74.06%, an accuracy of 69.2%, a precision of 35.44%, and recall of 51.85. These scores are very low and not very impressive. Furthermore, according to these scores, we can conclude that this model will fail (to some degree) at accurately separate the examples under the different class labels (i.e C1 and C2). With such less precise model, output prediction decisions should be further investigated. Also, steps should be taken to improve the precision, recall and accuracy since they are very low.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44},\\\"Sensitivity\\\":{\\\"Model A\\\":51.85}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "RE@@2-LBJH8-L6R22_54-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "On this imbalanced classification task, Sensitivity, accuracy, specificity, precision scores of 73.47%, 87.33%, 94.06% and 85.71%, respectively, indicate how good the model model's performance is in terms of correctly assigning the test instances to their correct class label. It has a moderately low false positive rate as indicated by the recall and precision scores suggesting that the likelihood of examples belonging to class label C1 being misclassified as C2 is very marginal.",
            "metrics_values": "\"{\\\"Sensitivity \\\":{\\\"Model A\\\":73.47},\\\"Accuracy\\\":{\\\"Model A\\\":87.33},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":94.06}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Specificity\":\"4\",\"Sensitivity \":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "For this imbalanced classification problem, the model's performance was evaluated as accuracy (82.0%), precision (79.95%), recall equal to 78.23% and 78.49% for the F2-score. These scores are high indicating that this model will be able to accurately identify the true class labels of several test instances/samples with only a few misclassification errors (i.e. low false-positive rate). Overall, the model is fairly confident with its prediction decisions across the majority of the test cases.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":78.49},\\\"Recall\\\":{\\\"Model A\\\":78.23},\\\"Accuracy\\\":{\\\"Model A\\\":82.0},\\\"Precision\\\":{\\\"Model A\\\":79.95}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The model earned or achieved a specificity score of 95.52%, an accuracy of 94.67%, and an F2-score of 94.6%. These scores across the different metrics suggest  that this model is effective as it will be able to generate the correct class labels for the majority of the test examples. A strong support for this conclusion is from the F2-score and recall scores indicate the model's classification confidence of predictions related to label C2 is very high.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":95.24},\\\"F2-score\\\":{\\\"Model A\\\":94.64},\\\"Sensitivity\\\":{\\\"Model A\\\":95.24},\\\"Accuracy\\\":{\\\"Model A\\\":94.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwhat balanced with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F2-score\":\"5\",\"Sensitivity\":\"5\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "Inspite of the disproportionate data distribution between the two class labels C1 and C2, the model's overall classification performance on this AI problem is high. Specifically, it has an accuracy of about 82.67%, AUC score of 87.78%, and a F2-score equal to 79.89%. These results indicate that the model has a modertately high predictive power and will be effective in terms of its prediction decsions for a number of  test cases/samples.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":87.78},\\\"F2-score\\\":{\\\"Model A\\\":79.89},\\\"Accuracy\\\":{\\\"Model A\\\":82.67},\\\"Precision\\\":{\\\"Model A\\\":80.44}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Movie Theatre Attendance",
            "id": 129,
            "narration": "The performance of the model on this binary classification problem is high as indicated by the scores achieved across all the metrics (precision, accuracy, AUC, and specificity). From the table, we can confirm that the scores are 82.67% (accuracy), 80.44% (precision), 87.78% (AUC score) and 79.78% (specificity). Judging based on the fact that it was trained on an imbalanced dataset, these results/scores are very impressive, demonstrating that the model will be effective at recognizing the observations drawn from each class or label.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":87.78},\\\"Accuracy\\\":{\\\"Model A\\\":82.67},\\\"Precision\\\":{\\\"Model A\\\":80.44},\\\"Specificity\\\":{\\\"Model A\\\":79.78}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 63% of the data belonging to class C1 and 37.0% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Specificity\":\"4\",\"AUC\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "Grouping the examples into two distinct classes (i.e. C1 and C2) was the goal of training the classifier on the balanced dataset. From the table, we can see that it has a Specificity, Sensitivity and F2-score, respectively,  equal to 75.0%, 84.38% and 76.09%. Furthermore, the accuracy score of its prediction output shows that is correct about 80.0% accurate at times. Overall these scores achieved show that it has fairly high confidence in its prediction decision implying that it is likely going to misclassify only a few samples of the test cases.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":75.0},\\\"Sensitivity\\\":{\\\"Model A\\\":84.38},\\\"F2-score\\\":{\\\"Model A\\\":76.09},\\\"Accuracy\\\":{\\\"Model A\\\":80.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model was trained on this balanced dataset to separate test samples according to their respective class labels. The class labels were C1 and C2. Assessment of the classification performance showed that the classifier has an AUC score of 87.17%, F2-score of 76.09, Sensitivity score of 75.6%,  with the Specificity score equal to 84.96%. These scores are quite high implying that the classifier will likely have a low misclassification error rate and can accurately determine the true class labels for a moderate proportion of the test samples.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.6},\\\"Specificity\\\":{\\\"Model A\\\":84.96},\\\"F2-score\\\":{\\\"Model A\\\":76.09},\\\"AUC\\\":{\\\"Model A\\\":87.17}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"F2-score\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier's performance evaluation scores are: accuracy is 70.0%,  a recall of 69.86, a precision score of 69.70% and an F1-score of 69.48% on the given multi-class ML task where it was trained to assign test cases to either C1 or C2 or C3. Surprisingly, these scores are very similar to each other which goes to show that this model has a moderately good understanding of the task and will be able to correctly identify a fair amount of test examples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.70},\\\"F1-score\\\":{\\\"Model A\\\":69.48},\\\"Recall\\\":{\\\"Model A\\\":69.86},\\\"Accuracy\\\":{\\\"Model A\\\":70.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "On the given multi-class ML task where it was trained to assign test cases to either C1 or C2 or C3, the trained classifier obtained the evaluation scores following: Accuracy is equal to 68.33, a recall score is 68.27 with the F2-score equal to 69.48%. Judging based on the scores, this model is shown to have a moderate classification performance on the task implying that it can manage to correctly identify a fair amount of test examples with a somewhat small chance of misclassification.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":69.48},\\\"Recall\\\":{\\\"Model A\\\":68.27},\\\"Accuracy\\\":{\\\"Model A\\\":68.33}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "This classifier achieved the scores: (1) Accuracy equal to 78.05%, (2) Recall score of 36.84% and (3) Precision score of 43.75%  on a classification problem where it was trained to assign one of the following class labels (C1, C2 and C3) to test instances/samples. Overall, the accuracy shows that the model can correctly identify a large number of test cases, however, the precision and recall score indicates the model will struggle with difficult test cases that are not easily distinguishable. There is more room for improvement before this model can start making meaningful classifications. Approaches improving the recall and precision scores should be explored which in term will further enhance the accuracy of the classifier.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":43.75},\\\"Recall\\\":{\\\"Model A\\\":36.84},\\\"Accuracy\\\":{\\\"Model A\\\":78.05}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"3\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The AUC, accuracy, precision, F2-score and recall scores achieved on this binary classification task are 90.96%, 81.67%, 82.32%, 81.83% and 82.14, respectively. These scores are impressive regardless of the fact that the classifier was trained on a balanced dataset. A possible conclusion on the overall classification performance of the model as suggested by the scores is that it will be able to accurately and precisely output the true class label for several test instances.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":82.32},\\\"AUC\\\":{\\\"Model A\\\":90.96},\\\"F2-score\\\":{\\\"Model A\\\":81.81},\\\"Recall\\\":{\\\"Model A\\\":82.14},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> </p>The dataset is balanced identical proportion of the data belonging to class C1,  and C2 ",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"AUC\":\"5\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "In simple terms, the model's performance on this binary classification task can be summarized as moderately high. This is based on the classifier achieving a predictive accuracy of 78.33%, an AUC score of 85.86 with Sensitivity and Specificity scores equal to 85.71% and 71.88%, respectively. The Specificity and Sensitivity scores demonstrate that a fair amount of positive and negative test cases can be correctly identified.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.86},\\\"Sensitivity\\\":{\\\"Model A\\\":85.71},\\\"Accuracy\\\":{\\\"Model A\\\":78.33},\\\"Specificity\\\":{\\\"Model A\\\":71.88}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> </p>The dataset is balanced identical proportion of the data belonging to class C1,  and C2 ",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"4\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "In simple terms, the model achieved a moderate predictive performance on this binary ML where it was trained to assign one of the two class labels (C1 and C2)  to test samples.  The judgement above is based on the model achieving a precision score of 76.92%, Sensitivity score of 71.43% and Specificity score of 81.25%. These scores further show that the model is able to accurately set apart a large number of examples belonging to the positive class (C2) and the negative class (C1) labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.92},\\\"Sensitivity\\\":{\\\"Model A\\\":71.43},\\\"Specificity\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> </p>The dataset is balanced identical proportion of the data belonging to class C1,  and C2 ",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The training of this classifier was done with a balanced dataset where there is a close to an equal number of samples from each of the two-class labels. The metrics along with their respective scores are: (1) Accuracy score = 80.0%, (2) Sensitivity score = 75.0%, (3) Precision score = 80.77% and (4) F1-score = 77.78%. These scores show that the model performs quite well on the classification task. Its precision and F1-score shows that the false positive rate is lower which goes further to show that the classifier will be able to separate between the positive and negative test cases more accurately.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.77},\\\"F1-score\\\":{\\\"Model A\\\":77.78},\\\"Sensitivity\\\":{\\\"Model A\\\":75.0},\\\"Accuracy\\\":{\\\"Model A\\\":80.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier was trained on a balanced dataset to correctly separate the examples into two different classes (i.e. C1 and C2). The classification performance or prowess of the given classifier can be summarized as it has a prediction accuracy of 80.0%, AUC score equal to 87.17% with the F1-score equal to 77.78%. What these scores tell us about the model is that it can accurately produce the correct labels for a large proportion of test examples drawn from both classes. Overall, it has a moderate to high classification performance implying the confidence in its predictive decision will be at an acceptable level in most cases.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":87.17},\\\"F1-score\\\":{\\\"Model A\\\":77.78},\\\"Accuracy\\\":{\\\"Model A\\\":80.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "With the model achieving a precision score of 76.92%, Sensitivity score of 71.43%, Specificity score of 81.25%, and prediction accuracy of 76.67,  its performance can be summarized as moderately high. This implies it can generate the true labels for several test examples belonging to the positive class (C2) and the negative class (C1) labels. The difference in precision, sensitivity, and specificity also indicate that the classifier is quite confident with its predictive decisions across multiple test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.92},\\\"Accuracy\\\":{\\\"Model A\\\":76.67},\\\"Sensitivity\\\":{\\\"Model A\\\":71.43},\\\"Specificity\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> </p>The dataset is balanced identical proportion of the data belonging to class C1,  and C2 ",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Accuracy\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 88,
            "narration": "On the classification task under consideration, the model attains an accuracy of 81.5%, with the recall and precision equal to 81.25% and 41.61, respectively. These scores clearly indicate that this model will be less precise at sorting out (separating) test observations or cases belonging to class C2. Some of the C2 predictions are wrong, due to the model having a moderately high false-positive rate (looking at the precision and recall scores).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "R0@26-@FTMC-EN9A8-88-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 45.61 and Accuracy of 81.5. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 98,
            "narration": "Close to perfect scores were achieved across all the metrics under consideration (precision, AUC, accuracy, and recall). To be specific, the accuracy achieved was equal to 95.58%, 98.04% was scored for the AUC, with the recall and precision equal to 92.16 and 87.78, respectively. From these high scores, we can be assured that this model will be highly effective and precise at correctly assigning the true labels for the test cases/cases with a marginal misclassification error rate. Finally, looking at precision and recall scores, the model is shown to have a very low false-positive rate.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.16},\\\"Accuracy\\\":{\\\"Model A\\\":95.58},\\\"AUC\\\":{\\\"Model A\\\":98.04},\\\"Precision\\\":{\\\"Model A\\\":87.78}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "2JQ1J-TJQAL-DYGW6_98-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Insurance Churn",
            "id": 101,
            "narration": "The model secured or obtained a predictive accuracy of about 90.46% and an AUC of 92.22%. The recall and precision scores, respectively, equaled 66.92% and 34.14%. In terms of these metrics' scores, the model is shown to have somewhat low confidence in its prediction decisions. Overall, the model will likely be less effective (than expected) pertaining to identifying the true labels for the majority of test cases associated with the different classes considered under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":34.14},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"Accuracy\\\":{\\\"Model A\\\":90.46}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "MJF2R-9QC89-AV7KM_101-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Insurance Churn",
            "id": 101,
            "narration": "The performance of the model on this classification task as evaluated based on the precision, AUC, accuracy, and recall achieved the scores of 34.14%, 92.22%, 66.92%, and 90.46% respectively. These scores were achieved on an imbalanced dataset. Therefore, from the precision and recall scores, we can make the conclusion that this model will perform poorly in terms of correctly picking out which test example belongs to class C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":34.14},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"Accuracy\\\":{\\\"Model A\\\":90.46}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "MJF2R-9QC89-AV7KM_101-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "The prediction performance of the algorithm on this binary classification task as assessed based on the accuracy, recall, and precision scored 74.26%, 76.21%, and 73.71%, respectively. These scores support the conclusion that this model is fairly precise and effective in terms of the prediction decisions for the examples from the class labels C1 and C2. The model has moderately low false positive and false-negative error rates as indicated by the precision and recall scores.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "The classification model trained on this artificial intelligence problem achieved quite identical scores across all the metrics, with the prediction accuracy equal to 74.26% with the recall (aka sensitivity) score and precision score equal to 76.21% and 73.71%, respectively. These scores indicate that this model will be moderately effective and precise with regards to labeling the test cases drawn from any of the classes (C1 and C2) under consideration. In other words, it can correctly assign the correct label for the majority of test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 106,
            "narration": "With a larger proportion of the dataset belonging to the class label C1, the model has an accuracy of 99.92, recall of 87.67 and a low precision score of 63.37% with a moderate F1-score of about 73.56%.  With such imbalanced classification problem, the accuracy score marginally better than the alternative model that constantly assigns the majority class label C1 to any given test case. In conclusion, this model has a very poor classification considering the F1-score and precision score achieved.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":73.56},\\\"Precision\\\":{\\\"Model A\\\":63.37},\\\"Accuracy\\\":{\\\"Model A\\\":99.92},\\\"Recall\\\":{\\\"Model A\\\":87.67}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "R632M-@BR@0-QWQQ0_106-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, F1-score, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 63.37 and Recall of 87.67. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 106,
            "narration": "The model obtained an F1-score of 73.56,  apredictive accuracy of 99.92 with the recall and precision equal to 87.67 and 63.37, respectively. Judging by the scores achieved, we can conclude that this model has a lower performance as it is not be able to correctly predict the actual labels of multiple test examples. Furthermore, the accuracy score is only marginally higher than the dummy model constantly assigning the majority class label C1 to any given test case.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":73.56},\\\"Precision\\\":{\\\"Model A\\\":63.37},\\\"Accuracy\\\":{\\\"Model A\\\":99.92},\\\"Recall\\\":{\\\"Model A\\\":87.67}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "R632M-@BR@0-QWQQ0_106-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, F1-score, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 63.37 and Recall of 87.67. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 109,
            "narration": "In the context of this binary machine learning problem where the test instances are classified as either C1 or C2, the evaluation performance scores achieved by the classifier  are 66.18% (accuracy), 60.32% (precision), and 62.3% (F1-score). From these scores, we can see that the prediction capability of the classifier is moderate and that a significant number of test cases are likely to be misclassified.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":62.3},\\\"Accuracy\\\":{\\\"Model A\\\":66.18}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 109,
            "narration": "The performance of the model on this AI problem as evaluated based on accuracy, precision, and  F1-score scored: 66.18%, 60.32% and 62.3%, respectively. On the basis of the scores stated above, we can conclude that this model has a moderate classification performance hence the classifier will be moderately effective at accurately differentiating between the examples or observations drawn from any of the different classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":62.3},\\\"Accuracy\\\":{\\\"Model A\\\":66.18}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 110,
            "narration": "The classifier has an accuracy score of 81.5%, with the recall and precision scores equal to 81.25% and 41.61, respectively on this classification task. These scores clearly indicate that this model will be less precise at correctly separating out the cases belonging to the different labels. Furthermore, the precision and recall scores show that the model has a moderately high false positive rate than expected.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Recall\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WN6X6-PL20R-937TG-110-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"2\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 111,
            "narration": "The classifier's performance or prowess was evaluated based on the following evaluation metrics: F1-score, recall, precision, and accuracy. For the accuracy, the model's score is 98.42%, for the precision it scored 91.43% with the recall score equal to 94.12%. Judging based on these scores attained, it is fair to conclude that this model can accurately classify several test cases with little misclassification error.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "J@PN2-LPKE4-NMUMQ_111-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 100,
            "narration": "The following are the evaluation scores achieved by the classifier on this machine learning classification task: Accuracy of 77.0%, precision score of 35.29%, F1-score of 43.36% and recall equal to 56.22%. Judging by the scores across the metrics, this model is shown to be not that effective at correctly choosing the right labels for test cases belonging to any of the class labels. The confidence for predictions of C2 is very low given the many false positive prediction decisions (considering the recall and precision scores). With the dataset being this imbalanced, the accuracy score is only marginally higher than the dummy model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":35.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":56.22},\\\"F1-score\\\":{\\\"Model A\\\":43.36}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "10A60-N8DAW-QB0HF-100-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 100,
            "narration": "This model did not perform well, with very low F1-score (43.36%) and precision (35.29%). The accuracy (77.0%) is not significantly better than the alternative model that constantly assigns the majority class label C1 to any given test case. Considering the disproportionate nature of the dataset, a high accuracy of 77.05% is less impressive. A recall of 56.22% and precision of 35.29% imply that the model's prediction decisions shouldn't be taken on the face value (i.e. the confidence level of the labels assigned is very low).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":35.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":56.22},\\\"F1-score\\\":{\\\"Model A\\\":43.36}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "10A60-N8DAW-QB0HF-100-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 100,
            "narration": "The ML algorithm's classification prowess or ability is outlined by the following scores: (a) Accuracy: 77.0%. (b) Precision: 35.29%. (c) Recall: 56.22%. Besides, this model has an F1-score of 43.36%. Judging from the scores across the metrics, we can conclude that the algorithm employed here will be less effective at accurately assigning labels to cases associated with any of the labels (C1 and C2). Since the dataset is severely imbalanced, the accuracy score is only marginally better than random choice.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":35.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":56.22},\\\"F1-score\\\":{\\\"Model A\\\":43.36}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "10A60-N8DAW-QB0HF-100-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 103,
            "narration": "On this binary classification task, the trained classifier achieved recall, accuracy, AUC, and precision scores of 77.59%, 84.78%, 91.11%, and 84.91%, respectively. With such moderately high scores across the metrics, the model is somewhat certain to have a lower misclassification error rate. The model assigns the C2 less frequently; hence, whenever it outputs this label, it is usually correct. Overall, the metrics' scores show that this classifier will be relatively effective at separating the examples under the different classes, C1 and C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"Accuracy\\\":{\\\"Model A\\\":84.78},\\\"AUC\\\":{\\\"Model A\\\":91.11}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and Precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 103,
            "narration": "On this binary classification task with a balanced dataset, the classifier has an accuracy of 84.78% with the AUC, recall and precision scores, respectively equal to 91.11%, 77.59%, and 84.91%. These results/scores are impressive as one can conclude that this model is an effective classifier with high confidence in its prediction decisions. In summary, only a small number of test cases are likely to be misclassified as indicated by the accuracy, recall and precision.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"Accuracy\\\":{\\\"Model A\\\":84.78},\\\"AUC\\\":{\\\"Model A\\\":91.11}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and Precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 103,
            "narration": "The model trained solve the given classification problem has the following prediction performance scores:  accuracy of 88.15% with the AUC, recall and precision, respectively, equal to 93.45%, 77.59% and 86.13%. The precision and recall scores show how good the model is at partitioning and classifying correctly the majority of the test samples. In essence, we can assert that this model will be effective at accurately generating the true labels for the examples drawn from the different classes.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":86.13},\\\"Accuracy\\\":{\\\"Model A\\\":88.15},\\\"AUC\\\":{\\\"Model A\\\":93.45}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and Precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Paris House Classification",
            "id": 135,
            "narration": "For this machine learning classification problem the test instances are classified as either C1 or C2. The model's performance assessment scores are as follows: Accuracy (93.38%), Recall (78.64%), precision (88.94%) and finally, an F1-score of 83.48%. Judging by the scores attained, it is fair to conclude that this model can accurately classify a greater number of test cases with a small set of instances misclassified. Overall, the model is relatively confident with its prediction decisions for test samples from the two classes under consideration.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.64},\\\"Precision\\\":{\\\"Model A\\\":88.94},\\\"F1-score\\\":{\\\"Model A\\\":83.48}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "B92UV-6LCVQ-AA1P5_135-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 135,
            "narration": "The machine learning model's performance scores on the binary classification problem or task under consideration are as follows: Accuracy (93.38%), Recall (78.64%), and a Precision score of 88.94%. As summarized by the scores, the model outperforms the dummy model that constantly assigns C1 to any given test instance/case. Overall, this model shows signs of effectively learning the features required to accurately or correctly tell-apart the observations belonging to each label under consideration. A large number of test cases can be correctly labeled by this model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.64},\\\"Precision\\\":{\\\"Model A\\\":88.94},\\\"F1-score\\\":{\\\"Model A\\\":83.48}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "B92UV-6LCVQ-AA1P5_135-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 181,
            "narration": "On this four-way multi-class classification problem, the model achieved close to perfect scores across all the metrics under consideration (i.e., precision, accuracy, and recall). From the table shown, we can see that it has an accuracy of about 95.8% suggesting a very low misclassification error rate. Furthermore, the precision score of 95.78% is very identical to the recall score of 95.84%. Therefore, it is fair to conclude that the classification performance of this model is very high and will be very effective at correctly labeling examples or observations associated with any of the classes (C1, C2, C3, and C4).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":95.78},\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Recall\\\":{\\\"Model A\\\":95.84}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "6G0KN-NX1TF-K1QTF-181-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score, Accuracy and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "86.148.95.68",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 181,
            "narration": "The model attains high scores across all the evaluation metrics on this multi-class classification problem where the model was trained to assign test samples to either C1 or C2 or C3 or C4. For the accuracy, it scored 95.8%, scored 95.78% for the precision score and 95.84% recall score. Considering all the scores, the classification performance/power of this model is shown to be quite impressive and the likelihood of misclassifying any given input test case is only marginal.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":95.78},\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Recall\\\":{\\\"Model A\\\":95.84}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "6G0KN-NX1TF-K1QTF-181-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score, Accuracy and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "86.148.95.68",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 118,
            "narration": "On the multi-class ML problem under consideration, the classifier attains high scores across all the evaluation metrics. For the accuracy, it scored 96.0%, with the precision and recall scores equal to 95.98%  and 96.08% respectively. These identical scores suggest that the model is very well balanced amongst the four class labels (C1, C2, C3 and C4). In essence, we can confidently conclude that this model will be highly effective at assigning the true labels for several test cases.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 118,
            "narration": "On the multi-class ML problem under consideration (where training objective is to assign test samples to either C1 or C2 or C3 or C4), the classifier is shown to attain high evaluation scores across all the metrics employed for its performance assessment. For the accuracy, it scored 93.45%, the precision it scored 96.08% with an F1-score equal to 95.08%, respectively. These identical scores suggest that the model is very well balanced amongst the four class labels (C1, C2, C3 and C4) with high confidence in its prediction decisions. Overall, we can conclude that this model will be highly effective at assigning the true labels for several test cases with the likelihood of misclassification very low.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.45},\\\"Precision-score\\\":{\\\"Model A\\\":96.08},\\\"F1-score\\\":{\\\"Model A\\\":95.08}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 147,
            "narration": "The classification algorithm trained on this ML task achieved an accuracy of 82.7%, with the AUC, recall, and precision scores equal to 88.67%, 77.52%, and 84.66%, respectively. These scores support the conclusion that this model will be highly effective at accurately or correctly labeling a large number of test cases drawn from the any of the labels, C1 and C2. Furthermore, from the recall (sensitivity) and precision scores, the model is shown to have a lower false-positive rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 147,
            "narration": "The machine learning classifier trained trained to solve the given AI task achieved an accuracy, the AUC, recall and precision scores of 82.7%, 88.67, 77.52 and 85.66, respectively. With such high scores across the metrics, we can be certained that this model will be able to predict the correct class labels of most test examples. In other words, it would be safe to say that the model has almost perfect performance with a very low classification error rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The performance of the model on this binary classification task as evaluated based on the F2-score, sensitivity, AUC, and specificity scored 76.09%, 75.6%, 87.17%, 85.6 and 84.96%, respectively. These scores suggest that the classification performance can be summarized as moderately high and can accurately assign the true labels for most of the test samples, however, it is not a perfect model hence it will misclassify a number of test instances.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.6},\\\"Specificity\\\":{\\\"Model A\\\":84.96},\\\"F2-score\\\":{\\\"Model A\\\":76.09},\\\"AUC\\\":{\\\"Model A\\\":87.17}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"F2-score\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The scores achieved by the learning algorithm on this binary classification task are: (1) AUC score of 87.17%, (2) Specificity score equal to 84.96%, (3) Sensitivity score (i.e. Recall) is 75.6% with an F2-score of 76.09. The F2-score, Sensitivity and Specificity scores indicate that the likelihood of misclassifying test samples is low leading to a higher confidence in prediction output decisions for the examples under the different label. Since these scores are not that pperfect the might be able to assign the actual labels for a number of test cases.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.6},\\\"Specificity\\\":{\\\"Model A\\\":84.96},\\\"F2-score\\\":{\\\"Model A\\\":76.09},\\\"AUC\\\":{\\\"Model A\\\":87.17}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"F2-score\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The performance of the classifier on this binary classification problem is: it has an AUC score of 87.17%, a specificity score equal to 84.96%, Sensitivity score (sometimes referred to as the recall score) is 76.09%. These scores across the different metrics suggest that this model can effectively assign or identify the correct class labels for a large proportion of test case. Finally, the false positive and negative rates are lower which further indicate that the likelihood of examples belonging to label C1 being misclassified as C2 is low and vice-versa.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.6},\\\"Specificity\\\":{\\\"Model A\\\":84.96},\\\"F2-score\\\":{\\\"Model A\\\":76.09},\\\"AUC\\\":{\\\"Model A\\\":87.17}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"F2-score\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model was trained to assign test cases to either C1 or C2 or C3. The following are the evaluation scores  obtained across the different metrics: Accuracy is equal to 68.33, Recall score is 68.27 with the F2-score equal to 69.48%. Judging based on the scores, this model is shown to have a moderate classification performance on this ML task indicating that it can manage to accurately identify and assign the correct labels for a number of test examples with a small margin of misclassification error.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":69.48},\\\"Recall\\\":{\\\"Model A\\\":68.27},\\\"Accuracy\\\":{\\\"Model A\\\":68.33}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model's classification prowess on this machine learning task (where the test samples are assigned either class label C1 or class label C2) is accuracy (81.67%), recall (81.92%), and precision (82.47%).  This classifier has a high classification or prediction performance which implies that it is fairly or relatively effective at correctly separating apart the examples or items belonging to any of the two different classes judging by these scores. Furthermore, the F2-score is about 81.66 as computed based on the recall and precision scores shows that it has a fairly low false-positive rate.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":81.66},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The effectiveness of the classifier regarding this machine learning problem where the test instances are classified as either C1 or C2 can be summarized by the following scores: 81.66% (for the F2-score), 81.67% (accuracy), 81.92% (recall score), and 82.47% (for the precision value). Judging based on the scores across the different metrics, we can make the overall conclusion that this model has a moderate classification performance hence will likely misclassify only a small number test samples drawn randomly from any of the class labels.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":81.66},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "For this classification task, the model's performance assessment scores are: accuracy (81.67%), recall (81.92%), precision (82.47%) and finally, a moderate F2-score of 81.66%. These scores support the conclusion that this model will likely be good at choosing which class label (i.e. C1 or C2) a given test example belongs. In summary, the F2-score shows that the classifier has lower false positive rate implying the confidence in predictions related to the positive class (i.e. C2) is high.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":81.66},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classification performance can be summarized as moderately high given that it achieved an accuracy of 81.67%, a  recall  score equal to 81.92%, a precision score of about 82.47% and finally, with a moderate F2-score of 81.66%. In general, based on the scores, the model can accurately identify a fair anumber of examples drawn randomly from the class labels C1 and C2. Besides, the recall and precision scores are identical further indicating that the classifier has lower false positive rate with the confidence in predictions related to the positive class label (C2) is high.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":81.66},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model has a prediction accuracy of about 81.67% with the precision and recall equal to 82.47% and 81.92%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the model performs well in terms of predicting the outcome of the test cases/instances. It has a moderate to high accuracy and F1-score which means that its prediction decisions can be reasonably trusted.        ",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":81.62},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "On the machine learning classification problem under consideration, the classifier achieved the following scores: 80.0% (accuracy), 75.0% (sensitivity), 80.77% (precision) and finally, an F1-score of 77.78%. These evaluation or assessment scores indicate that this model has a moderate classification performance hence will be less effective than expected at correctly sorting examples under or associated with any of the classes under consideration.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":77.78},\\\"Precision\\\":{\\\"Model A\\\":80.77},\\\"Sensitivity\\\":{\\\"Model A\\\":75.0},\\\"Accuracy\\\":{\\\"Model A\\\":80.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, C2 and C3",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model has a prediction accuracy of about 81.67% with the precision and recall equal to 82.47% and 81.92%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the model performs well in terms of predicting the outcome of the test cases/instances. It has a moderate to high accuracy and F1-score which means that its prediction decisions can be reasonably trusted.        ",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":81.62},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Recall\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model trained based the given classification objective achieved a sensitivity  score of 81.92% with an F1-score of about 81.62%. As shown in the metrics table, the classification model possesses the score 81.67% representing the prediction accuracy and precision scores equal to 81.82% and 82.47%, respectively. These scores are high implying that this model will be able to accurately identify and assign the true label for several test instances/samples.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":81.62},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Sensitivity\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier's performance was assessed based on the scores it achieved on the following evaluation metrics accuracy, sensitivity (recall), precision, and F1-score as shown in the table. On this binary classification problem, the classifier possesses an accuracy of about 81.67% with the associated precision, sensitivity, and F1-score equal to 82.47%, 81.92%, and 81.62%, respectively. These scores demonstrate this model will be effective in terms of its labeling power for the several test instances implying only a few test cases are likely to be misclassified.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":81.62},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Sensitivity\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The model's performance regarding this binary ML problem, where the test instances are classified as either C1 or C2, is  81.67% (accuracy), 81.62% (F1-score), 82.47% (precision score), and 81.92% (sensitivity score). This model has moderately low false positive and negative rates suggesting that the likelihood of misclassifying examples belonging to any of the two classes is very small. Overall, the model is relatively confident with its prediction decisions for test cases from the different labels under consideration. In essence, it can accurately determine the true label for most cases.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":81.62},\\\"Precision\\\":{\\\"Model A\\\":82.47},\\\"Sensitivity\\\":{\\\"Model A\\\":81.92},\\\"Accuracy\\\":{\\\"Model A\\\":81.67}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier trained to tackle the classification task achieved an accuracy of 78.0%, with the AUC, recall, and precision scores equal to 79.81%, 67.92%, and 87.8%, respectively. These scores indicate that this model will be moderately effective enough to sort between  examples from any of the different labels. Furthermore, from the recall (sensitivity) and precision scores, we can make the conclusion that it will likely have a lower false-positive rate.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":79.81},\\\"Precision\\\":{\\\"Model A\\\":87.8},\\\"Recall\\\":{\\\"Model A\\\":67.92},\\\"Accuracy\\\":{\\\"Model A\\\":78.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier on this binary classification problem, where the test instances are classified as either C1 or C2, got the following scores summarizing its prediction performance: Accuracy (78.9%); Specificity (89.36%), Precision (87.8%), and finally, F1-score of 76.6%. These scores across the different metrics suggest that this model is somewhat effective and can accurately/correctly assign the actual labels for a large proportion of test cases/instances. Overall, we can say that, the classification performance will be moderately high in most cases judging by the confidence level of the model.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":76.6},\\\"Precision\\\":{\\\"Model A\\\":87.8},\\\"Specificity\\\":{\\\"Model A\\\":89.36},\\\"Accuracy\\\":{\\\"Model A\\\":78.9}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Specificity\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "On this balanced classification task, the model was trained to assign the test samples the class label of either C1 or C2. Evaluated based on the Precision, Sensitivity, AUC, Specificity and F2-score, it scored 79.81%, 87.8%, 67.92%, 89.36%, and 71.15%, respectively. The F2-score score is a balance between the recall (sensitivity) and precision scores. In essence, we can assert that the likelihood of misclassifying test samples is quite small, which is impressive but not surprising given the data is balanced between the classes.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":71.15},\\\"Sensitivity\\\":{\\\"Model A\\\":67.92},\\\"Precision\\\":{\\\"Model A\\\":87.8},\\\"Specificity\\\":{\\\"Model A\\\":89.36},\\\"AUC\\\":{\\\"Model A\\\":79.81}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced identical proportion of the data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"F2-score\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "Evaluating the classifier's performance on this binary classification task produced the scores 83.56% for the predictive accuracy, 81.88% as the precision score with the associated sensitivity and specificity scores equal to 72.73% and 89.36%, respectively. The prediction capability of the model can be summarized as fairly accurate with a lower chance of misclassification. Besides looking at Specificity and precision scores, the confidence in predictions related to the two class labels is shown to be quite high.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":72.73},\\\"Precision\\\":{\\\"Model A\\\":81.88},\\\"Specificity\\\":{\\\"Model A\\\":89.36},\\\"Accuracy\\\":{\\\"Model A\\\":83.56}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 63% and 37% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The assessment of the classification performance of this classifier on this binary ML task produced a moderate scores 72.73%, 81.88%, 89.36%, and 83.56%, respectively, across the evaluation metrics sensitivity, precision, Specificity and Accuracy. With such high scores achieved on the imbalanced classification task, the predictive power and confidence can be summarized as moderately high hence will likely misclassify a small proportion of the test instances.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":72.73},\\\"Precision\\\":{\\\"Model A\\\":81.88},\\\"Specificity\\\":{\\\"Model A\\\":89.36},\\\"Accuracy\\\":{\\\"Model A\\\":83.56}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 63% and 37% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"3\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 197,
            "narration": "The model trained to tell-apart the labels for test observations achieved an accuracy of 72.4%, a sensitivity (recall) score of 58.62%, with the precision and AUC scores equal to 43.04 and 75.2% , respectively. These scores clearly indicate that this model will not be that effective at correctly singling out  examples belonging to any of the classes or labels. It fails to recognize most of the C2 examples. The confidence regarding the prediction output decisions for several test cases is shown to be lower.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"Precision\\\":{\\\"Model A\\\":43.04}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "56@KH-JJA19-UHKYW-197-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"2\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 197,
            "narration": "The classifier was trained on this imbalanced dataset to correctly separate the examples into two different classes (i.e. C1 and C2). The model's  performance assessment can be summarized as moderately low given the scores attained for the precision, Sensitivity, Accuracy and AUC. Respectively, it scored 43.04%, 58.62%, 72.4%, and 75.2%. In conclusion, this model will likely fail to identify the correct labels for several test instances (especially those belonging to class C2).",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"Precision\\\":{\\\"Model A\\\":43.04}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "56@KH-JJA19-UHKYW-197-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"2\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 196,
            "narration": "The classification model scored an accuracy of 94.15%, together with recall and precision scores equal to 95.92% and 32.8%, respectively, on this classification task. These scores suggest this classifier is less precise at correctly setting apart examples related to the C2 class. Furthermore, precision and recall scores show that the model has a moderately high false-positive rate. This model frequently assigns the C2; hence, a portion of C1 examples could be mislabeled as C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":95.92},\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "3ARW4-BU73N-JH74U_196-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 196,
            "narration": "The ability of the classifier to accurately perform this binary classification problem where the test instances are classified as either C1 or C2 is characterized by the following scores: Accuracy (94.15%), Recall (95.92%), and a very low Precision Score equal to 32.8%. These scores clearly indicate that this model is good at identifying the C1 examples, but it is not very good at correctly classifying the examples associated with  class C2. This is because the confidence for predictions of C2 is very low given the many false-positive prediction decisions (considering  recall and precision scores).",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":95.92},\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "3ARW4-BU73N-JH74U_196-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 196,
            "narration": "The classifier achieved an accuracy of 94.15%, with the recall and precision scores equal to 95.92% and 32.8%, respectively. Based on these metrics' scores, we can conclude that the model has a somewhat low performance as it is not be able to pick out the true labels for test cases under any of the class labels. In addition, there is little confidence in the prediction decisions of this model based on difference between the precision and recall scores,",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":95.92},\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "3ARW4-BU73N-JH74U_196-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 195,
            "narration": "The model's classification performance achieved on this binary classification problem, where the test instances are classified as either C1 or C2, is 63.97% (accuracy), 60.8% (F1-score), and 60.32% (precision). This model has a moderate classification performance which implies that it is fairly effective at correctly partitioning between examples belonging to the different classes. Furthermore, from the precision and F1-score, we can conclude that this model will likely misclassify some test samples drawn randomly from any of the two classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "AH6LX-J4826-FRTT1-195-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 195,
            "narration": "The model's predictive performance on this binary classification task was assessed based on the following evaluation metrics: accuracy, precision, and F1-score. For the accuracy, the model obtained a score of 63.97%; for the precision, it achieved 60.32% with the F1-score equal to 60.8%. Trained on a balanced dataset, these scores are not impressive, suggesting a somewhat moderate classification performance. This implies the likelihood of mislabeling a given test case is higher than expected.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "AH6LX-J4826-FRTT1-195-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 188,
            "narration": "The model has predictive accuracy equal to 81.32% with the F1-score, precision score, and recall score equal to 55.66%, 48.88%, and 64.61%, respectively. Based on scores across the different metrics under consideration, the model demonstrates a low classification ability when it comes to generating the true label for the majority of test cases. Furthermore, confidence in C2 predictions is very low given the number of false-positive predictions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.32},\\\"Recall\\\":{\\\"Model A\\\":64.61},\\\"F1-score\\\":{\\\"Model A\\\":55.66},\\\"Precision\\\":{\\\"Model A\\\":48.88}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "RXKE9-LH36N-LKDDX-188-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"2\",\"Recall\":\"3\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 188,
            "narration": "The evaluation performance of the model on this classification task, where the test samples are identified as belonging to either C1 or C2 is Accuracy (81.32%), Recall (64.61%), and a Precision score of 48.88%. With reference to these scores, one can conclude that the classification power of the learning algorithm is moderately low, suggesting the true class labels for most test examples are likely to be misclassified.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.32},\\\"Recall\\\":{\\\"Model A\\\":64.61},\\\"F1-score\\\":{\\\"Model A\\\":55.66},\\\"Precision\\\":{\\\"Model A\\\":48.88}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "RXKE9-LH36N-LKDDX-188-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"2\",\"Recall\":\"3\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 187,
            "narration": "The model's classification performance achieved on the given binary classification problem (where the test observations are classified as either C1 or C2) is summarized by the scores: recall (94.72%), accuracy (89.12%), precision (82.64%), and AUC (96.08%). In summary, these results or scores are very impressive. With the high precision and recall scores, the classification performance of the classifier can be summarized simply as good as only a small number of samples are likely to be misclassified. For example, since precision is lower than recall, we can draw the conclusion that this model frequently assigns the C2 label, of which only about 82.64% are correct.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.08},\\\"Recall\\\":{\\\"Model A\\\":94.72},\\\"Precision\\\":{\\\"Model A\\\":82.64},\\\"Accuracy\\\":{\\\"Model A\\\":89.12}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "4V4EK-7GE7G-3Y8Y2-187-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The training objective of the classifier is \"assign a class or label to instances\". A given test case is labeled as either C1 or C2. Evaluation of the classification performance is summarized as follows: the model boasts a classification accuracy of 84.0%; a moderate recall or sensitivity score equal to 67.74% with a precision score equal to 77.78%. Furthermore, a high true negative rate (i.e., the Specificity which indicates the model's ability to correctly identify cases belonging to class C1) score equal to 91.32% was achieved. Judging based on the sensitivity, specificity, and precision scores, this model demonstrates a moderately high classification performance implying it can correctly identify the actual labels for a large proportion of test cases with the margin of misclassification error very low.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":67.74},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Specificity\\\":{\\\"Model A\\\":91.32},\\\"Accuracy\\\":{\\\"Model A\\\":84.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 68% and 31% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier was specifically trained to assign test cases or instances to one of the two class labels C1 and C2. With the dataset being disproportionate, the model's ability to correctly classify test cases belonging to C1 and C2 is of greater importance. Therefore, only the specificity, sensitivity, and precision scores will be considered in this evaluation assessment. From the metrics table, the model has a very high score for specificity (i.e. 91.32%), moderately high scores for precision (77.78%), and sensitivity (67.74%). Overall, these scores indicate that the model can accurately produce the true class label for a large proportion of test examples with moderately high confidence in the prediction decision.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":67.74},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Specificity\\\":{\\\"Model A\\\":91.32},\\\"Accuracy\\\":{\\\"Model A\\\":84.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 68% and 31% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "On this imbalanced dataset, the training objective of the classifier is assigning test examples to one of the two class labels under consideration. The performance assessment conducted showed that the model has a predictive accuracy of about 84.0%, an AUC score of 83.31%, a precision score equal to 77.78%, and a recall score equal to 67.74%. These evaluation scores show that the model has a moderate to high classification performance. The precision and recall scores show that the model has a very good ability to identify most test instances belonging to the positive class C2 while maintaining a higher ability to accurately identify the negative test cases as summarized by the high specificity score of 91.32%.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":83.31},\\\"Recall\\\":{\\\"Model A\\\":67.74},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Specificity\\\":{\\\"Model A\\\":91.32},\\\"Accuracy\\\":{\\\"Model A\\\":84.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 68% and 31% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classifier is employed here to determine the true class labels for test cases. A test case can be earmarked as belonging to either class label C1 or C2. Model performance assessment conducted showed that the model has a classification accuracy of about 84.08% with a corresponding high AUC score of 85.86%. In addition, the F1-score (a balance between the model's precision and recall scores) is equal to 72.41% and the specificity(the true negative rate i.e. the model's ability to correctly identify the C1's test cases) is equal to 91.32%. These moderately high scores shows suggest the model will be somewhat effective at picking the true class labels for several test examples while failing to classify only a small proportion of test cases.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.86},\\\"F1-score\\\":{\\\"Model A\\\":72.41},\\\"Specificity\\\":{\\\"Model A\\\":91.32},\\\"Accuracy\\\":{\\\"Model A\\\":84.08}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 68% and 31% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"4\",\"F1-score\":\"3\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The training of the classifier on this dataset was conducted to correctly separate the test cases belonging to the class label C1 and class label C2. The scores achieved by the classifier demonstrating its classification performance are (1) Accuracy equal to 84.08%, (2) Specificity score of 91.32%, (3) AUC score of 85.86%, and (4) F1-score of 72.41%. Judging by the scores, the classifier demonstrates a moderate classification performance hence can somewhat tell apart the examples belonging to class C1 from those of C2 with a marginal likelihood of misclassification.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.86},\\\"F1-score\\\":{\\\"Model A\\\":72.41},\\\"Specificity\\\":{\\\"Model A\\\":91.32},\\\"Accuracy\\\":{\\\"Model A\\\":84.08}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 68% and 31% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"4\",\"F1-score\":\"3\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "Trained to pick out test samples belonging to class C2 from those under C1, this classifier achieved a sensitivity score of about 71.43%, a moderately high specificity score equal to 82.35%, and a moderate F1-score equal to 75.27%. In terms of the accuracy of the model, it scored 77.0%. The model demonstrates a propensity of being able to correctly identify the true classes for a large number of test cases under each of the respective classes. The F1-score  and Specificity scores show a moderate level of confidence with regard to the model's predictive decisions.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":71.43},\\\"F1-score\\\":{\\\"Model A\\\":75.27},\\\"Specificity\\\":{\\\"Model A\\\":82.35},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced 53% and 47% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "Separating the test samples belonging to class label C2 from those under C1 was the training objective of the classifier on this binary classification task. The classification performance scores achieved across the metrics Specificity, Accuracy, Sensitivity, and F1-score, respectively, are 82.35%, 77.0%, 71.43, and 75.27%. These scores indicate a model with a moderate ability to assign the appropriate label for multiple test examples. In most cases, this classifier will be able to correctly classify the test instances with a moderate to high confidence in the output prediction decision.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":71.43},\\\"F1-score\\\":{\\\"Model A\\\":75.27},\\\"Specificity\\\":{\\\"Model A\\\":82.35},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced 53% and 47% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "Identifying the true class labels (C1 or C2) for test cases was the objective used to train this classifier. The performance evaluation scores achieved are a Recall score of 71.43%, a Precision score equal to 79.55%, an Accuracy score of 77.0%, and a Specificity score of 82.35%. These scores are moderate indicating the model will be somewhat effective in the matter of most prediction decisions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":71.43},\\\"Precision\\\":{\\\"Model A\\\":79.55},\\\"Specificity\\\":{\\\"Model A\\\":82.35},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced 53% and 47% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Sentiment Classification",
            "id": 129,
            "narration": "The classification performance of this learning algorithm can be summarized as follows: (a) Recall = 71.43% (b) Precision = 79.55% (c) AUC score = 83.35% (d) Accuracy = 77.0%. Judging based on the scores, the model demonstrates a moderately high classification performance. This implies that this classifier is quite effective at separating the examples belonging to class label C1 from the examples under the alternative label, C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":71.43},\\\"Precision\\\":{\\\"Model A\\\":79.55},\\\"AUC\\\":{\\\"Model A\\\":83.35},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced 53% and 47% data belonging to class C1, and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "We can be sum up the overall classification ability of the classifier  as follows: (a) F1-score = 82.06%. (b) Precision = 78.25%. (c) Accuracy = 89.19%.  (d) Recall = 87.12%.  Judging based on the scores, the model demonstrates a moderately high classification performance. This suggests that this classifier will be quite effective at separating the examples belonging to each of the class labels under consideration (i.e. C1, C2, and C3).",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.12},\\\"Precision\\\":{\\\"Model A\\\":78.25},\\\"F1-score\\\":{\\\"Model A\\\":82.06},\\\"Accuracy\\\":{\\\"Model A\\\":89.19}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The modeling objective used to train the classifier was separating examples under the three-class labels C1, C2, and C3.  The classifier's performance as evaluated based on the Recall, Precision, F1-score, and Accuracy suggest that it is quite effective and will be able to correctly identify the actual label for most of the test instances. Specifically, the classifier achieved the scores (a) Precision = 78.25%. (b) Accuracy = 89.19%. (c) Recall = 87.12%. (d) F1-score = 82.06%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.25},\\\"F1-score\\\":{\\\"Model A\\\":82.06},\\\"Recall\\\":{\\\"Model A\\\":87.12},\\\"Accuracy\\\":{\\\"Model A\\\":89.19}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The model training objective was separating examples belonging to the class labels C1, C2, and C3.  The model's classification performance assessed based on the Recall score, Precision score, F1-score, and predictive Accuracy indicates that it is very effective at correctly picking the actual label for several test examples. The above statement can be attributed to the fact the classifier achieved near-perfect scores across all the evaluation metrics under consideration. Specifically,  the prediction Recall is equal to 96.44%, the Precision score is 96.46%, the accuracy of predictions made is 97.31% with the F1-score equal to 96.34%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":96.46},\\\"F1-score\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":96.44},\\\"Accuracy\\\":{\\\"Model A\\\":97.31}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The model's classification performance analyzed based on the Precision score, Recall score, F1-score, and predictive Accuracy show that it is highly effective and precise implying it will be able to correctly identify the actual/true label for most of the test examples. Furthermore, the likelihood of misclassification is at a very acceptable level (i.e. very low).  The above assessments and conclusions can be attributed to the fact the classifier achieved near-perfect scores across all the evaluation metrics under consideration. Specifically,  the Recall is equal to 96.44%, the Precision score is 96.46%, the accuracy of predictions made is 97.31% with the F1-score equal to 96.34%. Note that the model training objective was separating examples belonging to the class labels C1, C2, and C3.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":96.46},\\\"F1-score\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":96.44},\\\"Accuracy\\\":{\\\"Model A\\\":97.31}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "This classifier demonstrates a very high classification ability considering the fact that the Precision score, Recall score, F1-score, and predictive Accuracy are all near-perfect. The scores across these metrics imply that the classifier has the propensity to correctly identify the true label for most of the test examples belonging to any of the class labels C1, C2, and C3. Furthermore, the near-perfect accuracy and F1-scores show that likelihood of misclassification is very low. To be specific,  the Recall is equal to 97.17%, the Precision score is 97.14% with the F1-score equal to 97.13%, and finally, the accuracy of predictions made is 98.47%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":97.14},\\\"F1-score\\\":{\\\"Model A\\\":97.13},\\\"Recall\\\":{\\\"Model A\\\":97.17},\\\"Accuracy\\\":{\\\"Model A\\\":98.47}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "(a) Recall equal to 97.17%, (b) Precision score equal 97.14%, (c) F1-score equal to 97.13%, and (d) Accuracy equal to 98.47% are the evaluation metrics' scores achieved by the classifier trained on the task of assigning one of the three-class labels (C1, C2, and C3) to test examples. This classifier demonstrates a very high classification ability given that the Precision score, Recall score, F1-score, and predictive Accuracy are close-to-perfect. The scores across these metrics allude to fact that the classifier has a good understanding of the classification objective and can correctly identify the true labels for the majority of test examples under any of the class labels C1, C2, and C3. Furthermore, the F1-score and accuracy show that likelihood of incorrect predictions is very low.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":97.13},\\\"Recall\\\":{\\\"Model A\\\":97.17},\\\"Precision\\\":{\\\"Model A\\\":97.14},\\\"Accuracy\\\":{\\\"Model A\\\":98.47}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The evaluation metrics' scores achieved by the model trained to classify test examples under one of the three-class labels (C1, C2, and C3) are as follows: a. Recall equal to 93.27%, b. Precision score equal 88.88%, c. Accuracy is equal to 94.52% and d. F1-score equal to 90.95%. This classifier demonstrates a relatively high classification performance given the scores achieved across the evaluation/assessment metrics. In fact, the scores strongly demonstrate that the classifier has a good understanding of the objective of the classification task and can correctly predict the true labels for most of the test examples. Besides, the F1-score and accuracy show that the confidence in the output prediction decisions is very high.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":90.95},\\\"Recall\\\":{\\\"Model A\\\":93.27},\\\"Precision\\\":{\\\"Model A\\\":88.88},\\\"Accuracy\\\":{\\\"Model A\\\":94.52}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The scores of the evaluation metrics obtained by the model trained to classify test samples under one of the three-class labels (C1, C2, and C3) are: (a) Precision score equal to 88.88% (b) Recall equals 93.27%  (c) accuracy is equal to 94.52% (d) F1-score is equal to 90.95%. This classifier shows a relatively high classification performance in light of the scores achieved across the different evaluation metrics. Actually, the scores fairly indicate that the classifier has a good understanding of the purpose of the classification task and can (in most cases) correctly predict the true labels for the majority of test samples. Moreover, the F1-score and accuracy indicate that the classifier has high confidence in the majority of the output prediction decisions.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":90.95},\\\"Recall\\\":{\\\"Model A\\\":93.27},\\\"Precision\\\":{\\\"Model A\\\":88.88},\\\"Accuracy\\\":{\\\"Model A\\\":94.52}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "Evluation metric scores obtained by a model trained to classify test samples based on the three class labels (C1, C2, and C3) were  a precision score of 88.88%, a recall score of 93.27%, the accuracy score is equal to 94.52% with  the F1-score equal to 90.95%. In the context classification problem or task, this model is shown to have a relatively high classification performance in the light of the scores achieved across the metrics under consideration. In fact, the scores show that the classifier is able to capture the necessary features from the data to achieve the high of the classification performance on this task and in most cases, it can predict the true label  the test samples. In summary, the F1-score and accuracy indicate that the classifier is relatively reliable when it comes to the output prediction decisions.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":90.95},\\\"Recall\\\":{\\\"Model A\\\":93.27},\\\"Precision\\\":{\\\"Model A\\\":88.88},\\\"Accuracy\\\":{\\\"Model A\\\":94.52}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Featal Health Classification",
            "id": 129,
            "narration": "The purpose of the model training was to tell-apart the examples belonging to class labels C1, C2, and C3. We found that the classification power of the model evaluated based on recall, precision, F1-score, and prediction accuracy is very good at correctly choosing the true labels of several test examples. The above statement may be due to the fact that the classifier achieved near-perfect scores across all evaluation metrics under consideration. Specifically, the prediction recall is 96.44%, the precision score is 96.46%, the prediction accuracy is 97.31%, and the F1-score is 96.34%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":96.46},\\\"F1-score\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":96.44},\\\"Accuracy\\\":{\\\"Model A\\\":97.31}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Trained to recognize the samples belonging to the class labels C1, C2, and C3, the evaluation scores achieved by the classification model is: accuracy score equal to 85.90%, F2-score equal to 82.92%, with the precision and recall equal to 75.18%, and 85.97%, respectively. Judging by the scores, the model is shown to have a moderate to high classification power, hence, in most cases will be able to generate the actual label for the test samples. Overall, this model will likely have quite a low misclassification error rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"F2-score\\\":{\\\"Model A\\\":82.92},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.90}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The evaluation scores achieved by the classifier are as follows: it has an accuracy score equal to 85.90%, F2-score equal to 82.92%, with the precision and recall equal to 75.18%, and 85.97%, respectively. Judging by the scores and the training objective of this ML task (i.e. to make out the samples belonging to the class labels C1, C2, and C3), the model is shown to be effective and is precise with its prediction decisions in most cases, hence, will be able to produce the actual label for the test instances with quite a low misclassification error rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"F2-score\\\":{\\\"Model A\\\":82.92},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.90}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "This model was specifically trained to separate the examples belonging to any of the three classes (c1, C2, and C3) from the rest of the population. This model is shown to be able to do just that with a small margin of misclassification error. The statement above is based on the fact that it achieved high scores when evaluated based on the metrics F2-score, precision, recall, and predictive accuracy. That is, the classifier boasts of classification accuracy of about 93.89%, a recall score of 91.12%, a precision score equal to 88.47%, and an F2-score of 90.63%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.47},\\\"F2-score\\\":{\\\"Model A\\\":90.63},\\\"Recall\\\":{\\\"Model A\\\":91.12},\\\"Accuracy\\\":{\\\"Model A\\\":93.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"F2-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The machine learning model boasts of classification accuracy of about 93.89%, with recall score, precision score and F2-score equal to 91.12%, 88.47%,  90.63%, respectively. It should be noted that the training objective of this classification problem is separating test cases under the class labels C1, C2 and C3. From the scores across the different metrics, the model demonstrates a fairly high understanding of the task and in most cases can produce the true labels of the test cases with a small margin of error.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.47},\\\"F2-score\\\":{\\\"Model A\\\":90.63},\\\"Recall\\\":{\\\"Model A\\\":91.12},\\\"Accuracy\\\":{\\\"Model A\\\":93.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"F2-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Grouping examples into three class labels C1, C2, and C3 is the goal or objective of this classification problem. Evaluating the performance of the model based on the metrics F1-score, Accuracy, and Recall show that the model has a fairly high classification power and will be able to accurately identify the labels for the majority of test examples. Particularly, the accuracy score is 93.89, a recall score of 91.12% with an F1-score of 89.79%. Furthermore, from the F1-score and recall scores, we can estimate that the model's confidence in output prediction decisions is moderately high.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.89},\\\"F1-score\\\":{\\\"Model A\\\":89.79},\\\"Recall\\\":{\\\"Model A\\\":91.12}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Grouping samples into three class labels C1, C2, and C3 is the goal of this machine learning problem. Evaluation of the model's performance based on the F1-score, Accuracy and Recall metrics indicate that the model has a moderately high classification ability and will be able to correctly predict the labels for most test cases. Specifically, the Accuracy score is 93.89, the recall rate is 91.12%, and finally, the F1-score is 89.79%. In addition, based on the F1-score and recall scores, we can estimate that the model has moderately high confidence in the predictive decisions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.89},\\\"F1-score\\\":{\\\"Model A\\\":89.79},\\\"Recall\\\":{\\\"Model A\\\":91.12}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model evaluated based on the metrics Precision, Accuracy and F1-score achieved the scores 88.47%, 93.89%, and 89.79%, respectively, on this machine learning classification task. The model's ability to correctly group the test cases under the different classes C1, C2, and C3, is shown to be high indicating that the model has a relatively good understanding of the underlying ML task and is confident when it comes to the predictions for the majority of test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.47},\\\"F1-score\\\":{\\\"Model A\\\":89.79},\\\"Accuracy\\\":{\\\"Model A\\\":93.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "On this multi-class ML problem under consideration, the algorithm attains high scores across all the evaluation metrics. For the accuracy, it scored 93.89%, for the precision it achieved 88.47% with the F1-score equal to 89.79%. These identical scores suggest that the model is very well balanced amongst the three class labels (C1, C2 and C3). In essence, we can confidently say that this model will be very good at assigning the true labels for several test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.47},\\\"F1-score\\\":{\\\"Model A\\\":89.79},\\\"Accuracy\\\":{\\\"Model A\\\":93.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The algoritms's performance scores when trained on this multi-class classification problem (where a given test instance is classified as either C1 or C2 or C3) are: Accuracy (92.27%), Precision (90.12%), and finally, an F1-score of 90.79%. The scores across these evaluation metrics show that this classification algorithm has a moderate to high classification performance and will be able to accurately label several test samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.12},\\\"F1-score\\\":{\\\"Model A\\\":90.79},\\\"Accuracy\\\":{\\\"Model A\\\":92.27}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model's performance was evaluated based on the Precision, Accuracy, Recall and F1-score, and it scored 88.47%, 93.89%, 91.12% and 89.79%, respectively, on the given machine learning classification problem. The ability of the model to correctly group test cases under different classes C1, C2, and C3 is shown to be moderately high, further indicating that the model has a relatively good understanding of the underlying machine learning classification task and boasts of a high confidence in the predictions made.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.47},\\\"Recall\\\":{\\\"Model A\\\":91.12},\\\"F1-score\\\":{\\\"Model A\\\":89.79},\\\"Accuracy\\\":{\\\"Model A\\\":93.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model was trained based on the multi-class labeling objective. A given test case or observation can be labeled either C1 or C2 or C3. The accuracy of the model is very high, with precision, recall, and F1-score equal to 77.73%, 85.43% and 81.07%, respectively. Judging by the scores achieved, we can conclude that this model has a high classification performance and will be very effective at correctly picking the true label for new or unseen examples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F1-score\\\":{\\\"Model A\\\":81.07},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model has a fairly high classification performance judging by the scores achieved across the evaluation metrics (i.e. Recall, Accuracy, Precision, and F1-score). From the table shown, we can see that it has an accuracy of 88.75% with the precision and recall equal to 77.73% and 85.43%, respectively. Overall, the model is shown to be effective and will be able to correctly classify several test cases/instances with only few instances misclassified.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F1-score\\\":{\\\"Model A\\\":81.07},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "This model was trained to classify examples belonging to the three classes (c1, C2, and C3). The model has accuracy, precision, and recall scores of 88.75%,  77.73, and 85.43%, respectively. Besides, the F1-score is 81.09%. In essence these scores demonstrate that that this model will be effective when telling-apart a large number of test examples drawn from the different classes (i.e C1, C3 and C2) under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F1-score\\\":{\\\"Model A\\\":81.09},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The scores achieved by the classifier are (1) Accuracy equal to 88.75%), (2) Precision score of 77.33%, and (4) F2-score of 83.54%. The scores across the different metrics show that the classifier has a high performance and will be very effective at predicting the true label for most of the test cases/samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F2-score\\\":{\\\"Model A\\\":83.54},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The accuracy, precision, recall, and F2-score achieved show that the classifier has a moderately high classification performance. Specifically, the model has a prediction accuracy of 88.75%, F2-score of 83.54%, recall score of 85.43%, and precision score equal to 77.73%. Based on the above scores, it is valid to conclude that this model will be somewhat effective at correctly predicting samples drawn from any of the labels (C1, C2, and C3).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F2-score\\\":{\\\"Model A\\\":83.54},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model's performance when it comes correctly labelling test examples was evaluated based on the following evaluation metrics: F2-score, Accuracy, Precision, and Recall. For the accuracy, it scored 88.75%, with the recall score equal to 85.43% and precision score equal to 77.73%. Trained on a balanced dataset, these scores are quite impressive. With such moderately high scores across the various metrics, the model is almost certain to make just few mistakes (i.e. low misclassification error/rate).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.73},\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F2-score\\\":{\\\"Model A\\\":83.54},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The scores of the evaluation metrics obtained by the classifier on this machine learning problem are: (1) Accuracy equal to 88.75, (2) Recall score of 85.43%, and (3) an F2-score of about 83.54%. The model demonstrates a high level of classification prowess in terms of correctly marking out the test cases belonging any of the labels under consideration. Besides, from the F2-score and accuracy, it is obvious that the likelihood of misclassifying any given test example is quite small which is impressive but not surprising given the data was balanced.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F2-score\\\":{\\\"Model A\\\":83.54},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The scores of the evaluation metrics obtained by the model are as follows: Accuracy (88.75%), F1-score (85.54%) and Recall (85.43%). Trained to correctly label test cases as one of the class labels C1, C2, and C3, these scores are impressive. In view of the accuracy score and the F2-score, this model can be considered as somewhat good at correctly predicting the true class labels for several test cases with a lower prediction error rate.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":85.43},\\\"F2-score\\\":{\\\"Model A\\\":83.54},\\\"Accuracy\\\":{\\\"Model A\\\":88.75}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model's performance when trained on this multi-class classification problem where the test instances are classified as either C1 or C3 or C2 is: Accuracy is equal to 82.6%, a recall score of 79.74%, and finally, an F2-score of 75.58%. These scores across the different metrics show that this model has demonstrated its classification prowess in terms of correctly predicting the true label for several test examples.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"F2-score\\\":{\\\"Model A\\\":75.58},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Dealing with the machine learning classification objective where the classifier is trained to pick out the examples belonging to the three classes (c1, C2, and C3) , the model's accuracy is about 82.6%, a recall score of 79.74% and an F2-score of 75.58%. According to these scores, one can conclude that this model will be highly effective at generating the correct class labels for the majority of the test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"F2-score\\\":{\\\"Model A\\\":75.58},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model has a fairly moderate performance as indicated by the scores across the different metrics (i.e. Recall, Accuracy, and F1-score). From the table shown, we can confirm that it has an accuracy of 82.6% with the associated recall and F1-score equal to 79.74% and 71.05%, respectively. The model's ability to correctly recognize the test examples under each class C1, C2, and C3, is shown to be moderately high based on these scores.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"F1-score\\\":{\\\"Model A\\\":71.05},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "On the multi-class ML problem under consideration, the classifier boasts a predictive accuracy of 82.6%, a recall score of about 79.74 with the F1-score equal to 71.05%. From the scores across the different evaluation metrics, we can make the conclusion that this model will be somewhat effective at correctly predict the true label for the majority of the test samples under class C1, class C2 and class C3.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"F1-score\\\":{\\\"Model A\\\":71.05},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Grouping test samples into three class labels C1, C2, and C3 is the model training objective of this classification problem. This classifier has an accuracy of 82.6% with moderate precision and recall scores of 66.46% and 79.74%, respectively. The scores across the evaluation metrics suggest that the model performs quite well in terms of correctly predicting the true label for most of the test examples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":66.46},\\\"F1-score\\\":{\\\"Model A\\\":71.05},\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model training objective of this multi-class classification task is assigning test samples one of the three class labels C1, C2, and C3. The model attained an accuracy of 82.6%, with the recall score equal to 79.74% and precision score is 66.46%. Judging by the scores achieved, we can see that model has a moderate classification performance hence will be fairly good at selecting the correct label for the examples belonging to the different classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":66.46},\\\"F1-score\\\":{\\\"Model A\\\":71.05},\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model's classification performance concerning the given multi-class classification problem where the test instances are classified as either C1 or C2 or C3 is: 66.46% (precision score), 79.74% (recall score), and an accuracy of 82.6%. The model demonstrates a moderately high classification ability based on the scores across the different evaluation metrics. This suggests that this classifier will be quite effective at separating the examples belonging to the labels under consideration (C1, C2 and C3).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":66.46},\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The ML model trained to solve this classification task achieved an accuracy of 82.6%, with the recall, precision and precision scores equal to 79.74 and 66.46, respectively. These scores support the conclusion that the model will be moderately effective at correctly labelling a large number of test examples drawn from the different classes (that is C1, C2 and C3) under consideration. Furthermore, the likelihood of misclassification is marginal.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":66.46},\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Conducting evaluations of the different aspect of the model's classification showed that the model boasts an accuracy of 82.6%, with the recall and precision equal to 79.74 and 66.46 respectively. Judging from the Accuracy and recall scores, we can conclude that this model has a moderate classification performance hence will be somewhat effective at accurately labelling the examples belonging to the different classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":66.46},\\\"Recall\\\":{\\\"Model A\\\":79.74},\\\"Accuracy\\\":{\\\"Model A\\\":82.60}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "From the performance analysis conducted, the model achieved the following metrics: (a) Accuracy: 85.89%. (b) Precision: 75.18%. (c) Recall: 85.97%. These results or scores are relatively high and as such it can be concluded or asserted that this model is an effective classifier with high confidence in its prediction decisions. In short, only a small number of test cases are likely to be misclassified as indicated by the scores across the different metrics.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "On the multi-class ML problem under consideration, the classifier attains high scores across all the evaluation metrics. For the recall, the model's performance score is about 85.97% and has an accuracy equal to 85.89%, and for the precision it achieved 75.18%. The model is shown to have a relatively low misclassification error rate as indicated by the accuracy, recall and precision scores. In essence, we can confidently conclude that this model will be moderately effective at identifyinh the test cases under the different classes or labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The labeling performance of the algorithm regarding this multi-class classification problem where the test instances are classified as either C1 or C2 or C3 is: Accuracy is equal to 85.89%, precision score is 75.18%, recall score is equal to 85.97% and finally, an F2-score of 82.92%. These scores across the different metrics show that this model has a moderate to high classification performance and will be able to correctly classify several test cases/instances.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":82.92},\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The evaluation scores achieved by the clasifier on this classification task or problem where the test instances are a label from the set of classes C1, C3 and C2 can be summarized as follows: the recall score is equal to 85.97%, the prediction accuracy is equal to 85.89%, and the precision score is 75.18. A balance between the precision and recall scores is the  F2-score which is equal to 82.92%. These scores indicate that the likelihood of misclassifying test samples is small which is impressive but not surprising given the distribution of the dataset across the classes or labels. In conclusion, this model shows a high level of effectiveness at correctly predicting the true label for several test examples.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":82.92},\\\"Precision\\\":{\\\"Model A\\\":75.18},\\\"Recall\\\":{\\\"Model A\\\":85.97},\\\"Accuracy\\\":{\\\"Model A\\\":85.89}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "On the multi-class ML problem under consideration, the classifier is shown to achieve high evaluation scores across all the metrics employed for to assess the classification performance. For the accuracy, it scored 87.36%, for the precision score it scored 83.78 and the recall score is also equal to 86.85%. These identical scores suggest that the model is very well balanced amongst the three classes (C1, C2 and C3). In essence, we can confidently conclude that this model will be effective at assigning the true label for several test cases/samples with only few instances misclassified.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.78},\\\"Recall\\\":{\\\"Model A\\\":86.85},\\\"Accuracy\\\":{\\\"Model A\\\":87.36}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "Analyzing the classification performance on this classification task (where a given test instance is labelled as either C1 or C2 or C3) showed that the classifier scored: Accuracy (91.03%), precision (74.68%), and a recall score equal to 86.92%. These scores are high implying that this model will be moderately effective at picking out the examples related to any of the classes. Furthermore, from the F1-score and precision scores, we can say that it will likely misclassify some test cases but will have a high confidence in its classification decisions.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":79.30},\\\"Precision\\\":{\\\"Model A\\\":74.68},\\\"Recall\\\":{\\\"Model A\\\":86.92},\\\"Accuracy\\\":{\\\"Model A\\\":91.03}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The accuracy of the model is equal to 83.08% with the precision and recall equal to 69.6% and 82.75%, respectively. The model was trained on this multi-class classification task to assign labels to test samples from one of the classes C1, C2, and C3. Based on the scores across the different metrics under consideration, we can conclude that the model performs fairly well in terms of correctly predicting the true label for most of the test examples.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":74.24},\\\"Precision\\\":{\\\"Model A\\\":69.60},\\\"Recall\\\":{\\\"Model A\\\":82.75},\\\"Accuracy\\\":{\\\"Model A\\\":83.08}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "With respect to the modelling objective of this multi-class classification task, the performance of the classifier is analyzed based on the following evaluation metrics: Accuracy, Recall, and Precision. For the accuracy, it scored 83.08%, for the precision it achieved 69.6% with the recall score equal to 82.75% and F1-score equal to 74.24%. This model is shown to have a moderately high classification performance in terms of correctly classifying test samples from each of the three-class labels under consideration. In other words, we can assert that this model will be somewhat effective at correctly recognizing the examples associated with each class or label.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":74.24},\\\"Precision\\\":{\\\"Model A\\\":69.60},\\\"Recall\\\":{\\\"Model A\\\":82.75},\\\"Accuracy\\\":{\\\"Model A\\\":83.08}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The scores obtained by the model on this AI task are as follows (1) Accuracy equal to 83.08, (2) Precision score equal 69.6%, (3) recall score of 82.75% and (4) F2-score of 78.73%. The scores across the different metrics suggest that this model is moderately effective at correctly classifying most of the test cases/samples with only a small margin of error. Besides, the F2-score shows that the confidence in predictions is moderately high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.60},\\\"Recall\\\":{\\\"Model A\\\":82.75},\\\"F2-score\\\":{\\\"Model A\\\":78.73},\\\"Accuracy\\\":{\\\"Model A\\\":83.08}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The classifier trained to identify the true labels of test observations or cases has an accuracy of about 84.23% with the precision and recall scores equal to 79.6% and 83.21%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the model performs moderately well in terms of correctly predicting the true label for most test cases. Besides, It has a moderate to high confidence in the predicted output class labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.60},\\\"Recall\\\":{\\\"Model A\\\":83.21},\\\"F2-score\\\":{\\\"Model A\\\":78.73},\\\"Accuracy\\\":{\\\"Model A\\\":84.23}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "In view of this multi-class classification problem where the test samples are classified as either C1 or C2 or C3, the modelc scored: Accuracy (36.37%), Recall (65.69%), and a Precision score of 67.81%. These scores are lower than expected indicating how poor the model is at correctly generating the true class label for most test cases related to any of the three class labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":67.81},\\\"Recall\\\":{\\\"Model A\\\":65.69},\\\"F2-score\\\":{\\\"Model A\\\":53.05},\\\"Accuracy\\\":{\\\"Model A\\\":36.37}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"F2-score\":\"3\",\"Recall\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The classification performance or prowess attained by the model on this multi-class classification problem where the test instances are classified as either C1 or C2 or C3 is summarized as follows: a. Accuracy (36.37%), b. Recall (65.69%), c. a Precision score of 67.81%, d. F2-score equal to 53.05%. These scores across the different metrics suggest that this model is less effective and less precise (than expected) in terms of accurately predicting the true labels of several test examples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":67.81},\\\"Recall\\\":{\\\"Model A\\\":65.69},\\\"F2-score\\\":{\\\"Model A\\\":53.05},\\\"Accuracy\\\":{\\\"Model A\\\":36.37}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"F2-score\":\"3\",\"Recall\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The classifier's prediction performance on the machine learning problem where the test instances are classified as either C1 or C2 or C3 are as follows: Accuracy (35.74%), Precision (67.81%), and finally, an F1-score of 49.6%. Considering the scores across the different metrics under consideration, this model is shown to have a lower classification performance as it is not be able to accurately predict the actual labels of multiple test samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":67.81},\\\"F1-score\\\":{\\\"Model A\\\":49.60},\\\"Accuracy\\\":{\\\"Model A\\\":35.74}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and  <b>C3</b></p>The dataset is balanced belonging to class C1, C3 and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"F1-score\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The model's classification performance when it comes to this binary classification problem where the test instances are classified as either C1 or C2 is: 83.86% (precision score), 88.55% (accuracy), and 91.22% (Specificity). From these scores, we can make the conclusion that this model will be moderately effective at correctly segregating the examples associated with any of the labels based on the difference in precision and accuracy.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.86},\\\"Specificity\\\":{\\\"Model A\\\":91.22},\\\"Accuracy\\\":{\\\"Model A\\\":88.55}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced belonging to class C1,  and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Type Classification",
            "id": 129,
            "narration": "The classifier's performance with reference to the classification objective where the test samples are labeled as either C1 or C2 is as follows: (1) Accuracy (88.55%), (2) Specificity (91.22%), (3) a Precision score of 83.86%. These scores show that this model will be very effective at accurately labeling the examples belonging to each class. Furthermore, the scores indicate that the likelihood of misclassifying samples is only marginal.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.86},\\\"Specificity\\\":{\\\"Model A\\\":91.22},\\\"Accuracy\\\":{\\\"Model A\\\":88.55}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced belonging to class C1,  and C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "For this classification task, the model was trained to label the test samples as class C1 or class C2. The model demonstrates a high level of understanding of the ML problem considering the scores for the specificity, sensitivity/recall, F2-score, AUC and accuracy. As shown in the table, it obtained a score of 82.16% as the prediction accuracy, a sensitivity of 83.0%, a specificity of 79.72 and an F2-score of 81.56%. In general, the efficiency of classification is relatively high, so it can correctly identify true class label for most test cases.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":79.72},\\\"F2-score\\\":{\\\"Model A\\\":81.56},\\\"AUC\\\":{\\\"Model A\\\":87.62},\\\"Sensitivity\\\":{\\\"Model A\\\":83.0},\\\"Accuracy\\\":{\\\"Model A\\\":82.16}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "For this classification task, the model was trained to label the test samples as class C1 or class C2. The classifier shows signs of low understanding of the classification task under consideration.  This assertion is based on the scores for the sensitivity/recall, specificity, F2-score, AUC, and accuracy. As shown, it obtained a moderate scores of 69.89% (accuracy), 72.62% (AUC) and 68.93% (specificity) with very low scores for the sensitivity(32.89%) and F2-score(28.93%). Overall, the efficiency of classification is very lower than expected and from the sensitivity and F2-score, the model is shown to have very low predictive power concerning correctly separating out the observation under the class C2. Unlike C2 examples, this model can correctly identify the examples belonging to C1.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":68.93},\\\"F2-score\\\":{\\\"Model A\\\":28.93},\\\"AUC\\\":{\\\"Model A\\\":72.62},\\\"Sensitivity\\\":{\\\"Model A\\\":32.89},\\\"Accuracy\\\":{\\\"Model A\\\":69.89}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F2-score\":\"1\",\"AUC\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "The classification prowess of this model can be summarized as moderately high indicating that the model is good at correctly assigning test cases their respective true label as one of the classes C1 and C2. The confidence in output predictions is high considering the scores achieved across the evaluation metrics accuracy, precision, sensitivity, specificity, and F2-score. To be specific, the model attained the following evaluation metrics' scores: (1) Accuracy of 76.8%, (2) Sensitivity of 83.74%, (3) a moderate Precision of 73.05%, (4) Specificity of 70.08, and (5) an F2-score of 81.36%.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":70.08},\\\"F2-score\\\":{\\\"Model A\\\":81.36},\\\"Precision\\\":{\\\"Model A\\\":73.05},\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Precision\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "The classification performance of this machine learning model can be summarized as moderate to high, which indicates that the model is able to categorized test cases either one of the class label C1 and C2. The prediction decisions show to be very reliable given the scores obtained for the precision, accuracy, sensitivity/recall, specificity, and F2-score. Specifically, the model has: (1) a sensitivity/recall of 83.74%, (2) an accuracy of 76.8%, (3) an F2-score of 81. 36% (4) a moderate precision of 73.05%,  and (5) a moderate specificity of 70.08.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":70.08},\\\"F2-score\\\":{\\\"Model A\\\":81.36},\\\"Precision\\\":{\\\"Model A\\\":73.05},\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F2-score\":\"4\",\"Precision\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "The classifier has: (1) a recall score of 81.52%, (2) an accuracy of 78.03%, (3) an F1-score of 78.31% (4) a  precision of 75.36%,  and (5) an AUC score of 85.63%. On this machine learning problem, the model's classification performance is shown to be fairly high suggesting that it can correctly categorize most of the test cases either one of the class label C1 and C2  considering the scores obtained for the precision, accuracy,  recall, AUC, and F1-score. In summary, the model is likely to have a moderately low misclassification error rate.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.63},\\\"F1-score\\\":{\\\"Model A\\\":78.31},\\\"Precision\\\":{\\\"Model A\\\":75.36},\\\"Recall\\\":{\\\"Model A\\\":81.52},\\\"Accuracy\\\":{\\\"Model A\\\":78.03}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"4\",\"AUC\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 99,
            "narration": "Evaluation of the model's performance based on the metrics: recall, F1-score, AUC and accuracy produced the scores  81.52%,  78.31%, 85.63%, and  78.03%, respectively. On this machine learning problem, these scores indicate that model's ability to correctly assign labels (either one of the class label C1 and C2) to test samples is relatively high. As a result, the likelihood of misclassification is low for this classifier.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":85.63},\\\"F1-score\\\":{\\\"Model A\\\":78.31},\\\"Recall\\\":{\\\"Model A\\\":81.52},\\\"Accuracy\\\":{\\\"Model A\\\":78.03}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, and <b>C2</b> The dataset is imbalanced across all the class labels",
            "redeem_code": "XP5P0-Q3VVM-44EFV_99-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"AUC\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Recall, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Recall, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 192,
            "narration": "For this classification task, the model was trained to label test samples as either class C1 or class C2. As shown in the table, the classification performance/prowess of this machine learning model is very impressive considering the almost perfect scores  100.0%, 99.16%, 89.12%, and 95.08%, respectively, across the metrics specificity, AUC, sensitivity, and accuracy. Overall, the model has a lower misclassification error and given that the specificity is at a perfect rate of 100.0% we can be certain that it can accurately classify almost all the test cases related to class label C1.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"Sensitivity\\\":{\\\"Model A\\\":89.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.08}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "L0YXQ-@C9RJ-2@UAL-192-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 192,
            "narration": "The ability of the classifier with respect labelling test samples as either class C1 or class C2 is shown to be very high when you consider the scores across the metrics Accuracy (91.52%), Recall (87.51%), AUC (96.84%) and Specificity (88.96%). These scores imply that the model will fail to correctly predict the true label for only a small number of test examples. In summary, the model is pretty confident with its output decisions for both class labels C1 and C2.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.84},\\\"Specificity\\\":{\\\"Model A\\\":88.96},\\\"Recall\\\":{\\\"Model A\\\":87.51},\\\"Accuracy\\\":{\\\"Model A\\\":91.52}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "L0YXQ-@C9RJ-2@UAL-192-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Specificity\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 112,
            "narration": "On this machine learning classification problem, the model's performance was assessed based on the scores across the accuracy (83.56%), precision (45.23%), sensitivity score (76.63%), and F1-score (56.89%) for the F1-score. Considering the scores, we can say that the classification performance is moderately low. The same conclusion can be reached by looking at only the precision, and sensitivity scores.  The false-positive rate is moderately high as a subset of test samples belonging to class label C1 are likely to be misclassified as C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.63},\\\"Accuracy\\\":{\\\"Model A\\\":83.56},\\\"Precision\\\":{\\\"Model A\\\":45.23},\\\"F1-score\\\":{\\\"Model A\\\":56.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"2\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 112,
            "narration": "Regarding this machine learning classification problem, the performance of the model was evaluated based on scores for accuracy (83.56%), a precision (45.23%), recall score (76.63%) and F1-score (56.89%). Given the scores, we can say that the classification performance is moderately low. Similar conclusion can be made by analyzing only the F1-score  (derived from the precision and recall scores). The false positive rate is moderately high because a subset of test cases belonging to the C1 class label is likely to be misclassified as C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.63},\\\"Accuracy\\\":{\\\"Model A\\\":83.56},\\\"Precision\\\":{\\\"Model A\\\":45.23},\\\"F1-score \\\":{\\\"Model A\\\":56.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"2\",\"F1-score \":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 112,
            "narration": "With regards to this classification problem, the performance of the model was evaluated based on scores across the metrics Precision, Recall, Accuracy and the F2-score. For the accuracy, it scored 34.57%, has a precision score of 18.98%,a recall score of 19.53% with the  F2-score equal to 17.92%. We can say that this model has avery low classification prowess and will incorrectly classify a large percentage of test cases based on the scores above. In simple terms, it will struggle to identify the test cases belonging to both class labels C1 and C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":19.53},\\\"Accuracy\\\":{\\\"Model A\\\":34.57},\\\"Precision\\\":{\\\"Model A\\\":18.98},\\\"F2-score\\\":{\\\"Model A\\\":17.92}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Recall\":\"1\",\"Precision\":\"1\",\"F2-score\":\"1\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 112,
            "narration": "This model is shown to have a very poor classification performance after being trained to correctly identify the true label of a given test case as either C1 or C2. The model only managed to achieve moderate scores across the specificity (67.89%), accuracy (60.69%) and AUC (65.96%). However, the precision and sensitivity have very low scores 15.98% and 23.54%, respectively. Given that the performance regarding the C1 classification is moderate (that is based on the specificity score), we can say that the model has a significantly low prediction ability for the examples with C2 as their true label.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":23.54},\\\"AUC\\\":{\\\"Model A\\\":65.96},\\\"Accuracy\\\":{\\\"Model A\\\":60.69},\\\"Precision\\\":{\\\"Model A\\\":15.98},\\\"Specificity\\\":{\\\"Model A\\\":67.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Sensitivity\":\"1\",\"Precision\":\"1\",\"Specificity\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "For the dataset used to train this classifier, the number of observations for each class (C1 and C2) is somewhat balanced. The classifier's performance of predicting the true class label is the classification accuracy of about 52.11%, AUC score of 60.35, and F1-score  of 49.33%. These score show that the model might struggle to generate the correct label for a number of test cases but in general, the model demonstrates a fair under standing of the ML task.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":60.35},\\\"Accuracy\\\":{\\\"Model A\\\":52.11},\\\"F1-score \\\":{\\\"Model A\\\":49.33}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"F1-score \":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "On this classification task where the goal is labelling a given observation as either C1 or C2, the classifier demonstrate an extremely poor classification prowess. Specifically, when evaluated based on the Recall, Specificity, Accuracy and F2-score, the classification performance is characterized by the following low scores 25.64%, 21.48%, 32.45% and 14.27%, respectively. It is important to note that the number of observations for each class (C1 and C2) is somewhat balanced hence these scores are not very impressive suggesting new set of features or more training data should be used to re-train the model. In summary, these score show that the model generally struggles to generate the correct label for a number of test observations or cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":25.64},\\\"Specificity\\\":{\\\"Model A\\\":21.48},\\\"Accuracy\\\":{\\\"Model A\\\":32.45},\\\"F2-score\\\":{\\\"Model A\\\":14.27}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Recall\":\"2\",\"Specificity\":\"2\",\"F2-score\":\"2\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 117,
            "narration": "On this classification with a balanced distribution of the data between the class labels C1 and C2, the model achieves very low scores across all the evaluation metrics. For example, the accuracy is 40.1% with the AUC score equal to 43.61%.  These scores indicate how ineffective the model is at correctly predicting the true label for the majority of the test cases related to any of the class labels. Furthermore, the very low recall and precision scores of 12.56% and 13.77%, respectively, show that this classifier is less reliable with its prediction decision. In summary, there is a higher chance of misclassification.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":12.56},\\\"AUC\\\":{\\\"Model A\\\":43.61},\\\"Precision\\\":{\\\"Model A\\\":13.77},\\\"Accuracy\\\":{\\\"Model A\\\":40.1}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"2\",\"Precision\":\"1\",\"Recall\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 117,
            "narration": "This algorithm has a very poor classification performance as shown by the scores achieved with respect to the metrics recall, AUC, precision, and accuracy. As shown in the table, it has a low prediction accuracy of 40.1% meaning the algorithm is correct 40.1% of the time. Similarly, the scores across the other metrics are very low.  Given that the dataset was balanced, these scores are not very impressive. In summary, this algorithm is not effective hence has a very high misclassification rate.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":43.61},\\\"Recall\\\":{\\\"Model A\\\":12.56},\\\"Precision\\\":{\\\"Model A\\\":13.77},\\\"Accuracy\\\":{\\\"Model A\\\":40.1}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"2\",\"Precision\":\"1\",\"Recall\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 117,
            "narration": "The likelihood of the model misclassifying a test case is shown to be very high considering that it scored poorly when assessed based on the accuracy, AUC, precision, and recall where it achieved the scores 40.1%, 43.61%, 13.77%, and 12.56%, respectively. It should be noted that the number of observations for each class (C1 and C2) is balanced hence these scores show how flawed the model is. A large proportion of test observations will be misclassified by this classifier.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":12.56},\\\"AUC\\\":{\\\"Model A\\\":43.61},\\\"Precision\\\":{\\\"Model A\\\":13.77},\\\"Accuracy\\\":{\\\"Model A\\\":40.1}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"2\",\"Precision\":\"1\",\"Recall\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 63,
            "narration": "On this machine learning classification problem, the model earned an accuracy of 95.9%, a recall and precision scores of 76.19% and 91.43%, respectively. Considering the fact that the number of observations for each class is not balanced, the best indicator of the performance of the model on this classification task is the F1-score (which is derived from precision and recall). We can verify that the model has a high F1-score of about 83.12% suggesting it is quite effective as there is little chance of observations/cases belonging to class label C1 incorrectly classified as C2. In summary, the model is ver sure or certain about the correctness of its prediction decisions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":95.9},\\\"F1-score \\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":91.43}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score \":\"4\",\"Accuracy\":\"5\",\"Recall\":\"3\",\"Precision\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score , Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score , Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 197,
            "narration": "Evidenced by the scores across the metrics AUC, Accuracy, Precision and Sensitivity, this algorithm has a moderate classification performance when trained to classify any given observation as either C1 or C2. In conclusion, the learning algorithm employed here is quite confident about its C2 predictions and has a low false positive rate considering the moderaly high precision and Sensitivity score.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.23},\\\"Accuracy\\\":{\\\"Model A\\\":82.48},\\\"Sensitivity\\\":{\\\"Model A\\\":74.68},\\\"Precision\\\":{\\\"Model A\\\":77.32}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "56@KH-JJA19-UHKYW-197-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"2\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier attains the scores 86.49% for the recall metric, 65.57% for specificity metric, 77.04% as the accuracy, and F1-score  of 80.51%. The evaluation cores for the metrics recall, F1-score , and specificity suggest that the model will be fairly good at correctly recognizing the observations belonging to the two-class labels, C1 and C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":86.49},\\\"Specificity\\\":{\\\"Model A\\\":65.57},\\\"Accuracy\\\":{\\\"Model A\\\":77.04},\\\"F1-score \\\":{\\\"Model A\\\":80.51}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Specificity\":\"3\",\"F1-score \":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Evaluations based on the metrics recall, accuracy, F1-score, and specificity suggest the classifier has a moderately good classification ability hence is likely to make few misclassifications. To be specific, the model's performance assessment scores were 86.49% for the recall metric, 77.04% as the accuracy, 65.57% for specificity metric, and F1-score  of 80.51%.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":86.49},\\\"Specificity\\\":{\\\"Model A\\\":65.57},\\\"Accuracy\\\":{\\\"Model A\\\":77.04},\\\"F1-score \\\":{\\\"Model A\\\":80.51}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Specificity\":\"3\",\"F1-score \":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Trained to tell-apart the examples belonging to the class labels C1 and C2, the model's classification prowess is  characterized by the scores 86.49%, 75.29%, 81.61%, and 77.04% across the metrics sensitivity, precision, AUC, and accuracy. The AUC score indicates the model can fairly separate the positive and negative examples. Furthermore, the model has a low false-positive rate considering the sensitivity and precision scores.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":86.49},\\\"Precision\\\":{\\\"Model A\\\":75.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.04},\\\"AUC\\\":{\\\"Model A\\\":81.61}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The AUC score suggests the model has a moderately good performance in terms of correctly separating the positive and negative examples. Furthermore, the model has a low false-positive rate considering the sensitivity and precision scores. All the above conclusions are based on the model achieving the scores 86.49%, 75.29%, 77.04%, and 81.61% across the metrics sensitivity, precision, accuracy, and AUC.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":86.49},\\\"Precision\\\":{\\\"Model A\\\":75.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.04},\\\"AUC\\\":{\\\"Model A\\\":81.61}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The training objective is correctly sorting out (with a small margin of error) the observations belonging to classes C1 and C2. The scores achieved across the metrics accuracy, AUC, precision, and sensitivity are 78.52%, 80.84%,77.78%, and 85.14%. According to these scores, the model demonstrates a good understanding of the underlying ML task and can correctly separate the C2 examples from that of the C1 with only a few misclassification instances.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":85.14},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Accuracy\\\":{\\\"Model A\\\":78.52},\\\"AUC\\\":{\\\"Model A\\\":80.84}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (60%) and class C2 (40%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The scores are 78.52%, 80.84%, 77.78%, and 85.14%, respectively, across the evaluation metrics accuracy, AUC, precision, and sensitivity. Judging base on the scores above, the model is precise with its prediction decisions and is moderately effective at correctly sorting out the examples belonging to the classes C1 and C2.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":85.14},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Accuracy\\\":{\\\"Model A\\\":78.52},\\\"AUC\\\":{\\\"Model A\\\":80.84}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (60%) and class C2 (40%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Judging base on the scores achieved across the precision, F1-score , and specificity metrics, the model is quite effective at correctly predicting the actual labels for several test cases. The conclusion above is based on the model scoring 70.49%, 81.29%, 77.78%, and 78.52%, respectively, across the metrics specificity, F1-score , precision, and accuracy.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":70.49},\\\"Precision\\\":{\\\"Model A\\\":77.78},\\\"Accuracy\\\":{\\\"Model A\\\":78.52},\\\"F1-score \\\":{\\\"Model A\\\":81.29}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (60%) and class C2 (40%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Specificity\":\"3\",\"F1-score \":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "For this classification task, the performance of the classifier is summarized or characterized by the scores 82.89% (F2-score), 79.26% (Accuracy), 79.49% (Precision) and 83.67% (AUC). The scores across the metrics under consideration suggest the model performs quite well at predicting the actual or true class label of test observations or cases. In summary, despite a few misclassification instances, the model's confidence in prediction decisions is moderately high.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":82.89},\\\"Precision\\\":{\\\"Model A\\\":79.49},\\\"Accuracy\\\":{\\\"Model A\\\":79.26},\\\"AUC\\\":{\\\"Model A\\\":83.67}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The evaluation scores across the metrics under consideration suggest the model performance is quite good in terms of predicting the actual or true class label of test observations or cases (either C1 or C2). For this classification task, the model possesses an accuracy of 79.26%, 79.49% for the precision score, 82.89% as the F2-score,  and 83.67% characterizing the AUC.  In conclusion, the model's confidence in prediction decisions is moderately high despite a few misclassification instances.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":82.89},\\\"Precision\\\":{\\\"Model A\\\":79.49},\\\"Accuracy\\\":{\\\"Model A\\\":79.26},\\\"AUC\\\":{\\\"Model A\\\":83.67}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The scores across the metrics F1-score , Specificity, Recall, and Accuracy are 81.58%, 73.77%, 83.78%, and 79.26%, respectively. The performance assessment scores demonstrate that the model in most cases can correctly identify the actual label (either C1 or C2) of test observations with a marginal margin of error.",
            "metrics_values": "\"{\\\"F1-score \\\":{\\\"Model A\\\":81.58},\\\"Recall\\\":{\\\"Model A\\\":83.78},\\\"Accuracy\\\":{\\\"Model A\\\":79.26},\\\"Specificity\\\":{\\\"Model A\\\":73.77}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F1-score \":\"4\",\"Specificity\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The given model has a moderately lower classification performance than expected. Given that the number of observations is balanced between the class labels C1 and C4, achieving the scores 41.36% (F1-score), 53.19% (recall), 66.89% (accuracy), and 70.23% (AUC) is not impressive. This is indicative of the fact that the model failed to accurately learn or capture the information required to solve the ML problem.",
            "metrics_values": "\"{\\\"F1-score \\\":{\\\"Model A\\\":41.36},\\\"Recall\\\":{\\\"Model A\\\":53.19},\\\"Accuracy\\\":{\\\"Model A\\\":66.89},\\\"AUC\\\":{\\\"Model A\\\":70.23}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Recall\":\"3\",\"F1-score \":\"3\",\"AUC\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Given that the number of observations is balanced between the class labels C1 and C2, achieving the scores 41.36% (F1-score), 53.19% (recall), 66.89% (accuracy), and 70.23% (AUC) is indicative of the fact that the model fails at understanding the ML task. Overall, the scores are not impressive enough and the model is shown to have moderately lower classification performance than expected. It fails to provide the best solution to the given classification task.",
            "metrics_values": "\"{\\\"F1-score \\\":{\\\"Model A\\\":41.36},\\\"Recall\\\":{\\\"Model A\\\":53.19},\\\"Accuracy\\\":{\\\"Model A\\\":66.89},\\\"AUC\\\":{\\\"Model A\\\":70.23}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 and class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Recall\":\"3\",\"F1-score \":\"2\",\"AUC\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score . (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The learning algorithm trained on the given classification task has a score of 76.18% for specificity, 83.74% for sensitivity, 74.05% for precision, and 81.36% for the F2-score. The F2-score is generally calculated from sensitivity and precision scores, and it weighs the sensitivity twice as high. According to the scores, the algorithm is shown to be quite good at avoiding false negatives than it is at avoiding false positives. This algorithm provides a fairly good solution to this labeling task.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Specificity\\\":{\\\"Model A\\\":76.18},\\\"Precision\\\":{\\\"Model A\\\":74.05},\\\"F2-score\\\":{\\\"Model A\\\":81.36}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score , Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score , Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The scores of 76.18% for specificity, 74.05% for precision with about 81.36% for the F2-score were achieved by the machine learning algorithm employed to solve the classification task. From the F2-score, we can deduce that the sensitivity of the classifier is higher, and when combined with the specificity score, we can conclude that the algorithm has a better ability in terms of avoiding false negatives than it is at avoiding false positives. In other words, a number of test cases or observations will likely get misclassified.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":76.18},\\\"Precision\\\":{\\\"Model A\\\":74.05},\\\"F2-score\\\":{\\\"Model A\\\":81.36}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Specificity\":\"3\",\"Precision\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score , Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score , Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The ML algorithm's ability to accurately label test cases as either C1 or C2 was assessed based on precision, sensitivity, specificity, and predictive accuracy. The scores achieved across the metrics are 55.56% (precision), 90.77% (specificity), 24.19% (sensitivity or recall) and 69.27%(Accuracy). The very high specificity score of 90.77% suggests most of the C1 examples are correctly classified as C1. However, due to the algorithm's tendency to avoid false positives, it only assigns the C2 class for a small number of cases. In conclusion, the scores are lower than expected (precision, accuracy, and sensitivity) indicating how poor the model is at correctly generating the true class label for most test cases related to class C2.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The algorithm was trained on this dataset to correctly separate the test observations into two different classes, C1 and C2. It has an accuracy of 69.27% with the associated precision and recall scores equal to 55.56% and 24.19%, respectively. The algorithm's overall classification performance with respect to C2 cases can be summarized as moderately low given the scores achieved for precision, and sensitivity/recall. The specificity score (90.77%) shows how good the algorithm is with respect to predictions related to class label C1. Overall, this algorithm offers a weak solution to this classification task given that it does very well to identify several of the C1 examples than C2's.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The trained classifier or algorithm scores 55.56%, 24.19%, 90.77%, and 69.27% across the evaluation metrics Precision, Sensitivity, Specificity, and Accuracy. From the specificity score, the classifier is shown to have higher prediction performance with respect to correctly identifying examples belonging to the label C1. However, prediction confidence with regards to C2 is lower than expected given the precision, and recall scores. In summary, we can see that the model is less effective at correctly sorting out examples under class C2.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classifier was trained on this imbalanced dataset to correctly separate the examples into two different classes (i.e. C1 and C2). The performance evaluation of the classifier can be summarized as low according to the scores achieved for the precision, sensitivity, specificity, and accuracy. For the accuracy, it scored 69.27%, has a sensitivity score of 24.19%, precision score of 55.56% with the specificity score equal to 90.77%. Overall, the model is very confident with its prediction decisions for test cases related to the negative class label C1 unlike the predictions with respect to C2.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"2\",\"Sensitivity\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The capability of the ML algorithm to label accurately test samples as either C1 or C2 was assessed on the basis of the scores achieved for the precision, sensitivity, specificity, and predictive accuracy metrics. The evalaution scores are 55.56% (precision), 90.77% (specificity), 24.19% (recall). Unlike the specificity score, the scores attained for the other metrics are lower than expected indicating how poor the model is at generating the true class label for most test cases related to the class C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"2\",\"Recall\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The algorithm was specifically trained to assign test instances the class label either C1 or C2. With respect to this classification problem, it scored 90.77% (Specificity), 55.56% (Precision), 24.19% (Sensitivity) and 69.27%(Accuracy). From the score achieved on the specificity metric, we can see that only a few examples from C1 will likely be misclassified as C2, hence its confidence in predictions related to the C1 classes is very high. This is not true for the C2 examples. In simple terms, we can say that the model is very good sorting out the actual C1 examples from that of C2. However, it will struggle to accurate identify the C2 test cases.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":24.19},\\\"Specificity\\\":{\\\"Model A\\\":90.77},\\\"Accuracy\\\":{\\\"Model A\\\":69.27},\\\"Precision\\\":{\\\"Model A\\\":55.56}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Accuracy\":\"2\",\"Sensitivity\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classifier trained to solve the given AI task achieved an accuracy of 82.44%, with the AUC, recall and precision scores equal to 88.03%, 70.36%, and 89.93%, respectively. These scores support the conclusion that this model will be moderately effective enough to sort between the examples belonging to any of the different labels, C1 and C2. Furthermore, from the recall (sensitivity) and precision scores, we can say that it will likely have a lower false positive rate.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.36},\\\"AUC\\\":{\\\"Model A\\\":88.03},\\\"Accuracy\\\":{\\\"Model A\\\":82.44},\\\"Precision\\\":{\\\"Model A\\\":89.93}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classification performance of the algorithm regarding this classification problem where the test instances are classified as either C1 or C2 is: recall (70.36%), AUC (88.03%), accuracy (82.44%),  and precision (89.93%). These scores are high implying that this model will be moderately effective at correctly labelling most test observations with only a few misclassification instances.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.36},\\\"AUC\\\":{\\\"Model A\\\":88.03},\\\"Accuracy\\\":{\\\"Model A\\\":82.44},\\\"Precision\\\":{\\\"Model A\\\":89.93}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The algorithm trained on this classification task got a prediction accuracy of 82.44%. In addition, the AUC, precision and recall scores are equal to 88.03%, 89.93%, and 70.36%, respectively. Fortunately, the precision score is higher than recall; hence the algorithm tries its best to avoid false-positive predictions. Overall, we can estimate that the classification algorithm will be somewhat effective at correctly labelling most test cases/samples with only a small margin of error.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.36},\\\"AUC\\\":{\\\"Model A\\\":88.03},\\\"Accuracy\\\":{\\\"Model A\\\":82.44},\\\"Precision\\\":{\\\"Model A\\\":89.93}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The AI algorithm trained to solve the given classification problem achieved an accuracy of 82.44, an AUC of 88.03% with recall and precision scores equal to 70.36%, and 89.93%, respectively. The algorithm employed here is shown to be moderately effective in terms of sorting between the test examples under class C1 and class C2. Besides, the algorithm is shown to have a lower false-positive rate according to the recall (sensitivity) and precision scores achieved.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.36},\\\"AUC\\\":{\\\"Model A\\\":88.03},\\\"Accuracy\\\":{\\\"Model A\\\":82.44},\\\"Precision\\\":{\\\"Model A\\\":89.93}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The prediction performance of the classifier regarding this binary classification problem where the test instances are labeled as either C1 or C2 is, it has a recall of 70.36%, an accuracy score equal to 82.44%, AUC  score equal to 88.03% and finally, a precision  score of 89.93%. The scores shown above across the different metrics suggest that this model is very effective at correctly classifying most test cases. In conclusion, we can confidently say that it can correctly identify a moderate amount of test examples from both class labels.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.36},\\\"AUC\\\":{\\\"Model A\\\":88.03},\\\"Accuracy\\\":{\\\"Model A\\\":82.44},\\\"Precision\\\":{\\\"Model A\\\":89.93}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The scores achieved by the AI algorithm on this binary classification task are as follows (a) Accuracy equal to 85.68%. (b) Precision score equal 82.19%. (c) F1-score of 77.51%. (d) AUC score of 89.43%.  From accuracy and AUC scores, we can conclude that this model has a moderately high classification performance hence will likely misclassify few test samples drawn randomly from any of the class labels under consideration. Furthermore, based on the remaining metrics (i.e. precision, F1-score, and recall), the confidence in predictions related to label C2 can be summarized as high.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":77.51},\\\"AUC\\\":{\\\"Model A\\\":89.43},\\\"Accuracy\\\":{\\\"Model A\\\":85.68},\\\"Precision\\\":{\\\"Model A\\\":82.19}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The scores 85.68% (accuracy), 89.43% (AUC), 77.51% (F1-score), and 82.19% (precision), respectively, are the performance evaluation metrics' scores achieved by the algorithm trained on the task of assigning one of the two-class labels (C1 and C2) to test cases. On this machine learning problem, the algorithm demonstrates a moderate classification performance hence can somewhat tell apart the examples belonging to each class under consideration. In other words, the AUC and accuracy scores indicate that the likelihood of misclassifying samples is small which is impressive but not surprising given the data was balanced.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":77.51},\\\"AUC\\\":{\\\"Model A\\\":89.43},\\\"Accuracy\\\":{\\\"Model A\\\":85.68},\\\"Precision\\\":{\\\"Model A\\\":82.19}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The prediction performance of the classifier on this ML problem (where a given test instance is labeled as either C1 or C2) is: accuracy (85.68%), precision (82.19%) and AUC (89.43%). With such high precision and accuracy scores, we can be sure to trust that this model will be effective in terms of its prediction power for several test examples/samples under the different labels. This implies that the likelihood of misclassifying test samples is quite small which is impressive but not surprising given the distribution in the dataset across the classes or labels.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.43},\\\"Accuracy\\\":{\\\"Model A\\\":85.68},\\\"Precision\\\":{\\\"Model A\\\":82.19}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The performance evaluation metrics scores achieved by the algorithm on this binary classification task were: (a) Accuracy equal to 85.68%. (b) AUC score of 89.43%. (c) Precision of 82.19%. From these scores, we can make the conclusion that this model will likely misclassify only a small number of samples belonging to any of the classes. The accuracy and AUC scores indicates that the classifier is far better than random guessing. Furthermore, the precision score shows that the classifier is quite confident about its prediction decisions for the majority of the test cases.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.43},\\\"Accuracy\\\":{\\\"Model A\\\":85.68},\\\"Precision\\\":{\\\"Model A\\\":82.19}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "From the results in the table above, the algorithm correctly predicted the individual outcome in 76.86% of the cases as shown by the accuracy score achieved. This is far better than random guessing. Furthermore, it has a moderately high precision and sensitivity scores equal to 78.79%, and 77.43%, respectively. Overall, this algorithm will be able to tell-apart the cases belonging to any of the classes with a small margin of mislabeling error.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":77.43},\\\"Accuracy\\\":{\\\"Model A\\\":76.86},\\\"Precision\\\":{\\\"Model A\\\":78.79}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "According to the evaluation scores in the table above, the algorithm correctly generated the label in 76.86% of the test instances, which is confirmed by the achieved accuracy score. This is much better than making prediction decisions based on random guesses. In addition, it has a moderately high sensitivity score and precision scores, respectively equal to 77.43%, and 78.79%. In general, this algorithm will be able to distinguish cases belonging to any of the classes, with a small margin of error.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":77.43},\\\"Accuracy\\\":{\\\"Model A\\\":76.86},\\\"Precision\\\":{\\\"Model A\\\":78.79}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balance with 52% of the data belonging to class C1 and 48% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The algorithm correctly generated the label (C1 or C2) in 76.86% of the test instances according to the accuracy score. Considering the distribution of the data across the labels, this algorithm demonstrates a model level of understanding of the classification problem. Therefore, from  moderately high sensitivity score and precision score (respectively equal to 77.43%, and 78.79%), we can conclude that the classifier is quite precise with the prediction decisions made for examples from both class labels.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":77.43},\\\"Accuracy\\\":{\\\"Model A\\\":76.86},\\\"Precision\\\":{\\\"Model A\\\":78.79}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 61% of the data belonging to class C1 and 39% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-Score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-Score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The trained classifier demonstrates a good ability to tell-apart test cases under the different labels, C1 and C2. The prediction accuracy score of 82.71% indicates it is able to correctly label about 82.71% of all test instances. Besides, it scored 78.52% (precision), 72.48% (recall), and 76.25% (F1-score) suggesting that the classifier is somewhat confident with the prediction outcomes or decisions.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.52}, \\\"Recall\\\":{\\\"Model A\\\":72.48},\\\"F1-score\\\":{\\\"Model A\\\":76.25},\\\"Accuracy\\\":{\\\"Model A\\\":82.71}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is  balanced with data belonging to class C1 (51%) and class C2 (49%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "From the scores table shown, the model is fairly confident about the predictions across the different metrics under consideration. Specifically, the model is shown to have a very high recall score of 94.23%, an accuracy of 94.56%, a high specificity score of 94.66% with a moderate F2-score equal to 94.56%. Overall, the model shows a very high prediction or classification performance indicating that it can accurately generate the true label for a large proportion of the test cases.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.66}, \\\"Recall\\\":{\\\"Model A\\\":94.23},\\\"F2-score\\\":{\\\"Model A\\\":94.56},\\\"Accuracy\\\":{\\\"Model A\\\":94.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (62%) and class C2 (38%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Recall\":\"5\",\"F2-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The following are the evaluation scores achieved by the algorithm on this binary classification task: Accuracy is 94.65%, Recall is 94.23%, Specificity is 94.66% and F2-Score is 94.56%. According to the scores above, this algorithm has a very high classification performance and is shown to be very effective at correctly recognizing the appropriate or right labels for multiple test cases. In conclusion, it has a lower mislabeling or misclassification error rate.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.66}, \\\"Recall\\\":{\\\"Model A\\\":94.23},\\\"F2-score\\\":{\\\"Model A\\\":94.56},\\\"Accuracy\\\":{\\\"Model A\\\":94.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (62%) and class C2 (38%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Recall\":\"5\",\"F2-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "This model achieved a very impressive classification performance with an accuracy of 94.65%. Also, the specificity, F2-score and recall scores are equal to 94.66%, 94.56, and 94.23%, respectively. Based on these metrics' scores, we can conclude that the model is effective (in terms of its prediction decisions) and can correctly classify a large number of test observations with a margin of error less than <acc_diff>%.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.66}, \\\"Recall\\\":{\\\"Model A\\\":94.23},\\\"F2-score\\\":{\\\"Model A\\\":94.56},\\\"Accuracy\\\":{\\\"Model A\\\":94.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (62%) and class C2 (38%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Recall\":\"5\",\"F2-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The performance of the classifier in the context of this classification problem where the test instances are classified as either C1 or C2 is: 94.66% (Specificity), 94.65% (accuracy), 98.02% (AUC score), and finally, an F1-score of 94.94%. These scores across the different metrics suggest that this classifier is very effective and can accurately identify the true label for a large proportion of test cases/instances. Furthermore, the precision and recall scores indicate that the likelihood of misclassifying test samples is quite small which is impressive and surprising given the distribution in the dataset.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.66},\\\"AUC\\\":{\\\"Model A\\\":98.02},\\\"Sensitivity\\\":{\\\"Model A\\\":94.23},\\\"F1-score\\\":{\\\"Model A\\\":94.94},\\\"Accuracy\\\":{\\\"Model A\\\":94.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (62%) and class C2 (38%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"AUC\":\"5\",\"Sensitivity\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The labeling performance of the algorithm in terms of correctly separating the observations or examples into the different classes, C1 and C2, was assessed based on the metrics: accuracy, AUC, specificity, and F1-score. From the table, it achieved the scores 94.66% (Specificity), 98.02% (AUC score), and 94.94% (F1-score). From these scores, we can conclude that this model has  very high classification performance, and hence will be highly effective at assigning the actual labels to several test cases with only a few instances misclassified.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.66},\\\"AUC\\\":{\\\"Model A\\\":98.02},\\\"Sensitivity\\\":{\\\"Model A\\\":94.23},\\\"F1-score\\\":{\\\"Model A\\\":94.94},\\\"Accuracy\\\":{\\\"Model A\\\":94.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (62%) and class C2 (38%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"AUC\":\"5\",\"Sensitivity\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "On this classification task where a given test sample is classified under either class C1 or class 2, the algorithms's classification performance is summarized by the scores 99.25% (accuracy), 98.34% (recall), 99.97% (AUC), 100.0% (specificity) and 99.16% (F1-score). From the F1-score, recall and specificity, we can see that the model has a very low false positive rate. This implies that the chances of examples belonging to class label #CB being misclassified as #CA is very low.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"AUC\\\":{\\\"Model A\\\":99.97},\\\"Recall\\\":{\\\"Model A\\\":98.34},\\\"F1-score\\\":{\\\"Model A\\\":99.16},\\\"Accuracy\\\":{\\\"Model A\\\":99.25}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 (51%) and class C2 (49%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The metrics under consideration suggest the algorithm performs very well on the classification task. The prediction accuracy is at 99.25%, AUC at 99.97%, recall at 98.34% and F1-score at 99.16% all paint an image of the model is performing very well at telling-apart the C1 and C2 instances/cases accurately and precisely. There is a balance between the recall and specificity, which indicates a very low false-positive rate.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"AUC\\\":{\\\"Model A\\\":99.97},\\\"Recall\\\":{\\\"Model A\\\":98.34},\\\"F1-score\\\":{\\\"Model A\\\":99.16},\\\"Accuracy\\\":{\\\"Model A\\\":99.25}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with data belonging to class C1 (51%) and class C2 (49%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier's performance on this binary classification task was evaluated based on the precision, recall, and F1-score. It achieved 87.68% (precision), 75.27% (recall) and 79.89%(F1-score). Judging by these scores attained, it is fair to conclude that the algorithm can accurately predict the true label for several test cases from both classes with a lower misclassification error.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.68},\\\"Recall\\\":{\\\"Model A\\\":75.27},\\\"F1-score\\\":{\\\"Model A\\\":79.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning model's performance on this binary classification problem (that is the test instances are classified as either C1 or C2) is: precision (87.68%), recall (75.27%), and an F1-score of 79.89%. The scores across the different assessment metrics suggest that this model will be moderately effective at correctly classifying the majority of test cases/instances with only a small margin of error.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.68},\\\"Recall\\\":{\\\"Model A\\\":75.27},\\\"F1-score\\\":{\\\"Model A\\\":79.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The performance assessment scores achieved by the classifier on this binary classification task are as follows (1) Precision score equal to 87.68%. (2) Recall score of 75.27%.  (3) F1-score of 79.89%. According to the scores across the different metrics under consideration, we can see that the classification ability of the classifier is moderately high. Finally, the confidence in predictions related to the label C2 is moderately high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.68},\\\"Recall\\\":{\\\"Model A\\\":75.27},\\\"F1-score\\\":{\\\"Model A\\\":79.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm trained to solve the given classification problem (where the test instances are classified as either C1 or C2) has the following prediction performance scores: Recall (91.04%), Precision (90.03%), and finally, an F1-score of 90.87%. These high scores across the different metrics demonstrate that this ML algorithm is very confident that the predicted label for the given test observation is equal to the true label.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.03},\\\"Recall\\\":{\\\"Model A\\\":91.04},\\\"F1-score\\\":{\\\"Model A\\\":90.87}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The performance assessment scores across the evaluation metrics are as follows (1) Recall score is equal to 91.04, (2) Precision score equal 90.03%.  and (4) F1-score of 90.87%. These scores demonstrate that this algorithm is quite effective and can correctly assign the appropriate label for most of the test examples with a small margin of error (that is, it has a very low error rate).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.03},\\\"Recall\\\":{\\\"Model A\\\":91.04},\\\"F1-score\\\":{\\\"Model A\\\":90.87}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Regarding this binary classification problem where the test instances are classified as either C1 or C2, the performance of the classifier is summarized as follows: precision (52.16%), recall (39.45%), and finally, an F1-score of 44.27%. The scores mentioned above suggest that this model is less effective and less precise (than expected) in terms of correctly predicting the true labels for the majority of test cases. Overall, from the F1-score, we can estimate that the likelihood of misclassifying test samples is high which is not surprising given the data is imbalanced.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":52.16},\\\"Recall\\\":{\\\"Model A\\\":39.45},\\\"F1-score\\\":{\\\"Model A\\\":44.27}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Regarding this binary classification problem where the test instances are classified as either C1 or C2, the performance of the classifier is summarized as follows: Recall (39.45%), precision (52.16%), and  F1-score of 44.27%. The classification power of the classifier is questionable given these moderately low scores. This implies that the chances of misclassifying any given test case is high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":52.16},\\\"Recall\\\":{\\\"Model A\\\":39.45},\\\"F1-score\\\":{\\\"Model A\\\":44.27}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (72%) and class C2 (28%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The prediction performance on this binary classification problem (where a given the test instance is classified as either C1 or C2) is; Precision (90.98%), Recall (88.13%), and F1-score of 89.42%. All these scores suggest that this model has a high classification power and will be effective in terms of its prediction decisions for several test examples drawn from any of the two-class labels, C1 and C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (83%) and class C2 (17%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The model has a prediction precision of about 90.98% with the F2-score and recall equal to 89.69% and 88.13%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the model performs fairly well in terms of correctly generating the true label for most of the test samples. According to the precision and recall scores, only a few instances belonging to C1 will be assigned the label C2 (i.e. low false-positive rate).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F2-score\\\":{\\\"Model A\\\":89.69}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (83%) and class C2 (17%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F2-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The following are the scores achieved by the classifier on this classification task: Recall of 88.13%; Precision score equal to 90.98%; Recall score equal to 88.13%; and an F1-score of 89.42%. With this model trained on an imbalanced dataset, the resulting high scores for the F1-score, precision and recall show that the model is effective and can correctly identify the true labels for most test cases/instances. In summary, it is fair to conclude that this model can correctly identify a large number of test instances.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (83%) and class C2 (17%)",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Across the evaluation metrics, the model obtained the scores 88.13%, 93.42%, 90.98%, and 89.42% for the recall, accuracy, precision, and F1-score, respectively. The precision and recall scores are higher than expected indicating how good the model is at correctly predicting the true labels for the majority of the test samples drawn from the different labels (i.e. C1, C2, and C3). Finally, the F1-score summarizes the confidence level of the model with the scores for precision and recall, further indicating how good or effective the model can be.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":93.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm's prediction performance on the given multi-class classification problem where the test instances are classified as either C1 or C2 or C3 is: (a) Accuracy = 93.42%. (b) Precision = 90.98%. (c) F1-score = 89.42%. (d) Recall = 88.13%. On this multi-class problem, the algorithm is shown to perform very well across all the evaluation metrics under consideration. The scores across the different metrics indicate that it is very effective and precise at correctly labeling most of the test observations.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":93.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Across the evaluation metrics used to assess the prediction performance of the classifier, it achieved the scores 88.13%, 93.42%, 90.98%, in respect of the metrics recall, accuracy, precision, and F1-score. With the classifier trained on a well-balanced dataset, the scores achieved across the metrics are high and somewhat identical. This indicates that it has a fairly high understanding of the underlying ML task. Specifically, from the accuracy and F1-score, we can estimate that this model will be very effective at correctly predicting the true labels for the majority of the test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":93.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The given model achieved a very good classification performance with an accuracy of 93.42%, and an F1-score of 89.42%. In addition, it boasts a precision equal to 90.98%, and a recall score equal to 88.13%. In terms of this multi-class classification task (where a given test observation is labeled as either C1 or C2 or C3), the scores achieved across these metrics are very high. These scores are very impressive and in most cases reflect that the model is very confident about its prediction decisions. Overall, this model will fail to accurately label only a small percentage of all possible test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":90.98},\\\"Recall\\\":{\\\"Model A\\\":88.13},\\\"F1-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":93.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"F1-score\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The learning algorithm or classifier trained to tackle the given labeling task achieves the following performance scores: (a) Accuracy: 89.42% (b) Recall: 79.46% (c) Precision: 77.58%. Regarding the model training objective, it shows moderately high classification performance judging by the scores achieved across the evaluation metrics. From the precision and recall scores, we can see that the classifier is relatively precise with its labeling decisions for most test examples drawn from the different classes under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.58},\\\"Recall\\\":{\\\"Model A\\\":79.46},\\\"Accuracy\\\":{\\\"Model A\\\":89.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm employed here on this cases labeling task performs quite well in terms of correctly picking out the test cases belonging to the different classes, C1, C2, and C3. It achieved a recall score of about 79.46%, a precision of 77.58% with a prediction accuracy of 89.42%. Its prediction performance can be summarized as fairly high in terms of precisely classifying test samples from any of the classes and the misclassification error rate is <acc_diff>.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.58},\\\"Recall\\\":{\\\"Model A\\\":79.46},\\\"Accuracy\\\":{\\\"Model A\\\":89.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning algorithm trained on this multi-class problem (where a given test case is labeled as either C1 or C2 or C3) achieves a recall score of 79.46%, a precision score of 77.58%, and accuracy equal to 89.42%. With such high scores across the different metrics, the algorithm is fairly effective at accurately and precisely generating the true labels for most test cases. This implies that there is a high level of confidence in the prediction decisions for the majority of test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":77.58},\\\"Recall\\\":{\\\"Model A\\\":79.46},\\\"Accuracy\\\":{\\\"Model A\\\":89.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning model scores very highly across all the evaluation metrics, precision, accuracy, and recall. Specifically, It has an accuracy of 69.02%, a recall of 68.15%, and a precision score of 68.49%. The model is shown to be moderately effective with its test cases labeling decisions and can correctly identify the correct labels for most of the test cases. The high performance of the model could be attributed to the data being very balanced between the classes (C1, C2, and C3) under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "On the task under consideration, this classification model achieved a score of 68.15% for the recall with a precision score of 68.49%. Furthermore, the accuracy score is 69.02%. From the evaluation scores mentioned, we can see that the model has a somewhat high classification performance hence will be able to (in most cases) accurately label test examples drawn from any of the different labels: C1, C2 and C3.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The model's classification performance on this multi-class labeling problem where the test instances are classified as either C1 or C2 or C3 is Precision (68.49%), Recall (68.15%), and Accuracy (69.02%). Considering the distribution of the data across the classes, these scores are high implying that this model will be moderately effective at correctly labeling close to a large percentage of all possible test examples with only a small margin of error.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "For this multi-class prediction task (where a given test observation is labeled as either C1 or C2 or C3), the model has 69.02% (accuracy), 68.15% (recall), and 68.49% (precision) score. Judging by the scores across the different metrics here, it could be concluded that this model will be moderately effective at correctly labeling most test cases with only a few instances misclassified.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Across the evaluation metrics used to assess the prediction performance of the classifier, it attained: (a)A prediction accuracy equal to 69.02%. (b) A recall score of 68.15% (c) Precision is 68.49%. These scores across the different metrics suggest that this model will be moderately effective at correctly labeling the examples belonging to the three-clas labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"3\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning algorithm trained according to the objective of the classification problem achieved a score of 69.02 for the accuracy, 68.49% for the precision score and 68.15% for the recall. Based on the evaluation metrics used to assess the prediction performance, the classifier demonstrates a fairly high classification capability. Overall, the model is relatively confident with its prediction decisions for the majority of test observations.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"3\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "On this multi-class classification problem where the test instances are classified as either C1 or C2 or C3, the ML algorithm boasts an accuracy of 69.02%, a recall score of 68.15%, a precision score of 68.49% with an F1-score of 68.21%. These scores across the different metrics suggest that this model will be moderately effective enough to sort between the examples belonging to the three labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":68.49},\\\"Recall\\\":{\\\"Model A\\\":68.15},\\\"Accuracy\\\":{\\\"Model A\\\":69.02},\\\"F1-score\\\":{\\\"Model A\\\":68.21}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b> and <b>C3</b></p>The dataset is balanced with data belonging to class C1, C3 and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier's performance scores are 81.49%, 86.11%, 80.52%, and 81.41%, respectively, based on the asssessment metrics accuracy, recall, precision, and F1-Score. These evalaution scores support the claim that this model can effectively and correctly predict the true label for a large proportion of the test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Recall\\\":{\\\"Model A\\\":86.11},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning algorithm trained on this binary classification objective achieved a prediction performance of 81.49% for the accuracy, 80.52% as the precision score with the recall score equal to 86.11%. The F1-score of 81.41%, a balance between the recall and precision scores indicates that it has high confidence in the prediction decisions for the test examples drawn randomly from any of the classes. The accuracy score indicates that the model is good at predicting the true label for test cases drawn randomly from any of the labels and the misclassification error rate is <acc_diff>.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Recall\\\":{\\\"Model A\\\":86.11},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "This learning algorithm achieved recall, accuracy, precision scores of 86.11%, 81.49%, and 80.52%, respectively. According to the precision and recall scores, the algorithm boasts an F1-score of about 81.41%. On the basis of the scores across the metrics, it is shown to have a moderately high prediction performance and is able to tackle the prediction objective (i.e. assigning a label either C1 or C2 to any given test case) quite well. Also looking at the F1-score, the prediction confidence related to the minority class label C2 is very high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Recall\\\":{\\\"Model A\\\":86.11},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm's capability to correctly classify any given test instance as either C1 or C2 was assessed based on the metrics Precision, Specificity, Accuracy, and F1-score. The scores achieved across these metrics are 80.52%, 76.19%, 81.49%, and 81.41%, respectively. The F1-score and accuracy indicate that the model has a moderate to high classification or prediction performance hence will be able to correctly classify most test samples. In fact, the misclassification rate is just about <acc_diff>%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Specificity\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm's prediction capability assessment scores are as follows: (a) Accuracy equal to 81.49%. (b) A precision score equal to 80.52%. (c) Specificity score equal to 76.19%. (d) F1-score of 81.41%. Considering the learning objective here and the scores with respect to the assessment metrics, the algorithm is shown to be quite good at correctly predicting the true label for test cases related to any of the classes under consideration. This is further supported by the F1-score of 81.41%. Therefore judging by the scores, we can conclude that the algorithm boasts a high classification performance and is quite confident with its labeling decisions.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Specificity\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Given this balanced dataset, the classifier trained to tackle the cases labeling task got a prediction accuracy of about 81.49% with the associated precision and specificity scores equal to 80.52% and 76.19%, respectively. Based on the scores across the different metrics under consideration, we can conclude that the classifier performs well in terms of correctly predicting the true label for most test cases. It has a moderately high accuracy and F1-score (81.41%) which means that the model is very confident with the predictions across the majority of the test cases. Actually, the mislabeling error rate is about <acc_diff>%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":80.52},\\\"Specificity\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":81.49},\\\"F1-score\\\":{\\\"Model A\\\":81.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Regarding this labeling task, the model was trained to classify test samples as class C1 or class C2. Evaluations or assessment conducted based on the metrics accuracy, sensitivity, specificity, and F1-score show that the model is fairly good at correctly recognizing the test cases belonging to each class or label. For the accuracy, it scored 85.53%, specificity at 82.59%, sensitivity at 88.89%, and precision score of about 85.33%. From the sensitivity and precision scores, the F1-score is estimated to be equal to 87.07% further suggesting that the confidence level with respect to the prediction or labeling decisions is quite high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F1-score\\\":{\\\"Model A\\\":87.07}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The model's aptitude to precisely generate the true label for any given test sample as either C1 or C2 was evaluated based on the metrics accuracy, sensitivity, specificity, and F1-score as shown in the table. On the basis of the metrics, evaluation scores summarizing its prediction performance are accuracy equal to 85.53%, sensitivity score equal to 88.89%, specificity score equal to 82.59%, and finally, an F1-score of 87.07%. From the F1-score and sensitivity score, the precision score achieved is about 85.33%. These scores across the different metrics suggest that this model is somewhat effective and can accurately produce the true labels for a large proportion of test cases with a marginal likelihood of misclassification (in fact, the error rate is about <acc_diff>%).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F1-score\\\":{\\\"Model A\\\":87.07}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier was trained to assign test cases the class label either C1 or C2 and the classification performance can be summarized as very high considering the scores achieved across the metrics accuracy, precision, sensitivity, specificity, and F1score. For example, the model boasts an accuracy of about 85.53%, a specificity score of 82.59%, with the precision and sensitivity equal to 85.33%, and 88.89%, respectively. As mentioned above, these scores indicate that the classifier has a very high classification performance hence can correctly identify the correct labels for a large proportion of test cases. Finally, from the accuracy score, the misclassification error rate is estimated as <acc_diff>%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F1-score\\\":{\\\"Model A\\\":87.07}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The performance evaluation scores on this binary classification task achieved by the classifier are as follows: (1) Accuracy equal to 85.53% (2) Sensitivity score equal 88.89% (3) Specificity score equal to 82.59% (4) F1-score equal to 87.07% (5) Precision score equal to 85.33%.  The F1-score and accuracy indicate a moderately high level of understanding the ML task and when coupled with the high precision and specificity scores show a strong ability on the part of the classifier to tell apart the examples under the different classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F1-score\\\":{\\\"Model A\\\":87.07}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Evaluating the classifier's prowess on the classification task produced the scores 85.33%, 88.89%, 82.59%, 85.53%, and 88.15%, respectively, across the metrics precision, sensitivity, specificity, accuracy, and F2-score. The difference between the precision, and sensitivity scores indicates that the classifier is very confident about its C2 predictions. Similarly, the specificity score also suggests the confidence with respect to C1 predictions is also high. From the above statements, we can conclude that the classifier has a good classification ability, only misclassifying a small percentage of all possible test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The ML algorithm trained on this prediction task achieved a sensitivity score of 88.89%, an accuracy of 85.53%, a precision score of 85.33%, and an F2-score of 88.15%. Also, a specificity score of 82.59% was achieved. According to the precision, sensitivity and specificity scores, the algorithm has a moderately low false positive and false negative rates. In the context of the training objective, we can assert that the algorithm demonstrates a high prediction performance and will be able to accurately label several test cases belonging to the classes under consideration (C1 and C2).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Considering the scores across the metrics precision, sensitivity, specificity, accuracy, and F2-score, the algorithm demonstrates a high prediction performance and will be able to accurately label several test cases belonging to any of the classes under consideration (C1 and C2). The performance assessment scores are (a) Accuracy is 85.53%. (b) F2-score is 88.15%. (c) Specificity is 82.59%. (d) Precision equal to 85.33% (e) Sensitivity or recall score of 88.89%.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning model's ability to correctly classify test cases as either C1 or C2 was evaluated based on the specificity, F2-score, precision, sensitivity, and accuracy. The scores achieved across the metrics are: 85.53% (accuracy), 85.33% (precision), 82.59% (specificity), 88.89% (sensitivity), and 88.15% (F2-score). From the precision and sensitivity scores, we can see that the model has a moderately high confidence in its prediction decisions. Besides, it has a misclassification error rate of about <acc_diff> according to the accuracy score achieved.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Regarding this binary classification problem where the test instances are classified as either C1 or C2, the classification performance of the classifier is accuracy (85.53%), precision (85.33%), sensitivity (88.89%), specificity (82.59%), and finally, an F2-score of 88.15%. These scores across the different metrics suggest that this model is somewhat effective and can accurately identify the true labels for several test cases with a small margin of error (actually, the likelihood for mislabeling test cases is <acc_diff>%).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The performance of the model on this binary classification task as evaluated based on the precision, accuracy, specificity, sensitivity, and F2-score, is 85.33%, 85.53%, 82.59%, 88.89%, and 88.15%, respectively. These scores are high implying that this model will be moderately effective in terms of its predictive power for the majority of test cases/samples. Furthermore, the precision, specificity, and recall scores show that the likelihood of misclassifying test samples is lower.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.33},\\\"Sensitivity\\\":{\\\"Model A\\\":88.89},\\\"Specificity\\\":{\\\"Model A\\\":82.59},\\\"Accuracy\\\":{\\\"Model A\\\":85.53},\\\"F2-score\\\":{\\\"Model A\\\":88.15}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is somewhat balanced with data belonging to class C1, and class C2.",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "id": 33,
            "task_name": "Credit Risk Classification",
            "narration": "The precision score of the classifier is equal to 89.95%, it has a close to perfect specificity score of 92.61%, an F1-score of 86.96%, and a prediction accuracy of 88.89%. From the F1-score and precision scores, the recall score is shown to be quite high. This implies that the model is well balanced and does the job well in terms of correctly separating the test cases. According to the F1-score and specificity, the model can generate the appropriate labels for examples drawn from any of the two classes with a higher level of confidence.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":92.607},\\\"Accuracy\\\":{\\\"Model A\\\":88.889},\\\"F1-score\\\":{\\\"Model A\\\":86.957},\\\"Precision\\\":{\\\"Model A\\\":89.95}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "KFH@C-TC@DR-GW23H-33-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":5,\"F1-score\":4,\"Specificity\":5}"
        },
        {
            "id": 33,
            "task_name": "Credit Risk Classification",
            "narration": "In the context of the prediction objective, the classifier got high precision, specificity, and accuracy scores. These are equal to 80.46%, 89.79%, and 90.15%, respectively. Besides, it scored moderately with respect to the recall (45.98%) and F1-score (58.52%). The specificity score and precision score demonstrate the classifier's capability to correctly tell-apart cases belonging to any of the classes. However, considering the difference between recall and precision, this classifier can be considered somewhat picky when it comes to assigning the C2 label to test cases. This implies that the majority of cases it is quite confident with the prediction decisions.",
            "narrative_question": "<li> Summarize the scores achieved by the model across the different evaluation metrics. </li> <li> In not less than two sentences discuss the overall performance of the Model A as shown by the values of the evaluation metrics: Accuracy, Specificity, F1-score and Precision. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.26",
            "nb_models": 1,
            "model_name": "Model-4",
            "narrator": 45,
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":89.79},\\\"Sensitivity\\\":{\\\"Model A\\\":45.98},\\\"Accuracy\\\":{\\\"Model A\\\":90.15},\\\"F1-score\\\":{\\\"Model A\\\":58.52},\\\"Precision\\\":{\\\"Model A\\\":80.46}}\"",
            "deleted": false,
            "date_submitted": "24/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "KFH@C-TC@DR-GW23H-33-APC",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F1-score\":3,\"Specificity\":5,\"Sensitivity\":3}"
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier was trained based on the labeling objective where a given test case is labeled as either belonging to class C1 or C2. The classification performance is evaluated based on the metrics such as accuracy, precision, and specificity. The prediction accuracy is about 74.07%, precision equal to 78.95%, specificity score of 89.74%, sensitivity score of 52.63%, and F2-score is about 56.39%. Judging by the difference between the precision and sensitivity scores suggests that this classifier is somewhat picky in terms of the test cases it labels as C2. With such high precision and specificity scores, we can be certain that most test cases labeled as C1 or C2 will be correct.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.95},\\\"Sensitivity\\\":{\\\"Model A\\\":52.63},\\\"Specificity\\\":{\\\"Model A\\\":89.74},\\\"Accuracy\\\":{\\\"Model A\\\":74.07},\\\"F2-score\\\":{\\\"Model A\\\":56.39}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "As reported by the scores across the metrics: sensitivity (52.63%), precision (78.95%), specificity (89.74%), accuracy (74.07%), and F2-score (56.39%), this learning algorithm achieved a moderately high prediction performance in the context of the objective of the classification task. This implies that it can accurately label a large proportion of all test examples belonging to the different classes with a small chance of misclassification. The high precision compared to the recall (sensitivity) score also suggests the algorithm is mostly precise about the decisions related to the label C2. Furthermore, the algorithm demonstrates high confidence in C1's predictions.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.95},\\\"Sensitivity\\\":{\\\"Model A\\\":52.63},\\\"Specificity\\\":{\\\"Model A\\\":89.74},\\\"Accuracy\\\":{\\\"Model A\\\":74.07},\\\"F2-score\\\":{\\\"Model A\\\":56.39}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"4\",\"F2-score\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "As stated in the results table, the classifier achieved the scores (1) Sensitivity equal to 52.63%. (b) Precision is 78.95%. (c) Specificity equal to 89.74%. (d) Prediction accuracy of 74.07% with the F2-score equal to 56.39%. By looking at the precision and specificity scores, the algorithm demonstrates a good prediction ability and correctly label test cases as either C1 or C2. Given that the scores are not perfect, there will be instances where the algorithm will fail to accurately label test cases. However, we can still conclude that the confidence level for predictions under both classes is quite high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.95},\\\"Sensitivity\\\":{\\\"Model A\\\":52.63},\\\"Specificity\\\":{\\\"Model A\\\":89.74},\\\"Accuracy\\\":{\\\"Model A\\\":74.07},\\\"F2-score\\\":{\\\"Model A\\\":56.39}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"3\",\"F2-score\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Evaluations based on precision, F1-score, and specificity allude to the model being termed as quite an effective model on the task under consideration. Here the prediction task is assigning a label (either C1 or C2) to test cases. From the F1-score, the model has a moderate sensitivity score which will be less than the precision score mentioned in the table shown. In fact, the high specificity and precision scores paint a clear picture of a relatively confident model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.95},\\\"Specificity\\\":{\\\"Model A\\\":89.74},\\\"F1-score\\\":{\\\"Model A\\\":63.16}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"4\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "In most cases, the model can correctly tell-apart the class label for the test observations. The AUC score of 80.82% implies a fair amount of positive examples will be separated from negative examples. Supporting the above claim are the high scores from the precision (78.98%) and specificity (89.74%). In conclusion, the confidence level with respect to any given prediction decision will be moderately high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.95},\\\"AUC\\\":{\\\"Model A\\\":80.82},\\\"Specificity\\\":{\\\"Model A\\\":89.74},\\\"Accuracy\\\":{\\\"Model A\\\":74.07},\\\"F1-score\\\":{\\\"Model A\\\":63.16}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"4\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Prediction accuracy of 60.74% tells a story of a model with a moderate classification performance so will probably misclassify a number of test cases. However, a very high specificity score of 98.72% suggests the classifier is very good at correctly identifying the cases belonging to class C1. A precision score of 83.33% suggests it is very confident about the C2 predictions but some examples belonging to C2 are being misclassified as C1, hence it is not surprising that it boasts such a moderate accuracy.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.33},\\\"Specificity\\\":{\\\"Model A\\\":98.72},\\\"Accuracy\\\":{\\\"Model A\\\":60.74}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "A very high level of specificity of 98.72% indicates that this algorithm is very good at detecting class C1 observations. Also, a precision level of 83.33% indicates that it is fairly confident in terms of class C2 predictions. By comparing the specificity and precision scores, it is not surprising that the prediction accuracy is about 69.74%. The algorithm is very picky with the examples it labels as C2 hence, some examples of C2 are mistakenly classified as C1.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.33},\\\"Specificity\\\":{\\\"Model A\\\":98.72},\\\"Accuracy\\\":{\\\"Model A\\\":60.74}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "According to the specificity score (98.72%) achieved, the algorithm employed to tackle this binary labeling task is very accurate with the C1 predictions. The moderate accuracy score (60.74%) can be explained by the precision score of 83.33%, which indicates some test cases belonging to class C2 are being mislabeled as C1. This implies that the algorithm is very precise with the cases it labels as C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.33},\\\"Specificity\\\":{\\\"Model A\\\":98.72},\\\"Accuracy\\\":{\\\"Model A\\\":60.74}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Taking a critical look at the scores suggest that the model is somewhat picky in terms to labeling cases as C2 and when it does, it is usually correct. This is because the specificity score is very high (98.72%) with the precision and accuracy  equal to 83.33% and 60.74%, respectively. In conclusion, the specificity score shows that it is very good at labeling cases from C1 as C1.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":83.33},\\\"Specificity\\\":{\\\"Model A\\\":98.72},\\\"Accuracy\\\":{\\\"Model A\\\":60.74}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The algorithm is shown to be about 99.27% sure about the prediction output decisions related to class C1 given the specificity score achieved. This implies that we have to look at the precision score (85.71%) to explain why the accuracy is only about 63.11%. Compared to the specificity score, we can explain that the moderate accuracy score is due to the fact that the model is very biased in favor of assigning class C1 to most test cases, with only a selected few being labeled as C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":99.27},\\\"Accuracy\\\":{\\\"Model A\\\":63.11}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "It is shown that the algorithm is approximately 99.27% confident in the labeling decisions related to the C1 class, taking into account the achieved specificity score. This means that taking a look at the precision (85.71%) to explain why the prediction accuracy is only about 63.11%. The moderate score for the accuracy can be attributed to the fact that the model is very biased in favor of assigning a C1 label to most test cases, with only a select few being classified as belonging to the alternative class, C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":99.27},\\\"Accuracy\\\":{\\\"Model A\\\":63.11}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning model employed on this classification task scored a specificity of 99.27%, a precision score of 85.71%, and a prediction accuracy score of 63.11%. A possible conclusion from the scores mentioned above is that across most cases, the model tends to be very certain about the predictions of C1 compared to C2. This is probably the reason why the accuracy score is that low. Given how biased the model is against C2, we can be very sure about the truthfulness of cases labeled as C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":99.27},\\\"Accuracy\\\":{\\\"Model A\\\":63.11}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The machine learning algorithm used on this classification problem has a specificity of 99.27%, a precision score of 85.71%, and a labeling accuracy score of 63.11%. A possible takeaway from the above estimates is that, in most cases, the algorithm tends to very confident about the predictions C1 than C2. This could explain the accuracy score achieved. Given the bias of the model against C2, we can be very confident in the veracity of the cases labeled C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Specificity\\\":{\\\"Model A\\\":99.27},\\\"Accuracy\\\":{\\\"Model A\\\":63.11}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "Evaluation performed to assess the quality of the classifier in terms of accurately identifying the true label for test examples showed that it has a prediction accuracy of 81.33%, very high specificity, and precision scores of 96.35%, and 91.07%, respectively. Besides, the classifier has a moderate recall score of 57.95%. By comparing the precision, recall, and specificity scores, we can see that the accuracy score achieved is dominated by the correct predictions related to class C1. The classifier doesn't seem to regularly assign the positive class C2, which implies the majority of the cases it thinks are from C2 are actually from C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"Recall\\\":{\\\"Model A\\\":57.95},\\\"Specificity\\\":{\\\"Model A\\\":96.35},\\\"Accuracy\\\":{\\\"Model A\\\":81.33}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"3\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The prediction performance of the ML model employed on this task can be summarized by the score: precision of 91.07%, recall score of 57.95%, accuracy score of 81.33%, and a very high specificity score of about 96.35%. These scores in essence imply the model's certainty when it comes to C1 and C2 prediction is high. However, with such a moderate recall (sensitivity) score, we can be sure that the model's prediction performance (as shown by the accuracy score) is dominated by how good it is in terms of labeling cases as C1. In summary, the probability of the model misclassifying C1 cases is lower than those belonging to C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"Recall\\\":{\\\"Model A\\\":57.95},\\\"Specificity\\\":{\\\"Model A\\\":96.35},\\\"Accuracy\\\":{\\\"Model A\\\":81.33}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"3\",\"Accuracy\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The predictive capability of the machine learning algorithm used for this task can be summed up with a recall score of 57.95%, an precision score of 91.07%, an accuracy score of 81.33%, and a specificity score of 96.35%. The scores mentioned above essentially imply high confidence in the model when it comes to the C1 and C2 predictions. However, with such a moderate recall (sensitivity), we can be confident that the classification performance of a model (as shown by the accuracy score) largely depends on how good it is in terms of labeling cases as C1. Thus, the probability that the model misclassifies the C1 cases is lower than the C2 cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"Recall\\\":{\\\"Model A\\\":57.95},\\\"Specificity\\\":{\\\"Model A\\\":96.35},\\\"Accuracy\\\":{\\\"Model A\\\":81.33}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"3\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "The classifier's performance can be summed up with a recall score of 57.95%, a precision score of 91.07%, an accuracy score of 81.33%, and a specificity score of 96.35%. Also, the F1-score according to the recall and precision score is 70.05%. These evaluation scores essentially suggest the classifier has high confidence for predictions of any of the two classes. However, with such a moderate F1-score, the accuracy score of the classifier is shown to be largely dependent on how good it is when labeling cases as C1. In conclusion, the likelihood that it mislabels the C1 cases is much lower compared to instances where it will misclassify the C2 cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"F1-score\\\":{\\\"Model A\\\":70.05},\\\"Recall\\\":{\\\"Model A\\\":57.95},\\\"Specificity\\\":{\\\"Model A\\\":96.35},\\\"Accuracy\\\":{\\\"Model A\\\":81.33}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "According to the results shown in the table, the model scored a precision of 91.89%, a sensitivity (recall) score of about 38.64%, an accuracy of 74.67%, and a close to perfect specificity score of 97.81%. Looking at the true negative rate (specificity) and the true positive rate (sensitivity), we can explain away that the model is mostly accurate with the C1 predictions, unlike C2 predictions. The model has some sort of bias against the C2 label; hence it is shown to be very picky in the cases it labels as C2. Therefore, for cases it labels as C2, we can be certain that it is indeed true.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.89},\\\"Sensitivity\\\":{\\\"Model A\\\":38.64},\\\"Specificity\\\":{\\\"Model A\\\":97.81},\\\"Accuracy\\\":{\\\"Model A\\\":74.67}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Quality Predictions",
            "id": 112,
            "narration": "According to the results presented in the table, the algorithm boasts a precision of 91.89%, a sensitivity of about 38.64%, an accuracy of 74.67%, and an almost ideal estimate of specificity of 97.81% on the given ML task. Taking into account the specificity and the sensitivity scores, we can explain that the algorithm employed here is largely accurate with C1 predictions as opposed to C2 predictions. The model has a sort of bias towards C1 and against the C2 label; therefore, it is shown to be very pretentious when assigning the label C2 to cases. Basically, for observations that are labeled as C2, we can be sure that they are indeed the case.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.89},\\\"Sensitivity\\\":{\\\"Model A\\\":38.64},\\\"Specificity\\\":{\\\"Model A\\\":97.81},\\\"Accuracy\\\":{\\\"Model A\\\":74.67}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p>The dataset is imbalanced with data belonging to class C1 (64%), and class C2 (36%).",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Water Quality Classification",
            "id": 70,
            "narration": "The algorithm trained on this classification task scored 76.21%, 77.44%, 81.25%, and 63.72%, respectively, across the metrics specificity, accuracy, sensitivity, and F1-score. The specificity score, and F1-score (a balance between the recall and precision scores) indicate that the algorithm has a good ability to tell apart the positive and negative classes; however, it has a slightly lower precision score. Overall, the performance of the model can be summarized as moderately high.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":77.44}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "MM3R7-D0LDT-XJ7X2_70-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Specificity\":\"4\",\"Sensitivity\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Specificity and Sensitivity. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 71,
            "narration": "The performance of the algorithm regarding this binary classification problem can be summarized as follows: (a) It scored 71.52% as its prediction accuracy. (b) The AUC score (indicating how good it is at telling apart the positive and negative observations) is about 84.98%. (c) The recall or sensitivity score is 59.06%. (d) The specificity score is 94.96%. The very high specificity coupled with the AUC score demonstrates that the algorithm can almost identify all the C1 cases. Overall, these scores is motivating the conclusion that the algorithm is moderately effective enough to sort between the examples belonging to the two classes.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":84.98},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Specificity\\\":{\\\"Model A\\\":94.96}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "JPLPR-AT2KK-1WJ3V_71-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"3\",\"AUC\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Sensitivity, AUC and Specificity. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 75,
            "narration": "Evaluated based on accuracy, AUC, precision, and recall, the algorithm's scores are 95.84%, 98.01%, 88.11% and 93.09%, respectively. These results/scores are very impressive given that they were all high. Overall, from these scores achieved we can conclude that this algorithm in general is highly effective at correctly classifying most test cases with only a small margin of error (the misclassification error rate is only about <acc_diff>%).",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Precision\\\":{\\\"Model A\\\":88.11},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Recall\\\":{\\\"Model A\\\":93.09}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "91QCH-3A85T-FNENX-75-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 76,
            "narration": "The algorithm's classification performance on this labeling task as evaluated based on the precision, accuracy, AUC, and sensitivity scores are 53.96%, 93.16%, 94.73%, and 80.01%, respectively. The scores across the metrics under consideration indicate that this algorithm is moderately effective and can accurately identify the true labels for several test instances/samples with a margin of error. This is because, judging by  precision and recall scores, the algorithm in some instances tends to label cases from the negative class (C1) as part of the positive class (C2).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":53.96},\\\"AUC\\\":{\\\"Model A\\\":94.73},\\\"Sensitivity\\\":{\\\"Model A\\\":80.01},\\\"Accuracy\\\":{\\\"Model A\\\":93.16}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "JCJNF-MQA@Y-RPXJ1_76-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Sensitivity\":\"4\",\"Precision\":\"3\",\"Accuracy\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Sensitivity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 79,
            "narration": "The accuracy, recall, and precision scores achieved by the learning algorithm on this binary classification problem are 87.74, 95.31, and 79.22, respectively. These scores are very high indicating that this algorithm will be relatively effective in terms of the prediction decisions made for several test samples. However, from the precision (79.22%) and recall (95.31%) scores, we can see a proportion of samples belonging to C1 will likely be misclassified as C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Recall\\\":{\\\"Model A\\\":95.31}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "H3HGT-CJFAF-ETP8L_79-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"Recall\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 78,
            "narration": "The scores the algorithm attains on this binary classification task are as follows (1) Labeling accuracy is equal to 96.53%. (2) Precision score equals 91.43%. (3) Recall score is 80.03%. (4) F1score of 85.33%. These scores are high, demonstrating that the model has a fairly good understanding of the objectives of the classification problem. According to scores across the different metrics under consideration, it is valid to conclude that this ML algorithm is highly effective at accurately classifying most unseen test cases or samples with only a few instances misclassified.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":80.03},\\\"F1-score\\\":{\\\"Model A\\\":85.33},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":96.53}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "LVLQW-HA20W-DX54K-78-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 91,
            "narration": "The ML algorithm was specifically trained to assign test cases to one of the following classes C1, and C2. Evaluations conducted based on the metrics: accuracy, recall, precision, and F1-score show that it has fairly high classification performance and will be able to correctly identify the true label for most test cases. With such a high recall, we can say that this algorithm tends to frequently label cases as C2, with only a few of these predictions being correct (as shown by the precision score).",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"Accuracy\\\":{\\\"Model A\\\":98.12},\\\"Precision\\\":{\\\"Model A\\\":66.45},\\\"F1-score\\\":{\\\"Model A\\\":77.15}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "N@LRQ-V33DP-19MDB_91-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.67},\\\"Recall\\\":{\\\"Model A\\\":69.2},\\\"F1-score \\\":{\\\"Model A\\\":68.64},\\\"Specificity\\\":{\\\"Model A\\\":53.25}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> 59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "According to the results, the algorithm achieved a classification performance of 62.67% (accuracy), 69.2% (recall) score, 53.25% (specificity), and 68.64% (F1-score). From these scores, we draw the conclusion that it has a lower prediction performance and as such will fail to correctly identify the true labels for a number of test cases belonging to any of the class labels. In fact, the prediction performance is suboptimal.",
            "task_name": "E-Commerce Shipping",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":1,\"Recall\":2,\"Specificity\":1,\"F1-score \":2}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":81.15},\\\"AUC\\\":{\\\"Model A\\\":96.38},\\\"Precision\\\":{\\\"Model A\\\":98.02}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Assigning observations to one of the labels, C1 and C2, is the classification objective upon which the algorithm was trained. According to the table shown, the algorithm boasts a recall score equal to 81.15%; the accuracy is 92.78% and the precision score is 98.02%. The precision and recall scores demonstrate that the algorithm does usually label cases as C2, but when it does, it is very certain about it. Overall, these scores support the conclusion that this algorithm will be highly effective at correctly labelling most test cases drawn from any of these classes with only a small margin of error.",
            "task_name": "Car Acceptability Valuation",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":3,\"AUC\":5,\"Precision\":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.92},\\\"Recall\\\":{\\\"Model A\\\":94.25},\\\"F1-score \\\":{\\\"Model A\\\":92.82},\\\"Precision\\\":{\\\"Model A\\\":94.36}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "On this multi-class classification problem, where the unseen cases are labeled as either C1 or C2 or C3 or C4, the classification algorithm has an accuracy of about 91.92%, a recall score of 94.25%, a precision score of 94.36%, and an F1-score of 92.82%. From the accuracy and F1-score, we can draw the conclusion that the prediction performance of the algorithm is very high, and hence, can accurately classify several test samples with a small margin of error.",
            "task_name": "Air Quality Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":5,\"F1-score \":5}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.45},\\\"Sensitivity\\\":{\\\"Model A\\\":74.07},\\\"AUC\\\":{\\\"Model A\\\":87.95},\\\"Precision\\\":{\\\"Model A\\\":86.96}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p> The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The AI algorithm's ability to correctly label unseen test samples as either C1 or C2 was assessed based on the metrics: precision, sensitivity, accuracy, and AUC. Respectively, it scored 86.96%, 74.07%, 91.45%, and 87.95%. From the precision score, we can see that the algorithm is relatively confident with the C2 predictions across the majority of the test cases. In summary, this algorithm tends to be somewhat picky in terms of the observations it labels as C2, given the difference between the recall and precision scores but will be very accurate whenever it assigns the C2 label.",
            "task_name": "Food Ordering Customer Churn Prediction",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 1,
            "imetric_score_rate": "{\"Accuracy\":5,\"Precision\":4,\"Sensitivity\":4,\"AUC\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.29},\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"F1-score \\\":{\\\"Model A\\\":77.15},\\\"Precision\\\":{\\\"Model A\\\":66.45}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The algorithm was trained on this classification problem or task to assign test cases to one of the following classes C1 and C2. The classification performance is summarized by the following scores: (a) Recall = 91.96%. (b) Precision = 66.45%. (c) Accuracy = 96.29%. (d) F1-score = 77.15%. From the scores across the different metrics, we can conclude that this model has relatively high classification performance, and hence will be very effective at correctly recognizing test cases belonging to each class. However, considering the difference between recall and precision scores, there could be some instances where test cases belonging under C1 are mistakenly labeled as C2.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":5,\"Recall\":5,\"Precision\":3,\"F1-score \":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.91},\\\"Recall\\\":{\\\"Model A\\\":74.05},\\\"F1-score \\\":{\\\"Model A\\\":80.38},\\\"Precision\\\":{\\\"Model A\\\":87.89}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The evaluation metrics employed to analyze the prediction performance of the classifier on this binary classification problem, where the test instances are classified as either C1 or C2 is Precision (87.89%), Accuracy (82.91%), Recall (74.05%), and finally, an F1-score of 80.38%. From scores across the different metrics under consideration, we can draw the conclusion that this classifier will be effective in terms of correctly predicting the true label for the majority of test cases related to class labels. Furthermore, from the F1-score and prediction accuracy, it is valid to say the likelihood of misclassification is very low (actually it is equal to <acc_diff>).",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.02},\\\"Recall\\\":{\\\"Model A\\\":74.09},\\\"F1-score \\\":{\\\"Model A\\\":80.38},\\\"Precision\\\":{\\\"Model A\\\":87.84}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The following are the evaluation scores summarizing the prediction performance of the algorithm on this ML task: (a)The accuracy is 86.02%. (b) The recall is 74.09%. (c) The precision is 87.84%. (d) The F1-score is 80.38%. These scores across the different metrics suggest that this model will be relatively effective at correctly identifying the true label for the majority of test cases belonging to class labels C1 and C2. Furthermore, from the precision and recall scores, we can assert that the likelihood of misclassifying C1 cases as C2 is marginal; however, given the picky nature of the algorithm, some cases belonging to C2 might end up being labeled as C1. Overall, the scores across the metrics are impressive but not surprising given the data was balanced between the class labels.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.91},\\\"Specificity\\\":{\\\"Model A\\\":90.84},\\\"Recall\\\":{\\\"Model A\\\":74.05},\\\"F1-score \\\":{\\\"Model A\\\":80.38},\\\"Precision\\\":{\\\"Model A\\\":87.89}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "In this case labeling problem, the model got an accuracy of 82.91% with a precision score of 87.89% and a recall score equal to 74.05%. According to the recall and precision scores, we can assert that the classifier is quite confident with the prediction decisions made across the majority of the test cases belonging to class C2. In fact, it has a moderately low false-positive rate, as indicated by scores achieved for precision and recall. Overall, a very high specificity score of 90.84% and an F1-score of 80.38% indicate a good model for sorting out the unseen instances belonging to classes C1 and C2.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Specificity\":5,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.91},\\\"Specificity\\\":{\\\"Model A\\\":90.84},\\\"Sensitivity\\\":{\\\"Model A\\\":74.05},\\\"F2-score \\\":{\\\"Model A\\\":76.46},\\\"Precision\\\":{\\\"Model A\\\":87.89}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Sensitivity equal to 74.05%, specificity equal to 90.84%, accuracy equal to 82.91%, F2-score of 76.46%, and precision score equal to 87.89%, respectively, were the evaluation metrics' scores achieved by the model trained to classify test samples under one of the following classes C1 and C2. According to the scores, this model demonstrates a moderately effective prediction ability, and hence, it can correctly produce the true label for the majority of examples sampled from both class labels. However, considering the specificity, sensitivity, and precision scores, it is important to note that this model doesn't usually outputs the C2 label, but whenever it is usually correct.",
            "task_name": "Personal Loan Modelling",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F2-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Sensitivity\":4,\"Specificity\":5,\"Precision\":4,\"F2-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":47.16},\\\"Recall\\\":{\\\"Model A\\\":42.88},\\\"F1-score \\\":{\\\"Model A\\\":44.13},\\\"Precision\\\":{\\\"Model A\\\":49.61}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Trained to recognize the correct class (either C1, C2, C3, and C4) for unseen or new examples, the model got the scores: Recall (42.88%), Accuracy (47.16%), Precision (49.61%), and finally, an F1-score of 44.13%. The scores across these performance assessment metrics show that this model will be moderately good at correctly predicting the true label for most of the test cases.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"Precision\":3,\"F1-score \":3}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":47.16},\\\"Recall\\\":{\\\"Model A\\\":42.88},\\\"F1-score \\\":{\\\"Model A\\\":44.13},\\\"Precision\\\":{\\\"Model A\\\":49.61}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Trained to identify the samples belonging to the various class labels under consideration (C1, C2, C3, and C4), the classifier received the scores: recall (42.88%), precision (49.61%), accuracy (47.16%), and finally, an F1-score of 44.13%. The scores are not high as one might expect; however, they show that in some cases, this classifier will be able to correctly produce the right label.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":3,\"Recall\":3,\"Precision\":3,\"F1-score \":3}"
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "The machine learning model's labeling performance scores on this two-way classification problem under consideration are as follows: (a) Accuracy is 84.41%. (b) Specificity is 91.08%. (c) Precision is 81.33%. (d) Sensitivity (or Recall) is 72.05%. (e) F1-score is 76.41%. The specificity score achieved implies that the model's prediction of C1 is about 91.08% correct at times. Looking at recall and precision scores, the model doesn't frequently generate the C2 label for test cases; therefore, whenever it labels an item as C2, we can trust that it is true. Overall, the model has a moderately high classification performance with the misclassification error of <acc_diff>.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":76.41},\\\"Sensitivity\\\":{\\\"Model A\\\":72.05},\\\"Precision\\\":{\\\"Model A\\\":81.33},\\\"Specificity\\\":{\\\"Model A\\\":91.08},\\\"Accuracy\\\":{\\\"Model A\\\":84.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"F1-score\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "Estimates of the labeling effectiveness of a machine learning model on this two-class classification problem are as follows: (a) Specificity is 91.08%. (b) Accuracy is 84.41%.  (c) Precision is 81.33%. (d) The sensitivity (or recall) score is 72.05%. (e) F1-score is 76.41%. The specificity estimate achieved suggests that the C1 prediction is generally about 91.08% correct. Looking at the F1-score (computed based on recall and precision metrics), the model doesn't often generate a C2 label for test cases; hence, whenever it marks an element as C2, we can be sure that this is correct. Overall, the model has relatively high classification performance and <acc_diff>% misclassification error.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":76.41},\\\"Sensitivity\\\":{\\\"Model A\\\":72.05},\\\"Precision\\\":{\\\"Model A\\\":81.33},\\\"Specificity\\\":{\\\"Model A\\\":91.08},\\\"Accuracy\\\":{\\\"Model A\\\":84.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"F1-score\":\"4\",\"Specificity\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "To estimate the effectiveness of the classifier on this binary classification task, the metrics: accuracy, AUC, precision, and sensitivity are employed. The score per each metric is: (a) Accuracy = 84.41%. (b) AUC score = 81.57%. (c) Precision = 81.33%. (d) Recall (or Sensitivity) = 72.05%. The scores stated above tell a story of a classifier with fairly high classification prowess, meaning it has only a few instances that will be misclassified. However, it is important to mention that some examples from C2 are likely to be mislabeled as C1 given the difference between the precision and recall scores. Overall, the classifier is generally confident about the predictions output decision across the labels C1 and C2.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":81.57},\\\"Sensitivity\\\":{\\\"Model A\\\":72.05},\\\"Precision\\\":{\\\"Model A\\\":81.33},\\\"Accuracy\\\":{\\\"Model A\\\":84.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "To evaluate the performance of the algorithm on this binary classification problem, the following metrics are used: precision, accuracy, AUC, and sensitivity (also referred to as recall). Score for each metric: (a) Accuracy equal to 84.41%. (b) AUC score equal to 81.57%. (c) Precision is equal to 81.33%. (d) Sensitivity equal to 72.05%. The above scores speak of an ML algorithm with a relatively high prediction skill, which means that only a few new or unseen items might be misclassified. It is important to note, however, that some samples from C2 are likely to be mislabeled as C1 considering the difference in recall and precision scores. Overall, the classifier or algorithm has good confidence in the generated output predictions for the labels C1 and C2.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":81.57},\\\"Sensitivity\\\":{\\\"Model A\\\":72.05},\\\"Precision\\\":{\\\"Model A\\\":81.33},\\\"Accuracy\\\":{\\\"Model A\\\":84.41}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "The algorithm's effectiveness is summarized by the following scores: (a) AUC score is 76.75%; (b) Accuracy is 81.93%; (c) Precision score is 84.36%; (d) Recall is 59.44%. The algorithm is shown to be a little biased against predicting the C2 label for even cases belonging to the class considering the precision and recall scores achieved. Irrespective of this behavior, the confidence in positive class predictions is pretty good. It does also quite well on the negative class label (C1).",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":76.75},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"Recall\\\":{\\\"Model A\\\":59.44},\\\"Precision\\\":{\\\"Model A\\\":84.36}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"4\",\"Recall\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "The effectiveness of the algorithm is assessed by the following points: (a) the AUC estimate is 76.75%; (b) the accuracy is 81.93%; (c) 59.44% for the recall; (d) the precision is 84.36%. Given precision and recall scores, the algorithm doesn't frequently generate the C2 label, even for some examples belonging to class C2. Regardless of this behavior, confidence in positive class predictions is very good. It also performs very well with negative class label (C1) predictions.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":76.75},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"Recall\\\":{\\\"Model A\\\":59.44},\\\"Precision\\\":{\\\"Model A\\\":84.36}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"AUC\":\"4\",\"Recall\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "According to the specificity score (94.05%), this classifier is very effective at predicting identifying the items belonging to majority class C1, which happens to be the negative class. In addition, precision and recall scores were 84.36% and 59.44%, respectively. Considering the precision and recall scores, the C2 is not generated often given how picky the classifier is. This implies that only a few instances or items belonging to C1 will be misclassified as C2 (that is, it has a low false-positive rate). On the other hand, in some cases, a subset of examples belonging to C2 might be misclassified as being part of C1. Also, the accuracy score of 81.93% is dominated by the correct C1 predictions as shown by the specificity, precision, and recall scores. Overall, this classifier has a somewhat acceptable prediction performance. The above assertions are based on the fact that the classifier was trained on an imbalanced dataset.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.05},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"Recall\\\":{\\\"Model A\\\":59.44},\\\"Precision\\\":{\\\"Model A\\\":84.36}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "Judging by the specificity score of 94.05%, this classifier is very good when it comes to distinguishing items belonging to the majority class C1 (which happens to be the negative label). This implies that only a few cases or items related to C1 will be mislabeled as C2 (i.e., it has a true-negative rate). Also, the algorithm boasts precision and recall scores equal to 84.36% and 59.44%, respectively. And given these scores, the positive class, C2, is not often predicted meaning the classifier is quite picky when deciding which cases to label as C2. In other words, a subset of C2 samples may be misclassified as part of C1. It is important to note that the 81.93% accuracy score is dominated by accurate C1 prediction, according to the specificity, precision, and recall scores. In summary, this classifier has a relatively acceptable labeling performance. The above statements shouldn't be surprising given the distribution of the dataset between the two classes.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.05},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"Recall\\\":{\\\"Model A\\\":59.44},\\\"Precision\\\":{\\\"Model A\\\":84.36}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Specificity\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "The learning model employed on this two-way classification task scored: (a) Specificity = 94.05%; (b) AUC = 76.75%; (c) Accuracy  = 81.93%; (d) F1-score = 69.75%. The specificity score of 94.05% implies that the model is very confident about the prediction of C1. However, from the F1-score (which is computed based on the precision and sensitivity score), we can judge that some instances belonging to C2 are likely to be mislabeled as C1. This implies the model doesn't assign the C2 class frequently, and whenever it does, we can be sure that this is correct. Overall, this model achieved a moderately high classification performance, only misclassifying a small number of cases.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.05},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"AUC\\\":{\\\"Model A\\\":76.75},\\\"F1-score\\\":{\\\"Model A\\\":69.75}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Specificity\":\"5\",\"F1-score\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "UPS customer service Ratings",
            "id": 117,
            "narration": "The algorithm trained on this classification task was evaluated and scored as follows: (A) Specificity = 94.05%. (B) AUC = 76.75%; (c) Accuracy = 81.93%; (d) F1-score = 69.75%. A specificity score of 94.05% means that the algorithm is very confident in the C1 prediction. However, the F1-score (calculated based on the precision and sensitivity score) shows that some cases under C2 are likely to be incorrectly labeled as C1. This means that the model does not often allocate C2 classes, and every time it does, we can be sure that this is correct. In conclusion, this algorithm has a relatively high classification performance and only a few unseen instances are misclassified.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":94.05},\\\"Accuracy\\\":{\\\"Model A\\\":81.93},\\\"AUC\\\":{\\\"Model A\\\":76.75},\\\"F1-score\\\":{\\\"Model A\\\":69.75}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  63.9.% of the data belonging to class C1 and 36.1 belonging to class C2",
            "imetric_score_rate": "{\"AUC\":\"4\",\"Specificity\":\"5\",\"F1-score\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.46},\\\"Recall\\\":{\\\"Model A\\\":64.45},\\\"F1-score \\\":{\\\"Model A\\\":64.66},\\\"Precision\\\":{\\\"Model A\\\":66.0}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "On this four-way (that is, a given test case is assigned to one of the following classes: C1, C2, C3, and C4) classification task, the algorithm's accuracy is 64.46%; recall is 64.45% and the precision score is 66%. From the recall and precision, the F1-score, of the predictions is 64.66%. The evaluation scores demonstrate that it can accurately label a fair number of items or cases drawn from any of the classes.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.46},\\\"Recall\\\":{\\\"Model A\\\":64.45},\\\"F1-score \\\":{\\\"Model A\\\":64.66},\\\"Precision\\\":{\\\"Model A\\\":66.0}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "For this classification task, any given test case is assigned to one of the following classes: C1, C2, C3, and C4. The accuracy of the algorithm employed is 64.46%. It has a recall of 64.45% and the precision is 66%. Judging by the recall and accuracy, the F1-score is 64.66%. The scores stated above indicate that it can accurately label a sufficient number of cases taken from any of the classes.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Recall\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.46},\\\"F1-score \\\":{\\\"Model A\\\":64.66},\\\"Precision\\\":{\\\"Model A\\\":66.0}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The algorithm's or classifier's prediction performance was evaluated based on the F1-score, precision, and accuracy metrics. On these metrics, it achieved moderately high scores. Specifically, the accuracy score is about 64.46%, the precision score is 66%, and the F1-score is about 64.66%. It is worth mentioning that the dataset used to train the algorithm had an identical distribution of cases between the classes: C1, C2, C3, and C4. With all these scores in mind, we can draw the conclusion that it can precisely produce the actual labels for a number of new instances or examples with a margin of error equal to <acc_diff>%.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":64.46},\\\"F1-score \\\":{\\\"Model A\\\":64.66},\\\"Precision\\\":{\\\"Model A\\\":66.0}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The predictive effectiveness of the classification algorithm is evaluated based on F1 scores, accuracy, and precision. It got a fairly high score for these assessment metrics. Specifically, the accuracy score is approximately 64.46%, the precision score is 66%, and the F1-score is approximately 64.66%. Note that the datasets used to train the algorithm have the same distribution of observations in the classes: C1, C2, C3, and C4. Considering all these estimates, we can conclude that with a misclassification error rate equal to <acc_diff>%, the algorithm can accurately return the actual tag for a proportion of test cases.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F1-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.56},\\\"F2-score\\\":{\\\"Model A\\\":71.54},\\\"Precision\\\":{\\\"Model A\\\":71.99}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "Assessing the classification performance of the algorithm showed that it has a prediction accuracy of 71.56%; a precision score of 71.99% and an F2-score (computed based on the recall and precision) is 71.54%. It got identical high scores across all the metrics under consideration. Judging by them, we can draw the conclusion that, it has learned enough information about the underlying ML task making it capable of producing the correct label for a number of items or examples with the misclassification error rate equal to <acc_diff>%.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F2-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.56},\\\"F2-score\\\":{\\\"Model A\\\":71.54},\\\"Precision\\\":{\\\"Model A\\\":71.99}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The classification performance evaluation of the algorithm showed a prediction accuracy of 71.56% and the F2-score (calculated based on recall and precision (which is equal to 71.99%)) is 71.54%. This classifier achieved an almost similar high score on all the metrics. We can draw the conclusion that the classifier has been able to learn or capture enough information about the underlying ML task to make it possible to produce correct labels for some items or examples. It is important to note that the misclassification error rate is equal to <acc_diff>%.",
            "task_name": "Debtors Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F2-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":70.67},\\\"F2-score\\\":{\\\"Model A\\\":70.63},\\\"Precision\\\":{\\\"Model A\\\":72.90}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The underlying objective used to train this classifier is: assigning a label (either C1 or C2 or C3 or C4) to any given test example or observation. The performance was evaluated based on the scores achieved for the metrics: precision, F2-score, and accuracy, which were equal to 72.9%, 70.63%, and 70.67%, respectively. Given the distribution of the dataset between the four classes, we can draw the assertion that this classifier is not biased in favor of any of the classes. The scores are high and acceptable suggesting it has learned the necessary features or information to be able to accurately tell-apart the observations belonging to the different classes.",
            "task_name": "Food Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F2-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":70.67},\\\"F2-score\\\":{\\\"Model A\\\":70.63},\\\"Precision\\\":{\\\"Model A\\\":72.90}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "The training objective of this learning task is to assign a label (either C1 or C2 or C3 or C4) to each given sample of test or observation. Prediction performance was evaluated based on the scores achieved for the metrics: accuracy, precision, and F2-score, and showed that it scored 70.67%, 72.9%, and 70.63%, respectively. Considering the distribution of the dataset across the four labels, we can make the statement that this classifier is good. Furthermore, the high scores indicate that it has successfully learned the features or information needed to be able to accurately distinguish observations drawn from any of the classes.",
            "task_name": "Food Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Accuracy\":4,\"Precision\":4,\"F2-score \":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.68},\\\"F2-score\\\":{\\\"Model A\\\":70.63},\\\"Precision\\\":{\\\"Model A\\\":72.90}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "For this classification task, a given test instance is labeled as either C2 or C1 or C3 or C4. The performance of the trained model is summarized by the scores: (a) Recall = 70.68%; (b) Precision = 72.90%; (c) F2-score = 70.63. Judging by the scores, the model has moderately high predictive ability since it is shown to be able to accurately label a fair number of cases drawn from any of the four classes.",
            "task_name": "Food Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Recall\":4,\"Precision\":4,\"F2-score\":4}"
        },
        {
            "narrator": 45,
            "model_name": "Model-3",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":70.68},\\\"F2-score\\\":{\\\"Model A\\\":70.63},\\\"Precision\\\":{\\\"Model A\\\":72.90}}\"",
            "deleted": false,
            "date_submitted": "27/09/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b>, <b>C2</b>, <b>C3</b> and <b>C4</b></p> ",
            "redeem_code": "6940G-WGN6R-2PH3X_57-APC",
            "nb_models": 1,
            "narration": "This is a four-way classification problem where a given example can be labeled as either C1 or C2 or C3 or C4. The effectiveness of the trained model was evaluated according to the metrics recall, precision, and F2-score. It scored (a) Recall equal to 70.68%; (b) Precision equal to 72.90%; (c) F2-score equal to 70.63%. The model has a relatively high prediction power, as it has been shown to be able to accurately classify a large number of cases with a small margin of error.",
            "task_name": "Food Categorization",
            "narrative_question": "<li> Provide a sentence summarizing the evaluation metrics' scores (i.e Accuracy, Recall, Specificity and F1-score ) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of (1) achieving F1-score  of 67.47 and (2) achieving a Specificity of 56.02.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "10.212.134.22",
            "is_dataset_balanced": 2,
            "imetric_score_rate": "{\"Recall\":4,\"Precision\":4,\"F2-score\":4}"
        },
        {
            "task_name": "Insurance Churn",
            "id": 28,
            "narration": "The classifier achieves a precision score of 45.01% with a recall of about 58.09%. Other scores achieved were 89.91% (accuracy) and 87.58% (AUC). Since the model was trained on an imbalanced dataset, the metrics of importance were precision and recall scores. The scores achieved across these metrics are low, hence the model will have a lower F1-score. This implies that the model will perform poorly in terms of the prediction decisions for the samples drawn for the less common class label C2. Even based on the AUC and accuracy scores, we can conclude that the model has somewhat poor performance.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.914},\\\"Recall\\\":{\\\"Model A\\\":58.086},\\\"AUC\\\":{\\\"Model A\\\":87.581},\\\"Precision\\\":{\\\"Model A\\\":45.013}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "V4QTB-B204H-J9VHF-28-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 89.91 and AUC of 87.58. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Student Job Placement",
            "id": 29,
            "narration": "For the evaluation metrics recall, AUC, accuracy, and precision, the model achieved scores of 90.0%, 97.45%, 93.02%, and 100.0%, respectively. Based on the almost perfect scores across the different metrics under consideration, it is valid to conclude that this model will be very effective at correctly predicting the true class label for the majority of the test cases/samples.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.02},\\\"AUC\\\":{\\\"Model A\\\":97.45},\\\"Recall\\\":{\\\"Model A\\\":90.0},\\\"Precision\\\":{\\\"Model A\\\":100.0}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "X8@@3-NN9Y4-L6@BG_29-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving Recall of 90.0 and AUC of 97.45.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 30,
            "narration": "The following are the scores achieved by the classifier on this ML task: Accuracy of 62.98; recall score of 50.0%; precision score of 69.36%. On the basis of the precision and recall scores, the model's F1-score is about 58.11%. Judging from scores across the metrics, we can conclude that the model has somewhat lower performance, and hence will be moderately good at correctly sorting out the true label for the majority of the samples drawn from the different classes, C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.985},\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"F1-score\\\":{\\\"Model A\\\":58.108},\\\"Precision\\\":{\\\"Model A\\\":69.355}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "D3BDR-19LTL-PGNEG-30-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 62.98 and Recall of 50.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "House Price Classification",
            "id": 31,
            "narration": "According to the table, the model has a prediction accuracy of 79.41% with precision and recall scores equal to 89.36% and 72.41%, respectively. Based on the precision and recall scores, we can see that the F1-score is 80.01%. However, since the recall is greater than the precision score, some observations labeled as C2 by the model could be from label C1. Given that the model was trained on a balanced dataset, we can say that it has moderate prediction performance and that it can fairly identify the correct class labels for test cases from both class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.412},\\\"Recall\\\":{\\\"Model A\\\":72.414},\\\"F1-score\\\":{\\\"Model A\\\":80.01},\\\"Precision\\\":{\\\"Model A\\\":89.362}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "RGBGM-8UPQT-B2YR4_31-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Tic-Tac-Toe Strategy",
            "id": 32,
            "narration": "On this ML problem, the model achieves the scores 79.59% (Precision), and 88.64% (F1-score). Furthermore, it has almost perfect Accuracy and AUC scores of 93.06% and 99.29%, respectively. Based on all the scores, the model is shown to have a somewhat high prediction performance and will be able to correctly identify the majority of test cases from even the minority class (C2). In other words, in most cases, it can correctly tell apart (with moderately high confidence) the unseen observations belonging to the different classes.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.056},\\\"AUC\\\":{\\\"Model A\\\":99.291},\\\"F1-score\\\":{\\\"Model A\\\":88.636},\\\"Precision\\\":{\\\"Model A\\\":79.592}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "2VK9M-WNQYE-25K76-32-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"AUC\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and AUC. (Your answer should capture the implications of achieving AUC of 99.29 and Precision of 79.59.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 33,
            "narration": "The machine learning model trained on the given classification task attained the performance evaluation score of 94.51% when measuring accuracy; 99.1% for AUC, and 91.12% and 90.2% for precision and recall respectively.  The model performed well in general and prediction ability is balanced (i.e. not biased) across the two classes with similar precision and recall values of 91.1% and 90.2% respectively, which was achieved despite the <|majority_dist|>/<|minority_dist|> imbalanced distribution in the dataset across the different classes C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.51},\\\"Recall\\\":{\\\"Model A\\\":90.20},\\\"AUC\\\":{\\\"Model A\\\":99.099},\\\"Precision\\\":{\\\"Model A\\\":91.12}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "EDTU9-KNAVK-GEGTB_33-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 91.09 and Recall of 90.2. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Cab Surge Pricing System",
            "id": 34,
            "narration": "Regarding the F1-score, accuracy, recall, and precision metrics, the model got scores of 88.65%, 83.99%, 83.74%, and 94.18%, respectively. The accuracy is very similar to recall and quite dissimilar to precision, which is substantially higher. This suggests that the precision metric dominates the accuracy measure rather than recall. In summary, the classifier will be able to correctly label test cases from any of the class labels C1, C2 and C3 with a small chance of error.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.986},\\\"Recall\\\":{\\\"Model A\\\":83.74},\\\"F1-score\\\":{\\\"Model A\\\":88.653},\\\"Precision\\\":{\\\"Model A\\\":94.18}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
            "redeem_code": "T8NA3-GUQL1-W48VA-34-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 83.74 and Accuracy of 83.99. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "2.25.71.194",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 35,
            "narration": "Evaluation metric scores of 74.19% for accuracy, 91.11% for recall, 53.25% for precision, and 91.09% for AUC were achieved by the model. Despite training on a balanced dataset, the model has a bias towards predicting the positive C1 class for several test cases, since it has a low precision of 53.25% but a high recall of 91.11%. This implies the  confidence related to class C2 prediction is usually low, making the model less useful than it may seem from the 74.19% accuracy.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.194},\\\"Recall\\\":{\\\"Model A\\\":91.111},\\\"AUC\\\":{\\\"Model A\\\":91.092},\\\"Precision\\\":{\\\"Model A\\\":53.247}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "UV7@U-RGNLU-D71VG-35-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision, Accuracy and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 91.11 and Precision of 53.25. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Attrition",
            "id": 36,
            "narration": "The classifier obtained the following evaluation scores on the given machine learning classification problem: AUC: 84.46%, accuracy: 87.11%, precision: 40.82%, recall: 83.33%. The low precision of the model suggests that the model has a bias towards predicting the negative class label (C1). This is to be expected and remains a challenge when working with a large dataset imbalance, where <|majority_dist|> of the data belong to class C1. This bias implies that the performance of the model is worse than what the moderately high accuracy of 87.11% or the AUC of 84.46% suggests.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.816}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 37,
            "narration": "Metric values of 72.0% for accuracy, 73.5% for AUC, 60.47% for sensitivity, and 32.91% for precision were achieved by the model. The model achieves a reasonable AUC of 73.5% showing some degree of understanding. The very low precision of 32.91% with moderate sensitivity (recall) of 60.47% suggests that the model has a bias against predicting the positive class, C2, which is also the minority class with about <|minority_dist|> of examples in the dataset.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":72.0},\\\"Sensitivity\\\":{\\\"Model A\\\":60.465},\\\"AUC\\\":{\\\"Model A\\\":73.499},\\\"Precision\\\":{\\\"Model A\\\":32.911}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "XGT6Y-BJ0YV-4MV4L_37-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"1\",\"Accuracy\":\"2\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Sensitivity, Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 38,
            "narration": "The algorithm's ability to tell-apart the examples belonging to the different classes was evaluated based on the metrics accuracy, recall, F1-score, and precision. It achieved the following scores: accuracy equal to 71.04%; F1-score of 56.5%, precision of 50.81%, and a recall score of 63.64%. On such an imbalanced dataset, only the F1-score, precision and recall are important when making a decision about how good the model is. From the scores across the different metrics, we can conclude that the model has a moderate false-positive rate, and only a few examples from class label C2 can be correctly classified.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Recall\\\":{\\\"Model A\\\":63.64},\\\"F1-score\\\":{\\\"Model A\\\":56.50},\\\"Precision\\\":{\\\"Model A\\\":50.81}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "UN099-UM@EN-LX4JU-38-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
            "model_name": "Model-6",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, F1-score, Precision and Accuracy. (You should consider the implications of the model's score across each metric. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 39,
            "narration": "On these metrics Accuracy, Precision, F1-score and Recall, the model achieved 93.88%, 67.66%, 80.61% and 99.69%, respectively. According to the F1-score, it can be said that the model has a moderate classification performance. It can successfully produce the correct label for most test cases. However, some cases from class C1 will be labeled as C2 judging based on the difference between the precision and recall scores.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.88},\\\"Recall\\\":{\\\"Model A\\\":99.69},\\\"F1-score\\\":{\\\"Model A\\\":80.61},\\\"Precision\\\":{\\\"Model A\\\":67.66}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "P6L66-M@4H6-6YK@M-39-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"3\",\"F1-score\":\"4\",\"Recall\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, F1-score and Recall. (Your answer should capture the implications of achieving Accuracy of 93.88 and Precision of 67.66.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 40,
            "narration": "From the table shown, we can say the model has a 78.65% Recall score, 83.48% F1-score, 88.94 precision, and an Accuracy score of 93.38%. This model despite being trained on an imbalanced dataset, is shown to do pretty well at picking out a large number of examples belonging to any of the two classes. Based on the precision score (88.94%) and recall score (78.65%), we can say that it has a lower false-positive rate. It goes to show that the model doesn't frequently label test observations as C2, but when it does, it is usually correct.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":83.48},\\\"Precision\\\":{\\\"Model A\\\":88.94}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "7F8VR-PD5M8-QG7Q8-40-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F1-score\":\"4\",\"Precision\":\"4\",\"Recall\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 41,
            "narration": "Across the metrics: AUC, Recall, Precision, and Accuracy, the model achieved very high scores (i.e., 98.59, 97.33, 94.8, and 96.0, respectively). According to these scores, the model is very confident regarding its prediction decisions for unseen cases from any of the class labels. In simple terms, it can correctly classify a larger number of test cases belonging to the different classes under consideration, and the misclassification rate is <acc_diff>.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Recall\\\":{\\\"Model A\\\":97.333},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Precision\\\":{\\\"Model A\\\":94.805}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "1CC3F-2YAR6-@HWD0_41-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 97.33 and Accuracy of 96.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Broadband Sevice Signup",
            "id": 42,
            "narration": "These are the scores the model achieved across the following metrics: Accuracy (93.07%); Precision (91.75%), and Recall (92.97%). Given the fact that it was trained on imbalanced data, its prediction performance is very high with almost perfect scores across the metrics. This implies that the model will be very effective at correctly predicting the actual or true labels for the majority of test cases.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.073},\\\"Recall\\\":{\\\"Model A\\\":92.966},\\\"Precision\\\":{\\\"Model A\\\":91.746}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "N1NQ6-MEHMY-FVQLG_42-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision and Recall. (You should consider the implications of the model's score across each metric. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.201",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 43,
            "narration": "On this ML problem, the model has a recall of 71.74% and a precision score equal to 57.9%. Besides, it has an accuracy of 81.5%. Judging from the scores, the model demonstrates a fairly moderate prediction performance. It has a high chance of mislabeling some test observations drawn from the class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":71.739},\\\"Precision\\\":{\\\"Model A\\\":57.895}}\"",
            "deleted": false,
            "date_submitted": "08/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "JM18F-9N8UX-FM0H6_43-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 57.9 and Recall of 71.74. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 44,
            "narration": "According to the table shown, the algorithm achieved almost perfect scores for accuracy (97.99%) and recall (99.19). Besides, it also has a high F1-score and precision score, respectively, equal to 88.17% and 79.36%. Judging by these high scores, we can say the model can confidently generate the true label for a large number of test cases. However, not all C2 predictions are actually true considering the difference between precision and recall scores.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.994},\\\"Recall\\\":{\\\"Model A\\\":99.194},\\\"F1-score\\\":{\\\"Model A\\\":88.172},\\\"Precision\\\":{\\\"Model A\\\":79.355}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "J6R3B-UNXYA-37HMB_44-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 45,
            "narration": "This ML algorithm achieved almost perfect scores across the recall, accuracy, precision and AUC evaluation metrics. With the model being trained on a somewhat balanced dataset, it is not surprising to see such high scores. These scores achieved by the model indicate that it can confidently and accurately predict the actual label for a larger number of test cases.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.97},\\\"Recall\\\":{\\\"Model A\\\":91.502},\\\"AUC\\\":{\\\"Model A\\\":97.432},\\\"Precision\\\":{\\\"Model A\\\":92.365}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "BPFG6-VPX65-E5EKP_45-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Real Estate Investment",
            "id": 46,
            "narration": "As shown in the table above, the model has an accuracy of 95.11%, recall of 94.12%, AUC of 96.12%, and a precision score of 85.71%. With such high scores across the metrics, the model is almost certain to make just a few mistakes. That is, it has low misclassification error/rate close to about <acc_diff>. Furthermore, the prediction performance is very impressive considering the fact that it was trained on such an imbalanced dataset.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.11},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":94.12}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "K7LMJ-BDK1T-DNDKJ-46-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 47,
            "narration": "The following are the performance evaluation metrics employed to assess the classification capability of the algorithm: AUC, Accuracy, Recall, and Precision. For the AUC and accuracy, it achieved 98.37% and 94%, respectively. The precision score is 89.61% and an almost perfect recall of 98.57%. Trained on a balanced dataset, the classifier's performance is not that surprising. Overall, this model is likely to have a lower misclassification error as indicated by the scores. This implies that it will be highly effective at correctly predicting the correct class label for several test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":98.57},\\\"Accuracy\\\":{\\\"Model A\\\":94.0},\\\"Precision\\\":{\\\"Model A\\\":89.61},\\\"AUC\\\":{\\\"Model A\\\":98.37}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "NHYBL-BC65X-C4V8P_47-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Air Quality Prediction",
            "id": 48,
            "narration": "For this multi-class classification task (where a given test case is labeled as either C1 or C2 or C3 or C4), the model has close to perfect score across all the evaluation metrics under consideration (that is, Accuracy = 97.54%; Precision = 97.69%; F1-score = 97.32%; and Recall = 96.95%). From the classification performance, it is valid to say this model is very effective at correctly recognizing  test cases drawn from all the class labels with a lower misclassification error rate.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":97.69},\\\"Accuracy\\\":{\\\"Model A\\\":97.54},\\\"F1-score\\\":{\\\"Model A\\\":97.32},\\\"Recall\\\":{\\\"Model A\\\":96.95}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "NKQH7-N6K0K-A1K8U_48-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 49,
            "narration": "Evaluated based on the metrics Precision, AUC, Accuracy and Recall, respectively, the classifier achieved the scores of 93.2%, 99.34%, 98.17% and 98.56.  Trained on an imbalance dataset, these scores are impressive and very good indicative of the high classification performance of the model. It has a very low false positive error rate as indicated by the very high precision score.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":93.21},\\\"AUC\\\":{\\\"Model A\\\":99.34},\\\"Accuracy\\\":{\\\"Model A\\\":98.17},\\\"Recall\\\":{\\\"Model A\\\":98.56}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "U4PUE-AY3XX-5YVF4-49-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 93.21 and AUC of 99.34. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 50,
            "narration": "The evaluation performance score achieved are as follows: (a) Accuracy: 83.15% (b) F2-score: 79.41 (c) Recall: 79.36%  (d) Precision: 79.71%. According to the scores above, the algorithm employed to solve this ML task has a moderately high classification performance and will be able to correctly classify most test samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.71},\\\"Accuracy\\\":{\\\"Model A\\\":83.15},\\\"Recall\\\":{\\\"Model A\\\":79.36},\\\"F2-score\\\":{\\\"Model A\\\":79.41}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "X0DG2-168@U-76E11_50-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F2-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, F2-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Water Quality Classification",
            "id": 51,
            "narration": "According to the table shown, the model achieved an Accuracy of 77.44%, Specificity score of 76.21%, a Sensitivity score (i.e. Recall) equal to 81.25%, and an F1-score of 63.72%. This model trained on an imbalanced dataset has a moderate classification performance hence might misclassify some test samples especially those drawn from the class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.44},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "B4PHL-6Y4AH-VUJ0G-51-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"F1-score\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Specificity, Sensitivity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 63.72 and Sensitivity of 81.25. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 52,
            "narration": "Trained on a balanced dataset, this model achieves F1-score(77.06%), Precision(68.58%), Recall(87.94%) and Accuracy(79.8%). These scores imply that the model will be somewhat good at separating the test samples into their respective class label. From the accuracy and F1-score, there is a chance that a number of test cases might be mislabeled. For example, according to the recall and precision scores, some C1 examples might be mislabeled as C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"F1-score\\\":{\\\"Model A\\\":77.06},\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Precision\\\":{\\\"Model A\\\":68.58}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "4YE64-BMDAR-RDXWJ-52-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Precision, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Precision, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Cab Surge Pricing System",
            "id": 53,
            "narration": "The classifier enjoys an accuracy of 83.99%, an F1-score of 88.65%, precision equal to 94.18%, and a recall score of 83.74%. For this multi-class problem, a valid conclusion that can be made about the model is that, it has a high classification performance, hence will be able to correctly classify test samples from any of the labels.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":88.65},\\\"Precision\\\":{\\\"Model A\\\":94.18},\\\"Recall\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":83.99}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
            "redeem_code": "7XFCM-BRE@6-30CF7-53-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 54,
            "narration": "The table shows the scores achieved by the model across the metrics under consideration. For the prediction accuracy metric, the model achieved a score of 69.2%. Sensitivity equal to 51.85%, AUC of 74.06%, and a very low precision score of 35.44%. Due to the fact the model is being trained on an imbalanced dataset, only the recall (sensitivity) and precision scores are important. This model performs poorly on the classification problem. It has a very high false-positive rate, hence will find it difficult to correctly classify test samples, especially those from the class label C2.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44},\\\"Sensitivity\\\":{\\\"Model A\\\":51.85}}\"",
            "deleted": false,
            "date_submitted": "10/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "RE@@2-LBJH8-L6R22_54-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 55,
            "narration": "On this ML classification task, the model scored 50.01% (recall), 62.98% (accuracy) and 69.36% (precision). From the recall and precision, we can see that the model achieves an F1-score of 58.11%. Even though the model was trained on imbalanced data, we can say that the model might find it difficult to accurately identify the labels for test cases drawn randomly from any of the class labels. In summary, we can conclude that this model has low predictive power.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.36},\\\"Recall\\\":{\\\"Model A\\\":50.01},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Accuracy\\\":{\\\"Model A\\\":62.98}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "9V2TG-4J0M5-UHY68_55-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"2\",\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, F1-score, Accuracy and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 50.0 and Accuracy of 62.98. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 56,
            "narration": "On this ML problem, the algorithm employed achieved accuracy equal to 99.95%, with the F1-score, precision, and recall, respectively, equal to 84.32%, 77.23%, and 92.86%. This classification problem is one of the extreme cases of class imbalance, with almost all the examples belonging to the class label C1. Therefore, the accuracy of 99.95% is not a good indicator of how well the algorithm performs across the examples from both classes. It is the F1-score (balance between the recall and precision scores) that is very important here. From the F1-score, we can draw the conclusion that overall the algorithm has moderate performance and will struggle a bit when it comes to examples belonging to the minority class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.95},\\\"Precision\\\":{\\\"Model A\\\":77.23},\\\"F1-score\\\":{\\\"Model A\\\":84.32},\\\"Recall\\\":{\\\"Model A\\\":92.86}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "8583H-9JTAY-4FH7G_56-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 56,
            "narration": "The algorithm's prediction prowess is summarized by the F1-score, precision, and recall, respectively, equal to 84.32%, 77.23%, and 92.86%. Also, the accuracy of predictions is equal to 99.95%. For this classification problem the majority all the examples belong to the class label C1. Hence, making judgments about the overall performance of the algorithm based on the accuracy of 99.95% is not ideal. The overall performance is correctly reflected by the F1-score (balance between the recall and precision scores). Overall, the algorithm has the tendency to predict the majority of examples as C1 even though their actual label is C2. That is, the algorithm has moderate classification performance and will struggle a bit when it comes to examples belonging to the minority class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.95},\\\"Precision\\\":{\\\"Model A\\\":77.23},\\\"F1-score\\\":{\\\"Model A\\\":84.32},\\\"Recall\\\":{\\\"Model A\\\":92.86}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "8583H-9JTAY-4FH7G_56-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Printer Sales",
            "id": 57,
            "narration": "This classifier was trained on a close-to-balanced dataset and it attains an accuracy of 86.67%; a very high AUC score of 94.03; a Precision score of 83.78, and finally, an F2-score of 87.57%. According to the scores as mentioned, we can see that this model has a high classification performance and as such will be quite good at accurately differentiating between examples from both class labels under consideration.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":94.03},\\\"Precision\\\":{\\\"Model A\\\":83.78},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"F2-score\\\":{\\\"Model A\\\":87.57}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "RWJPN-TUCYN-JK80V_57-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"AUC\":\"5\",\"F2-score\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, AUC and F2-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 58,
            "narration": "From the metrics table shown, the model attains an accuracy of 67.09%, a marginal or low Specificity of 56.02%; recall score of 82.92% with an F1-score of just 67.47%. The model in general demonstrates a somewhat moderate performance. Besides, scores across the metrics show that it might fail at classifying some examples that are likely difficult to distinguish. Overall, from the F1-scoreand recall scores, we can draw the conclusion that it might have a close to high false positive rate.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "JN@96-EXNET-4JV8W-58-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Specificity\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 59,
            "narration": "When trained to assign the class label (either C1 or C2) to different test cases, the machine learning model's predictive power is characterized by scores across the metrics: precision, accuracy, recall, and F1-score. For the precision metric, it achieved, 91.06%. 91.48% for the recall score with 91.26% as the F1-score. Finally, it has an accuracy of about 91.37%. As shown by the scores, the model has a very high classification performance and as such can be trusted to make valid and correct predictions even for samples that might be difficult to sort out. In summary, the model is shown to be effective and there is a lower chance of misclassification error occurring (i.e. about <acc_diff>%).",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":91.26},\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"Precision\\\":{\\\"Model A\\\":91.06},\\\"Recall\\\":{\\\"Model A\\\":91.48}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "5E1QH-CKT87-M4R81_59-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Real Estate Investment",
            "id": 60,
            "narration": "Evaluated based on the Accuracy, AUC, Precision, and Recall metrics, the model achieved 85.78 (accuracy), 91.96 (AUC), 46.43 (precision), and 92.86 (recall). Since it was trained on an imbalanced dataset, the metrics of greater interest will be precision and recall. The low precision and very high recall score indicate that a lot of cases were labeled as C2. While some of them were true, a lot of them were also from C1.  In conclusion, from these scores, we can draw the conclusion that this model has  moderate performance with a somewhat high false-positive rate given that some examples of the majority class C1 are being misclassified as C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"Accuracy\\\":{\\\"Model A\\\":85.78},\\\"Precision\\\":{\\\"Model A\\\":46.43},\\\"AUC\\\":{\\\"Model A\\\":91.96}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "WHAMV-DUCX6-4QGDL-60-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Precision\":\"2\",\"Recall\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 61,
            "narration": "As shown in the metrics table, the model achieved a classification accuracy of 77.12%, recall, and precision scores, respectively, equal to 43.86, and 64.1. This model has low classification performance considering the precision and recall scores. This indicates that it would likely have many examples from the C2 class misclassified as C1. Therefore, it is not very effective for this machine learning problem.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":43.86},\\\"Recall\\\":{\\\"Model A\\\":64.1},\\\"Accuracy\\\":{\\\"Model A\\\":77.12}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "W2CAG-FDLWM-R0JRM-61-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"2\",\"Recall\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 62,
            "narration": "The evaluation metrics employed are AUC, precision, F1-score, and Accuracy. On the AUC, it has a score of 90.02% with accuracy also equal to 85.09%. This model has a moderate F1-score and a precision score of 65.31% and 61.47%, respectively. Only the precision score and F1-score are important to assess the performance of the model. This is because the data was imbalanced. Based on these metrics, we can make the assessment that this model demonstrates moderate classification performance and will likely misclassify a small number of examples drawn from the positive class C2 as C1. However, a balanced precision and recall score is a good indicator of how effective the model could be.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":65.31},\\\"Precision\\\":{\\\"Model A\\\":61.47},\\\"AUC\\\":{\\\"Model A\\\":90.02},\\\"Accuracy\\\":{\\\"Model A\\\":85.09}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "NQG8K-H7YFQ-FLBLH-62-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"F1-score\":\"3\",\"Accuracy\":\"4\",\"AUC\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 63,
            "narration": "On this machine learning classification problem, the model scored an accuracy of 95.9%, a recall and precision scores of 76.19% and 91.43%, respectively. Since the data is imbalanced, the best indicator of the performance of the model on this classification problem is the F1-score which is derived from precision and recall. We can verify that the model has a high F1-score of about 83.12%. According to the F1-score, the model is shown to be effective as there is little chance of cases belonging to class label C1 being classified as C2 (i.e., low false-positive rate). The model is sure about the correctness or preciseness of its prediction decisions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":95.9},\\\"F1-score\\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":91.43}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"5\",\"Recall\":\"3\",\"Precision\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 64,
            "narration": "For this classification problem, the ML model has an AUC score of about 89.13%, with an accuracy of 89.74%. However, the metrics of higher interest for this problem are the sensitivity (or the recall) and the precision scores. For these metrics, the model achieved 65.22% (precision) and 78.95% (sensitivity).  As a model trained on an imbalanced dataset, it performed moderately well at classifying examples/samples from both class labels. There is some sort of a fair balance between its recall (sensitivity)  and precision which indicates how good the model could be.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.13},\\\"Accuracy\\\":{\\\"Model A\\\":89.74},\\\"Precision\\\":{\\\"Model A\\\":65.22},\\\"Sensitivity\\\":{\\\"Model A\\\":78.95}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "WP0XW-UW7C1-210RB-64-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Sensitivity and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 65,
            "narration": "The values in the table summarize the prediction performance the model achieved based on the scores across the different evaluation metrics. It has almost perfect scores across all the metrics. The accuracy is 95.19%, specificity of 97.53%, AUC score of 98.4% and sensitivity score of 91.99%. According to the scores achieved, it would be safe to conclude that this model is highly effective at correctly assigning the correct class labels to test cases with little room for misclassification. Actually, from the accuracy the misclassification error rate is only <acc_diff>%.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.19},\\\"Specificity\\\":{\\\"Model A\\\":97.53},\\\"Sensitivity\\\":{\\\"Model A\\\":91.99},\\\"AUC\\\":{\\\"Model A\\\":98.4}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "8P5C3-Q03X1-H8CRK_65-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Specificity and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 98.4 and Accuracy of 95.19. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Air Quality Prediction",
            "id": 66,
            "narration": "Evaluated based on the recall, F1-score, accuracy, and precision, the model achieved 77.42% (recall), 86.64% (F1-score), 86.5% (accuracy), and 98.36% (precision). The very high precision and fairly high recall score demonstrate that the model is quite confident about the prediction of the C2 class. From these scores, we can conclude that the model demonstrates a high classification ability and will be able to correctly classify most of the samples belonging to each class label under consideration.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.42},\\\"F1-score\\\":{\\\"Model A\\\":86.64},\\\"Accuracy\\\":{\\\"Model A\\\":86.5},\\\"Precision\\\":{\\\"Model A\\\":98.36}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "2Q88Y-UJPDF-EYHMV_66-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, F1-score, Accuracy and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 98.36 and Recall of 77.42. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 67,
            "narration": "The classification algorithm achieves 78.87% as the precision score, accuracy of 75.74%, and recall of 75.68%. Looking at the difference between recall and precision, we can draw the assertion that this model is quite confident about the C2 predictions. From these scores, we say that this model is fairly accurate and would be able to correctly predict the true label for test cases from the class labels C1 and C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":75.74},\\\"Recall\\\":{\\\"Model A\\\":75.68},\\\"Precision\\\":{\\\"Model A\\\":78.87}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "4N3LG-KK5HE-A4W1D_67-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 68,
            "narration": "From the table, we can see that the model is characterized by the AUC and accuracy scores of 74.17% and 71.6%, respectively. As for the precision and sensitivity (recall) scores, the model only manages the scores of 50.63% and 55.56%.  Judging based on these scores, the model shows relatively poor classification performance. It will marginally outperform the dummy model that predicts only the majority class label C1 for all test cases. In summary, the performance of the model is not impressive and as such can't be really trusted to always make correct classification predictions.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":50.63},\\\"Accuracy\\\":{\\\"Model A\\\":71.6},\\\"Sensitivity\\\":{\\\"Model A\\\":55.56},\\\"AUC\\\":{\\\"Model A\\\":74.17}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "Y3J5V-6M@EF-EGT4F_68-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 69,
            "narration": "The learning algorithm trained on this ML task under consideration achieves the classification performance of 89.57% (recall or sensitivity), 89.42% (Precision-score), and 89.4% (accuracy). The high precision and recall scores demonstrate that the model is fairly picky with its C2 predictions but very certain when it does label cases as C2. In summary, e can see that this model has high prediction confidence and can correctly predict the true label for the majority of test cases/samples.",
            "metrics_values": "\"{\\\"Precision-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":89.4},\\\"Recall-score\\\":{\\\"Model A\\\":89.57}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "3DT9X-UA4TB-QQMUW-69-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision-score\":\"5\",\"Accuracy\":\"5\",\"Recall-score\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Water Quality Classification",
            "id": 70,
            "narration": "From the table shown, the model is shown to achieve 76.21% (Specificity), 63.72% (F1-score), and 81.25% (Sensitivity or Recall). In addition, it has an accuracy of  77.44%. The performance of the model in terms of splitting apart examples belonging to class label C2 is relatively moderate as shown by the F1-score and the Sensitivity. For the identification of C1's test sample, it does quite well as shown by the Specificity score. The above assertions are made based on the fact that the model was trained on an imbalanced dataset where the majority of examples belonged to the class label C1.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":77.44}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "MM3R7-D0LDT-XJ7X2_70-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Specificity and Sensitivity. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 71,
            "narration": "The classification algorithm employed to solve this machine learning task attains the scores 59.06% (sensitivity or recall), 94.96% (Specificity), 84.98% (AUC score), and 71.52% (Accuracy). Based on the sensitivity and Specificity scores, it is obvious that this algorithm will be effective in terms of correctly telling-apart examples belonging to class label C1 and might struggle a bit when classifying examples under the class label C2. The Specificity also shows that the classifier's accuracy is dominated by the correct predictions of the C1's samples.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":84.98},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Specificity\\\":{\\\"Model A\\\":94.96}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "JPLPR-AT2KK-1WJ3V_71-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"3\",\"AUC\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Sensitivity, AUC and Specificity. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 72,
            "narration": "On the ML classification task under consideration, the evaluation scores of the learning algorithm are as follows: 78.89% for the F1-score, 89.95% for the precision score metric; a specificity of 91.24%, and an accuracy of 80.17%. With the model trained on a heavily imbalanced dataset, the F1-score, specificity, and precision scores are the best assessors of the classification performance of the model. The specificity score shows that this model can relatively pick out examples from C1 from the population with a much higher degree of certainty. The precision score and F1-score also tell us that this model is somewhat confident about its predictions for test cases belonging to the class label C2.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":91.24},\\\"Accuracy\\\":{\\\"Model A\\\":80.17},\\\"F1-score\\\":{\\\"Model A\\\":78.89},\\\"Precision\\\":{\\\"Model A\\\":89.95}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "GTN7L-G9WW7-VK@P9_72-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"5\",\"Specificity\":\"5\",\"Accuracy\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Specificity and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 89.95 and Accuracy of 80.17. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 73,
            "narration": "With reference to the classification problem's objective, the classifier achieved an accuracy of 93.04%, a recall score of 81.85%, and a very low precision score of 23.69%.  Since the dataset used to train the model was imbalanced, we are only interested in the precision and recall scores. Based on these metrics' scores, the model is shown to have a very high false-positive and as such the confidence in the output prediction of the class label, C2 is very low. On the other hand, there is high confidence pertaining to the prediction output of the majority class label C1.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":23.69},\\\"Accuracy\\\":{\\\"Model A\\\":93.04},\\\"Recall\\\":{\\\"Model A\\\":81.85}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "68Q36-J5XWC-EYL22-73-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 74,
            "narration": "This classifier achieves almost perfect scores for the Recall (93.76%),  and AUC (95.96%). Besides, for the precision and accuracy scores, the model attains 83.1%, and 88.89%, respectively. Considering all the scores mentioned above, the model is shown to have relatively high confidence in the prediction decisions for the majority of test cases. It has a low false-positive rate.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.89},\\\"Precision\\\":{\\\"Model A\\\":83.1},\\\"AUC\\\":{\\\"Model A\\\":95.96},\\\"Recall\\\":{\\\"Model A\\\":93.76}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "2G3WD-T10LW-9C4YD_74-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\",\"AUC\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and AUC. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 75,
            "narration": "Looking at the results table, the model achieved accuracy and AUC scores of 95.84% and 98.01%, respectively. In addition, the precision score and recall (sensitivity) scores respectively are 87.1% and 93.9%. Trained on an imbalanced dataset, the results are quite impressive. The precision and recall scores indicate the model will likely have a high F1-score demonstrating its effectiveness at correctly predicting the class labels for the majority of the test cases. It has high confidence in its prediction outputs.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Precision\\\":{\\\"Model A\\\":87.1},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Recall\\\":{\\\"Model A\\\":93.9}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "91QCH-3A85T-FNENX-75-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 76,
            "narration": "The algorithm trained on this imbalanced dataset achieved a sensitivity (recall) score of 80.01% with a precision score equal to 86.96%. Besides, it has an AUC score of 94.73% and an accuracy score of 93.16%.  The model has a fairly high prediction performance as indicated by the recall (sensitivity) and precision scores. Basically, the model has a lower false-positive rate. Furthermore, if we were to go by the accuracy and AUC scores, we can say it will have a lower chance of misclassifying most test samples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":86.96},\\\"AUC\\\":{\\\"Model A\\\":94.73},\\\"Sensitivity\\\":{\\\"Model A\\\":80.01},\\\"Accuracy\\\":{\\\"Model A\\\":93.16}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "JCJNF-MQA@Y-RPXJ1_76-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Sensitivity\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Sensitivity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Cab Surge Pricing System",
            "id": 77,
            "narration": "On this multi-class classification problem, the model has a recall score of 85.82%, an accuracy score of about 82.24%, and a precision score of 87.11%. From the recall and precision, the F1-score achieved by the model is about 86.46%. From these scores, a valid conclusion that could be made here is that this model has a moderate to high performance and can correctly identify the true label for most test samples drawn from the different classes: C1, C2, and C3.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.46},\\\"Precision\\\":{\\\"Model A\\\":87.11},\\\"Accuracy\\\":{\\\"Model A\\\":82.24},\\\"Recall\\\":{\\\"Model A\\\":85.82}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
            "redeem_code": "W5G1E-7CHWU-1DWB5-77-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Accuracy, F1-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, F1-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 78,
            "narration": "Evaluation of the classification performance is based on the following evaluation metrics:  F1-score, Recall, Precision, and Accuracy. For the accuracy, the model scored 96.53%, for the precision it scored 91.43% with the recall score equal to 80.03%. According to the recall and precision scores, we can verify that it has an F1-score of about 85.33%.\n Trained on a severely imbalanced dataset, these scores are quite impressive. It has a lower false-positive rate hence the confidence in predictions related to the minority class label C2, is very high. The above conclusion is based on the precision and recall scores. The accuracy though might not be that important when dealing with such imbalanced data offer some form of support to the claims about the confidence level of the model's output predictions.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":80.03},\\\"F1-score\\\":{\\\"Model A\\\":85.33},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":96.53}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "LVLQW-HA20W-DX54K-78-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 79,
            "narration": "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, the accuracy score is 87.74% and the precision score is 79.22%. The model does fairly well at correctly classifying most test cases. As indicated by the precision and recall scores, it should be noted that this model has a tendency of labeling some cases belonging to C1 as C2. In summary, the algorithm has moderately high confidence in its prediction decisions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Recall\\\":{\\\"Model A\\\":95.31},\\\"AUC\\\":{\\\"Model A\\\":96.34}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "H3HGT-CJFAF-ETP8L_79-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 80,
            "narration": "The classifier scored close to perfect scores across all the metrics (i.e. Precision, AUC, Accuracy and Recall). From the results table, we can see that it scored 94.06% (Precision), 99.42% (AUC), 97.11% (accuracy), and 95.96% (sensitivity/recall). Surprisingly, these scores were achieved even though the dataset was imbalanced.  From the precision and recall scores, we can assert that the learning algorithm is very confident about its prediction decisions for samples belonging to the class label C2. Finally, the accuracy and AUC show that it has a lower misclassification error.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":94.06},\\\"Accuracy\\\":{\\\"Model A\\\":97.11},\\\"Recall\\\":{\\\"Model A\\\":95.96},\\\"AUC\\\":{\\\"Model A\\\":99.42}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "PK731-LG4HB-CRN93_80-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 99.42 and Accuracy of 97.11. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 81,
            "narration": "The machine learning algorithm trained to solve this classification problem achieved a score of 84.38% for the accuracy, a score of 90.03% (AUC),  82.27% (Precision) and 81.8% (recall). Judging from these scores, the algorithm is shown to be quite effective at correctly choosing the true labels for most test cases. There is a balance between the recall and precision scores hence the confidence in predictions related to the label C2 is high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":82.27},\\\"Accuracy\\\":{\\\"Model A\\\":84.38},\\\"AUC\\\":{\\\"Model A\\\":90.03},\\\"Recall\\\":{\\\"Model A\\\":81.8}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "7H98A-F4TUL-MR5WP-81-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"AUC\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Accuracy, Precision and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and AUC. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 82,
            "narration": "The scores achieved by the model on this classification problem are: (1) accuracy equal to  67.09%. (2) Specificity score of 56.02%. (3) recall (sensitivity) score of 82.92%. (4) F1-score of 67.47%. The model was trained on an imbalanced dataset, therefore, these results indicate the it has a weak prediction power. From the recall and F1-score, we can make the conclusion that this model will have a low precision hence will have a somewhat high false-positive rate. Therefore, it will fail in most cases to correctly identify the examples belonging to the class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "12/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "WBBV0-6LQXX-RHK19-82-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"3\",\"Recall\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 83,
            "narration": "For this classification problem, the model scored 55.56% precision with a moderate F1-score of 60.87%. Besides, it has an accuracy of about 66.91%. Based on the scores above, the model is relatively unreliable in terms of its predictions. Furthermore from the precision score, it is valid to say the model will have a high false positive rate.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":55.56},\\\"Accuracy\\\":{\\\"Model A\\\":66.91}}\"",
            "deleted": false,
            "date_submitted": "13/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "AF0DK-KVV7A-P7F3F-83-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, F1-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 66.91 and F1-score of 60.87. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Paris House Classification",
            "id": 84,
            "narration": "Given the table above, we can confirm that the model scored: 83.12% for the recall metric, 69.15% precision score, and an accuracy score of 91.56%. From the recall and precision scores, the model has a fairly high F1-score of 75.49%. The model is fairly confident with its predictions with the samples from the minority class label C2 as indicated by the F1-score. Since the dataset is severely imbalanced, the accuracy score is less significant when judging the classification performance of the model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.56},\\\"Recall\\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":69.15},\\\"F1-score\\\":{\\\"Model A\\\":75.49}}\"",
            "deleted": false,
            "date_submitted": "13/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "QW3LB-DJ51K-F52V7_84-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 85,
            "narration": "This model scored 88.89% on accuracy metric, almost perfect  Specificity score of 92.61%. In addition, the precision and F1-scores are 89.95%, and 86.96%, respectively. The accuracy score is not important metric for this analysis since the data is quite imbalanced.  Therefore based on the Specificity, precision and F1-score, we can argue that this model will be quite effective in terms of its prediction power for the minority class C2 and the majority class C1.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"Accuracy\\\":{\\\"Model A\\\":88.89}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "3APUV-AXY5G-18Q7M_85-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"F1-score\":\"5\",\"Precision\":\"5\",\"Specificity\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 86,
            "narration": "For this classification problem, the model scored 91.09% AUC, 74.19% Accuracy, 53.25% precision and the recall of 91.11%. The dataset is pretty balance as such all the metrics here can be used to make valid conclusions about it's classification performance on this ML task. From the precision and recall scores, we can say that this model has a moderate performance will likely make some classification errors in relation to correctly sorting or separating the test cases belonging to the label C2. This assertion or conclusion is supported by the values of the AUC and accuracy.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":53.25},\\\"AUC\\\":{\\\"Model A\\\":91.09},\\\"Accuracy\\\":{\\\"Model A\\\":74.19},\\\"Recall\\\":{\\\"Model A\\\":91.11}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "5DPK5-@LC@T-5YANM-86-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"3\",\"Accuracy\":\"3\",\"Recall\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 87,
            "narration": "In the case of this classification task, the model has the scores: Accuracy (77.66%), precision (42.12%), recall (57.09%) and 48.48% (F1-score). With the model trained on an imbalance dataset, the accuracy can be ignored when deciding if the model is effective or  not. As shown by the scores across the F1-score, Precision and Recall, this model performs quite poorly in terms of predictions related to the class label C2. From the precision and recall, we can see that the false positive is higher than the true positive predictions. Even though the accuracy might not be important here, we can also conclude that this model is not different from the dummy model that keeps assigning the same class label, C1, to any given input. That is there is marginal difference between the accuracy of this model and that of the dummy model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":42.12},\\\"Recall\\\":{\\\"Model A\\\":57.09},\\\"F1-score\\\":{\\\"Model A\\\":48.48},\\\"Accuracy\\\":{\\\"Model A\\\":77.66}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "8B91Q-MH7DL-W06V0-87-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\",\"Recall\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 88,
            "narration": "On this ML classification task, the model boasts a high accuracy score of 81.5%, a low precision score of 45.61% with a recall score of 81.25%. This model was trained on an imbalance dataset so decisions on the effectiveness of the model should be made based on the recall (sensitivity) and precision. From the scores across these metrics, we can make the conclusion that the model will not be that good at correctly predicting the true labels for a greater number of samples belonging to label C2. Besides, the model marginally outperforms the dummy model that constantly assigns the majority class label (C1) to all given input test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":81.25}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "R0@26-@FTMC-EN9A8-88-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 45.61 and Accuracy of 81.5. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Real Estate Investment",
            "id": 89,
            "narration": "With the model trained on a severely imbalanced dataset, it scored the following scores across the metrics Accuracy, Recall, Precision,  and AUC, respectively, 85.78%, 92.86%, 46.43%, and 91.96%. By just looking at the precision and recall scores, this model has a high false-positive rate hence low confidence in the predictions associated with the minority label, C2. On the other hand, It performs quite well as it can correctly choose the true label for the majority of samples related to C1.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":46.43},\\\"AUC\\\":{\\\"Model A\\\":91.96},\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"Accuracy\\\":{\\\"Model A\\\":85.78}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "C7KA7-BKH5E-Q8JB4_89-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\",\"AUC\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 46.43 and Recall of 92.86. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 90,
            "narration": "The dataset used to train the model was imbalanced with a larger proportion belonging to the class label C1. Therefore, C2 is the minority class here and it happens to be the positive label. Evaluating the model based on the different metrics produced the scores 74.17% (AUC), 55.56% (sensitivity), 50.63% (precision) and 71.6% (accuracy).  From the accuracy and AUC scores, we can see that this model doesn't significantly outperform the dummy classifier (which assigns the label C1 to any given input). The model seems to performs poorly on predictions related to the label C2. In summary, this modelis not as effective as desired and is likely to have low confidence in its prediction decisions.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":55.56},\\\"AUC\\\":{\\\"Model A\\\":74.17},\\\"Precision\\\":{\\\"Model A\\\":50.63},\\\"Accuracy\\\":{\\\"Model A\\\":71.6}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "XU2TE-HKXPR-X9RAK-90-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"3\",\"AUC\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC, Accuracy and Sensitivity? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 91,
            "narration": "According to the metrics table, this model scored 77.15% (F1-score), 91.96% (recall), 96.29% (accuracy) and finally, a moderate precision of 66.45% on this machine learning problem under consideration here.  Not much information is given about the distribution of the dataset across the two class labels however, judging by the values, the model is shown to be fairly accurate with its prediction decisions for the majority of test cases. However, caution should be taken when dealing with prediction outputs related to the class label C2. This is due to the score achieved for the precision evaluation metric.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"Accuracy\\\":{\\\"Model A\\\":96.29},\\\"Precision\\\":{\\\"Model A\\\":66.45},\\\"F1-score\\\":{\\\"Model A\\\":77.15}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "N@LRQ-V33DP-19MDB_91-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"3\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 92,
            "narration": "The learning algorithm explored here has high accuracy (93.04%) and recall (81.85%) scores, However, it scored poorly in terms of its precision (23.69%). These scores were achieved on an imbalanced dataset. This implies that the model has a very low confidence in terms of its C2 predictions. This is based on the precision and recall (also known as sensitivity) score achieved.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":81.85},\\\"Accuracy\\\":{\\\"Model A\\\":93.04},\\\"Precision\\\":{\\\"Model A\\\":23.69}}\"",
            "deleted": false,
            "date_submitted": "14/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "M@R8U-71VBP-KWJML-92-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.120.217.114",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Air Quality Prediction",
            "id": 93,
            "narration": "Trained to assign one of the labels (C1, C2, C3, and C4) to any given input example, the model achieved precision, recall,  F1-score, and accuracy metric scores of 97.96%, 96.95%, 97.32%, and  97.54%, respectively. As shown above, the model achieved almost perfect scores across the different evaluation metrics. This demonstrates that this model will be very effective at correctly outputing the true label for any given input test case.  The confidence of its prediction decision is very high.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.54},\\\"Recall\\\":{\\\"Model A\\\":96.95},\\\"F1-score\\\":{\\\"Model A\\\":97.32},\\\"Precision\\\":{\\\"Model A\\\":97.69}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
            "redeem_code": "TUB0K-C0KM4-QEV3G-93-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-5",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 94,
            "narration": "Trained to classify any given input as either C1 or C2, this model has an accuracy of 74.26%, precision score and recall score of 73.71% and 76.21%, respectively. The classification performance of the model is fairly high with a clear balance between the precision and recall scores. The model is relatively confident about its prediction decisions for example cases related to class label C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71},\\\"Recall\\\":{\\\"Model A\\\":76.21}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "M7TKQ-Q9KX2-E9AFB_94-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 95,
            "narration": "Under this classification problem, the model was evaluated based on its scores across the following metrics: Accuracy, Recall, F2-score and Precision. With respective to the accuracy, the model scored 80.23%. For the precision and recall (sometimes referred to as the sensitivity score), the model scored 76.77%, 74.53%. The F2-score computed based on the recall and precision scores is equal to 74.57%. The model performs fairly well in terms of correctly predicting the true label for test cases related to any of the class labels under consideration. In summary, we can be assured that this model will be able to assign the correct label to the majority of the test examples.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "RTUJ1-JBLJR-EH6C4-95-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Recall and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 96,
            "narration": "Across the following metrics: F1-score, specificity, accuracy and precision, the model scored 57.94%, 70.46%, 60.78%, and 65.61%, respectively. Trained on an imbalanced dataset, the scores achieved by the model are not that impressive. Considering the accuracy score, this model performed poorly compared to the dummy model that keeps assigning the majority class label C1 to any given test case. However, due to the distribution of the data across the two class labels, the F1-score and precision metrics are more suitable for the analysis. Finally, the model has a moderate confidence regarding the C2 prediction decision for the test samples.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":57.94},\\\"Precision\\\":{\\\"Model A\\\":65.61},\\\"Specificity\\\":{\\\"Model A\\\":70.46},\\\"Accuracy\\\":{\\\"Model A\\\":60.78}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "0KUNK-4QRGH-44K9M-96-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Specificity\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"3\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Specificity, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Specificity, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 97,
            "narration": "Evaluated based on the metrics Recall, Precision, Accuracy and F1-score, the model achieved the scores  94.12%, 91.43%, 98.42% and 92.75%, respectively on this classification problem. Relatively, the classification performance of the model is very high. This implies that for the majority of test cases, the confidence in the final prediction decision will be very high irrespective of the output class label.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "QJ48F-2T7X5-AQ0KC-97-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 98,
            "narration": "The ML algorithm was trained on this task to predict the class labels C1 and C2. The evaluation metrics employed to assess its classification power were  Recall, Accuracy, Precision and AUC. With the accuracy and AUC scores of  95.58, and 98.04, respectively, it scored 92.16% (for the recall/sensitivity) and  87.78% (precision). Since the dataset was imbalanced, it will be wise to analyze the performance based on the balance between the Recall and precision. The recall and precision are both high hence we can conclude that the learning algorithm has a lower false positive rate, hence, the prediction of the class label C2 for any given test example is likely to be correct. Basically, we can trust the model to a certain degree to make the best prediction decision for the majority of test samples.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.16},\\\"Accuracy\\\":{\\\"Model A\\\":95.58},\\\"AUC\\\":{\\\"Model A\\\":98.04},\\\"Precision\\\":{\\\"Model A\\\":87.78}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "2JQ1J-TJQAL-DYGW6_98-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 100,
            "narration": "The learning algorithm's  recall score is 56.22%, precision score is 35.29%, and accuracy score of 77.0% on this classification task. The F1-score derived from the precision and recall is just 43.36%. From the distribution of the dataset between the two class labels (C1 and C2), we can verify that this algorithm's performance will be identical to the random classifier that always assigns the class label C1 to any given test case. The model has a very low precision and recall scores hence will fail to correctly classify the majority of the cases belonging to the minority label C2. This assertion is further supported by the trade-off score, F1-score.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":35.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":56.22},\\\"F1-score\\\":{\\\"Model A\\\":43.36}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "10A60-N8DAW-QB0HF-100-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\",\"F1-score\":\"2\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Insurance Churn",
            "id": 101,
            "narration": "When trained on the given imbalanced dataset, the model has the scores 34.14%, 92.22%, 66.92%, and 90.46% across the metrics Precision, AUC, Recall and Accuracy, respectively. The precision and recall scores show how poor the performance of the model at correctly assigning C2 is. The model has high false positive rate hence the prediction confidence rated to the minority class label C2 is low. Even with the high accuracy and AUC scores, this model can't be trust when it comes to the test cases belonging to C2.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":34.14},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"Accuracy\\\":{\\\"Model A\\\":90.46}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "MJF2R-9QC89-AV7KM_101-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Tic-Tac-Toe Strategy",
            "id": 102,
            "narration": "Evaluated on the metrics AUC, accuracy, precision, and F1-score, the classification algorithm achieved close to perfect scores 99.83%, 98.61%, 95.92%, and 97.92%, respectively, on the given ML task. The high values across these metrics indicate that this model can effectively and correctly identify the true labels for the majority of the test cases and the confidence-level in its predictions is very high.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":97.92},\\\"AUC\\\":{\\\"Model A\\\":99.83},\\\"Precision\\\":{\\\"Model A\\\":95.92},\\\"Accuracy\\\":{\\\"Model A\\\":98.61}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "7EN31-0RN@5-HHU7F_102-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Precision, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 103,
            "narration": "The model trained on this ML task scored 91.11%,  84.78%, 84.91%, and 77.59%, respectively, across the metrics AUC, Accuracy, Precision, and Recall. The training dataset was fairly balanced between the two class labels C1 and C2. From these scores, we can conclude that the learning algorithm employed to solve the ML task is very effective and confident with the majority of its prediction decisions. ",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"Accuracy\\\":{\\\"Model A\\\":84.78},\\\"AUC\\\":{\\\"Model A\\\":91.11}}\"",
            "deleted": false,
            "date_submitted": "15/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and Precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "185.201.60.254",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Wine Quality Prediction",
            "id": 104,
            "narration": "The classification performance on this ML task as evaluated based on the Precision, Accuracy and Recall are 73.71%, 74.26%, and 76.21%, respectively. These scores are high indicating that this model is somewhat effective and  can accurately identify most of the test cases with small margin of error.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "8V93K-VY676-5J20J_104-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 105,
            "narration": "On the machine learning problem under consideration, the model scored 90.32% (precision), 94.6% (F1-score), 99.29% (recall) and 99.03% (Accuracy). These scores are very high. Based on the above performance scores, we can conclude that the model is very effective and can accurately distinguish the majority of the test samples with a small margin of misclassification error. Besides, \nthe precision and recall scores, it is obvious that the model has a very low false positive rate hence is very confident about its prediction decisions.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.03},\\\"Precision\\\":{\\\"Model A\\\":90.32},\\\"F1-score\\\":{\\\"Model A\\\":94.6},\\\"Recall\\\":{\\\"Model A\\\":99.29}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "NLYKP-HQY57-K772A_105-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 106,
            "narration": "With a larger proportion of the dataset belonging to the label C1, the model evaluated based on the following metrics precision, F1-score, accuracy and recall, respectively, achieved 63.37%, 73.56%, 99.92%, and 87.67%. According to the scores, one can conclude that the performance of the model is not impressive. The accuracy score indicates this model is not that different from the dummy model that always assigns the same label (C1) to any given input example. However, only the precision, recall and F1-score are important here for this assessment. From these scores, we can conclude that this model has a moderate false positive rate and the prediction output of C2 might need further investigation.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":73.56},\\\"Precision\\\":{\\\"Model A\\\":63.37},\\\"Accuracy\\\":{\\\"Model A\\\":99.92},\\\"Recall\\\":{\\\"Model A\\\":87.67}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "R632M-@BR@0-QWQQ0_106-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Recall\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, F1-score, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 63.37 and Recall of 87.67. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 107,
            "narration": "The performance of the classifier/model on this binary classification task was assessed based on the Precision, AUC, F1-score and Accuracy scores.  The accuracy score is  85.11% and  90.07% for the AUC  metric. Furthermore, the precision and F1-score are 63.95% and 66.23%, respectively. From the  F1-score, we can estimate that the recall score will be identical to the precision score. Therefore saying the model has a low false positive classification is a valid statement. Overall, we can conclude that this model achieved a moderate performance hence can accurately classify a decent number of test cases.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"Accuracy\\\":{\\\"Model A\\\":85.11}}\"",
            "deleted": false,
            "date_submitted": "16/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "@6Q1G-9P3P4-QFPND_107-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"4\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, AUC, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 109,
            "narration": "The performance of the model on this classification problem as evaluated based on F1-score, Accuracy, and Precision scored: 66.18%, 60.32% and 62.3%, respectively. A valid conclusion is: the model has a moderate classification performance hence is likely to misclassify a significant number of test cases.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":62.3},\\\"Accuracy\\\":{\\\"Model A\\\":66.18}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 110,
            "narration": "The classification performance of the ML algorithm explored on this ML task can be summarized as: recall (81.25%), low precision (45.61%), and accuracy (81.5%). Since the dataset is imbalanced, we can conclude that the model has moderately low classification performance as the difference between the recall and precision indicates there is a high false positive rate. Hence predictions output of label C2 should be taken with a grain of salt.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Recall\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WN6X6-PL20R-937TG-110-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"2\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 111,
            "narration": "The classifier or algorithm attains very high scores across all the metrics under consideration. Specifically, the recall score of 94.12%, the accuracy score is 98.42%, precision score of 91.43% and F1-score of 92.75%. Judging by these scores attained, it is fair to conclude that this model can accurately distinguish several test cases with little  misclassification error. Besides, the F1-score indicates the model's classification confidence of output predictions related to label C2 is very high.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "J@PN2-LPKE4-NMUMQ_111-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 112,
            "narration": "On this ML problem, the model's performance was evaluated as accuracy (83.56%), precision (45.23%), sensitivity score (76.63%) and 56.89% for the F1-score. The model's prediction performance according to the scores above can be summarized as moderately low (weak) given the difference between the precision, and recall scores.  There is a high false positive rate as a number of samples belonging to class C1 are likely to be misclassified as C2.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.63},\\\"Accuracy\\\":{\\\"Model A\\\":83.56},\\\"Precision\\\":{\\\"Model A\\\":45.23},\\\"F1-score\\\":{\\\"Model A\\\":56.89}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"2\",\"F1-score\":\"3\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 113,
            "narration": "Evaluated based on the accuracy, recall, precision and AUC, the ML algorithm scored 92.78%, 81.15%,  98.02%, and 96.38%, respectively on this classification problem where a given input sample is classified under either class C1 or class C2. These results/scores are very impressive based the fact that the dataset was imbalanced. With such high scores for precision and recall, the classification performance of this model can be summarized simply as almost perfect as only a small number of samples are likely to be misclassified. This is a very model with high confidence in its prediction decisions related to the two-class labels under consideration.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":98.02},\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":81.15},\\\"AUC\\\":{\\\"Model A\\\":96.38}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "H@PTU-6AXJA-Q9Q5R_113-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Airline Passenger Satisfaction",
            "id": 114,
            "narration": "Trained on somewhat balanced dataset, the model scores 97.91% (AUC), 93.2% (accuracy), 93.12% (recall) and 91.26% (precision score). These results/scores are very impressive as one can conclude that this model is almost perfect with higher confidence in its prediction decisions. In summary, only a  small number of test cases are likely to be misclassified as indicated by the accuracy, recall and precision.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Precision\\\":{\\\"Model A\\\":91.26},\\\"Accuracy\\\":{\\\"Model A\\\":93.2},\\\"Recall\\\":{\\\"Model A\\\":93.12}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
            "redeem_code": "L3800-W0KMY-C14ET_114-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 93.2 and Recall of 93.12. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Attrition",
            "id": 115,
            "narration": "The evaluation scores achieved by the model on this ML classification problem as shown in the table are: accuracy (86.72%), recall (94.12%), AUC (85.39%) and precision (32.65%). On this imbalanced dataset classification problem, these scores are lower than expected indicating how poor the model is at correctly identifying the true class label for the majority of test cases related to label C2. The above conclusion is drawn by simply looking at the precision, recall and distribution of the data across the two class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.72},\\\"AUC\\\":{\\\"Model A\\\":85.39},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":32.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "MD6TR-AYUX6-@H3RX_115-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Recall\":\"4\",\"AUC\":\"3\",\"Precision\":\"1\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 86.72 and Recall of 94.12. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 115,
            "narration": "Accuracy equal to 86.72%, recall equal to 94.12%, AUC equal to 85.39% and very low precision equal to 32.65% are the evaluation scores achieved by the model on this ML classification problem as shown in the table. We can see that the model avoids false-negative predictions but sacrifices its ability to correctly identify the true label for the majority of test cases related to class C2. The above conclusion is drawn by simply looking at the precision, recall and distribution of the data across the two class labels.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.72},\\\"AUC\\\":{\\\"Model A\\\":85.39},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":32.65}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "MD6TR-AYUX6-@H3RX_115-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Recall\":\"4\",\"AUC\":\"3\",\"Precision\":\"1\"}",
            "model_name": "Model-3",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 86.72 and Recall of 94.12. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Broadband Sevice Signup",
            "id": 116,
            "narration": "On this imbalanced classification problem, this learning algorithm has an accuracy of  96.58%, a recall score, and a precision score equal to 96.78% and 95.72%, respectively. Judging by the scores achieved, we can conclude that this model has a very high classification performance and will be very effective at correctly predicting the labels for the majority of the test cases. This is because from the precision score of 96.78% with the recall score of 95.72%, the confidence in the predictions related to any of the class labels is very high.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":95.72},\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Accuracy\\\":{\\\"Model A\\\":96.58}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "Y7FKM-JE0EL-KY8G3-116-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 117,
            "narration": "On this classification with a balanced distribution of the data between the class labels, the model achieves high scores across the metrics under consideration. For example, the accuracy is 94.0% with the AUC score equal to 98.37%.  These scores show how good the model is when predicting the true label for the majority of the test cases related to any of the class labels. Furthermore, the high precision and recall scores of 89.61% and 98.57%, respectively, show that there is high confidence in predictions related to the label C2. In summary, there is a lower chance of misclassification.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":98.57},\\\"AUC\\\":{\\\"Model A\\\":98.37},\\\"Precision\\\":{\\\"Model A\\\":89.61},\\\"Accuracy\\\":{\\\"Model A\\\":94.0}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"5\",\"Accuracy\":\"5\"}",
            "model_name": "Model-1",
            "narrator": 45,
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 118,
            "narration": "In view of the classification objective under consideration, the model attains high scores across all the evaluation metrics. For the accuracy, it scored 96.0%, 95.98% for the precision-score and 96.08% recall-score.  It is fair to conclude that the classification performance/power of this model is very impressive and the chances of misclassifying any given input test case is very low.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
            "deleted": false,
            "date_submitted": "18/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
            "model_name": "Model-4",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Airline Passenger Satisfaction",
            "id": 120,
            "narration": "The algorithm employed to separate the test cases the distinct classes (C1 and C2) scores highly across all metrics; scoring 89.69% for Accuracy, 88.39% for Recall, 87.83% for Precision and 95.52% for AUC 89.59% accuracy implies that 89.59% of all predictions made were correct. An AUC of 95.52% means that the model is well balanced and is able to effectively tell-apart the observations under positive and negative classes.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.83},\\\"Recall\\\":{\\\"Model A\\\":88.39},\\\"AUC\\\":{\\\"Model A\\\":95.52},\\\"Accuracy\\\":{\\\"Model A\\\":89.59}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
            "redeem_code": "TQ5Y5-9MUQU-07D2B_120-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 89.59 and AUC of 95.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 121,
            "narration": "An accuracy of 96.0%, precision of 94.8%, recall of 97.33% and AUC of 98.59% was achieved. The model attained a very high performance across all the evaluation metrics. Its predictions can be treated as reliable.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Recall\\\":{\\\"Model A\\\":97.33},\\\"Precision\\\":{\\\"Model A\\\":94.8}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "99Q5J-CEDC7-QMV7K_121-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 122,
            "narration": "For the metrics Precision, Accuracy, F1-score and Specificity, the model scored 89.95%, 80.17%, 78.79% and 91.24% respectively. A very high precision and specificity indicate good performance in predicting the negative class, but a lower accuracy and F1-score indicate that the model was less able to predict the positive, minority class.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":78.89},\\\"Accuracy\\\":{\\\"Model A\\\":80.17},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Specificity\\\":{\\\"Model A\\\":91.24}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "BY7EL-9E79H-D5T1X_122-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"3\",\"F1-score\":\"4\",\"Specificity\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 123,
            "narration": "The algorithm achieved the following performance values or scores: Accuracy 87.27, AUC 92.32, Precision 67.18, F1-score of 70.68 on this classification task. Despite the high accuracy and AUC, the low precision shows that the model gets many false positives. This is not surprising given the dataset imbalance, with only <|minority_dist|> of the data belonging to class C2 (positive), yet it has to be taken into consideration when deploying the model.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":70.68},\\\"AUC\\\":{\\\"Model A\\\":92.32},\\\"Precision\\\":{\\\"Model A\\\":67.18},\\\"Accuracy\\\":{\\\"Model A\\\":87.27}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "4EPVC-WGABT-TNE89-123-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"AUC\":\"4\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, AUC and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 124,
            "narration": "The F1-score, accuracy and precision are 60.8%, 63.97% and 60.32%, respectively. The given F1-score and accuracy score is indicative of a model with fairly good signs of being accurate and precises in determining C1 and C2. However, the models only perform decently well, with still room for improvement, and with similar precision and accuracy scores suggesting a combined issue with the model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "RGKYV-ND62W-88LR8-124-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, F1-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 60.8 and Accuracy of 63.97. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 125,
            "narration": "An AUC of 88.67, accuracy of 82.7, recall of 77.52 and precision of 84.66 was achieved by the model. With all the metrics being of a similar value, the model performs evenly across the two categories. Nonetheless, the achieved scores are sub-optimal and more research is needed to improve the models performance.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"AUC\\\":{\\\"Model A\\\":88.67},\\\"Recall\\\":{\\\"Model A\\\":77.52}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "TE827-GEXW7-1X90P_125-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"3\",\"Recall\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 126,
            "narration": "This model did not perform well, with very low F1-score (56.5%) and precision (50.81%) and only marginally better recall (63.64%) and accuracy (71.04%). The F1-score of 56.5% is a good indicator of an overall non-effective performance from this model. A precision of only 50.81% shows that it has almost no ability to identify the positive class and a moderate accuracy is mostly down to the class imbalance.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Precision\\\":{\\\"Model A\\\":50.81},\\\"Recall\\\":{\\\"Model A\\\":63.64},\\\"F1-score\\\":{\\\"Model A\\\":56.5}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "B5DU9-75@TN-U8JTL-126-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"1\",\"Recall\":\"1\",\"Precision\":\"1\",\"Accuracy\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-6",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Recall, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Recall, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 127,
            "narration": "The machine learning algorithm employed to solve the task boasts an accuracy of 77.0%, yet its precision is only 43.86%, while the recall is 64.1%. Despite the moderately high accuracy of the model, its low precision and recall suggest that its prediction is not very trustworthy. This is most likely caused by the class imbalance, where the model gains a lot of its accuracy from being biased towards predicting negatives.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":64.1},\\\"Precision\\\":{\\\"Model A\\\":43.86},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "E1BNU-C9N3V-B8YY0_127-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"3\",\"Recall\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Flight Price-Range Classification",
            "id": 128,
            "narration": "The accuracy of the model is moderately high, with precision, recall, and F2-score following marginally behind however overall the model's performance can be considered favorably in classifying a large number of test samples.  The model has overall very good performance with achieving high F2-score indicating that as recall or accuracy is weighted more significantly, it is suggestive that the model is good at determining correct class labels most of the time. The precision of 76.77 is below the 80.23 of accuracy, albeit very close together, however suggesting the model is struggling to perform well on the precision metric and may provide an avenue for improvement.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
            "redeem_code": "4@61G-707H5-L5GCQ-128-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\",\"F2-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Recall, Accuracy and F2-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F2-score of 74.57 and Precision of 76.77. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 129,
            "narration": "The algorithm trained on this task was able to achieve 84.06% accuracy, 74.6% recall, 88.68% precision and 92.21% auc. The algoritm was fairly effective with an accuracy of 84.06% on this somewhat balanced dataset providing a good indicator of the overall prediction capability. Scoring 88.68% precision means that the false positive rate was only <preci_diff>.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.68},\\\"Accuracy\\\":{\\\"Model A\\\":84.06},\\\"AUC\\\":{\\\"Model A\\\":92.21},\\\"Recall\\\":{\\\"Model A\\\":74.6}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 130,
            "narration": "On this balanced dataset the model was a fairly good performer/classifier (Accuracy 79.8%, F1-score 77.06%) but was more effective at catching positive cases (recall 87.94%) than it was at avoiding false negatives (precision 68.58%). This model scored 79.8% accuracy which implies a moderately good performance overall, however when looking at the precision (68.58%) as well it implies that the model is not very effective at avoiding false negatives.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":77.06},\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Precision\\\":{\\\"Model A\\\":68.58}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "60Y44-0KFAL-V7VYR_130-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"F1-score\":\"3\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 131,
            "narration": "The classification algorithm has moderately high accuracy; however, precision is low, thereby suggesting a flaw in the model; this is apparent in an F1-score of 46.98. The model has fairly high accuracy with a good recall score; however, it has an overall low precision and therefore is an area that strongly requires improvement before deployment. The F1-score of 46.98 is apparent of this low precision score of 40.17, further providing evidence of the model's inability to provide labels that are precise, albeit highly accurate.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.38},\\\"Recall\\\":{\\\"Model A\\\":56.58},\\\"F1-score\\\":{\\\"Model A\\\":46.98},\\\"Precision\\\":{\\\"Model A\\\":40.17}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "WHN4F-V7A3N-8UWGM_131-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 132,
            "narration": "This model scored an AUC of 90.07%, a precision of 63.95%, an F1-score of 66.23%, and an accuracy of 85.11%. Considering this dataset is very imbalanced, a high accuracy of 85.11% and a high AUC of 90.07% is less impressive. An F1-score of 66.23%, which is similar to precision (63.95%), indicates an overall moderately low prediction performance from this model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.11},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "7Q3YE-NAQD3-225D7_132-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Precision\":\"2\",\"F1-score\":\"2\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, F1-score and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 85.11 and F1-score of 66.23. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 133,
            "narration": "On this classification task, the model was evaluated based on the Recall, accuracy, AUC and precision scores. Recall of 93.18% and a precision score 81.19  with an accuracy of 92.78%  suggest the model is less precise but it is more accurate. This assertion is supported by the AUC with 96.03, however, the model is good at analyzing the dataset for this classification task/problem.  The overall performance of the model is capturing the accuracy of the dataset is considered high at 92.78 however this value is decreased by the precision value of 81.19. This suggest that the model is accurately able to identify true positive cases however the reduction seen in precision suggest that it produces errors as a result of this.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":93.18},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"AUC\\\":{\\\"Model A\\\":96.03}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "V49AX-9X0AW-A81HD_133-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 81.19 and Accuracy of 92.78. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 134,
            "narration": "Recall of 93.18 and accuracy of 92.78 with a precision value 81.19 suggest the model is more accurate than it is precise, this value is backed up by the AUC with 96.03 however overall the model is good at analyzing the dataset.  The overall performance of the model is capturing the accuracy of the dataset is considered high at 92.78 however this value is reduced by the precision value of 81.19. This suggests that the model is accurately able to identify true positive cases however the reduction seen in precision suggests that it produces some misclassification errors as a result of this.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"AUC\\\":{\\\"Model A\\\":96.03},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"Recall\\\":{\\\"Model A\\\":93.18}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "J42KL-24QMR-W656D_134-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 81.19 and Accuracy of 92.78. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Paris House Classification",
            "id": 135,
            "narration": "This dataset is very imbalanced, however this model was still able to achieve high scores of 78.64%, 93.38%, 88.94% and 83.48% for recall, accuracy, precision and F1-score respectively An accuracy of 93.38% means that 93.38% of all predictions were correct, however in an imbalanced dataset such as this, a high accuracy is less indicative of overall performance. A high precision of 88.94% shows a low false positive rate of <preci_diff> and a high recall of 78.64% means a low false negative rate also. This is summarised with an F1-score of 83.48% which is an average of recall and  precision.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.64},\\\"Precision\\\":{\\\"Model A\\\":88.94},\\\"F1-score\\\":{\\\"Model A\\\":83.48}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "B92UV-6LCVQ-AA1P5_135-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 136,
            "narration": "The classification algorithm is reporting very highly for recall and accuracy however very low in precision suggesting a large amount of true positive however also a large quantity of false positives.  The model is very highly accurate to the dataset at 94.15 which entails that most test cases would have  been accurately identified/classified. However, the very low precision score of 32.8 suggest that a large quanity of test cases maybe identified prematurely or not at all suggesting a major flaw in the model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15},\\\"Recall\\\":{\\\"Model A\\\":95.92}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "0DFX1-G18TD-H9Y8L_136-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"1\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 32.8 and Accuracy of 94.15. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Suspicious Bidding Identification",
            "id": 137,
            "narration": "Precision (91.43%), accuracy (98.42%), F1-score (92.75%) and recall (94.12%) scores indicate a very effective model all round. Despite an imbalanced dataset, this model is still able to achieve a very good performance. 98.42% of overall predictions were correct and an F1-score of 92.75% indicate a very balanced as well as high scoring model.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
            "redeem_code": "GJ502-4LTWD-NHGHY-137-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Insurance Churn",
            "id": 138,
            "narration": "On this extremely imbalanced dataset, a high auc (90.05%) and accuracy (90.43%) mean little. Very low recall and precision scores of 66.83% and 33.76% respectively indicate a very ineffective model overall. An AUC of 90.05% means that the model can fairly accurately make out which observation belongs to the positive and negative classes, although it is not the best metric for total judgement.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":66.83},\\\"Precision\\\":{\\\"Model A\\\":33.76},\\\"AUC\\\":{\\\"Model A\\\":90.05},\\\"Accuracy\\\":{\\\"Model A\\\":90.43}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
            "redeem_code": "FCCFM-V7EUT-A4@@5-138-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Recall\":\"2\",\"Precision\":\"1\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 66.83 and AUC of 90.05. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 139,
            "narration": "The learning algorithm employed scores very highly across all metrics: F1-score 92.61%, Accuracy 92.74%, Recall 93.26%, Precision 91.97% on this ML classification task. This model is a very effective performer all round: an F1-score of 92.61% is defined as the mean of recall (93.26%) and precision (91.97%), so therefore in this case the model has shown to be very effective. The dataset is balanced, so therefore a very high accuracy of 92.74% is a good measure of very good performance.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.61},\\\"Recall\\\":{\\\"Model A\\\":93.26},\\\"Accuracy\\\":{\\\"Model A\\\":92.74},\\\"Precision\\\":{\\\"Model A\\\":91.97}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "MG6F9-CCTPP-1@9@9-139-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 140,
            "narration": "The algorithm employed to solve this artificial intelligence problem got an accuracy of 99.94%, with a precision and recall of 81.19% and 83.67% respectively, leading to an F1-score of 82.41%. Despite achieving a really high accuracy, the model scored lower on the precision and recall. However, given the extremely large dataset imbalance, with only 0.17% of examples belonging to class 2, the F1-score of 82.41% can be considered as very good, with the model yielding reliable results.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":82.41},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"Accuracy\\\":{\\\"Model A\\\":99.94}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "T470Q-NQ6VT-RURM9_140-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 141,
            "narration": "The classification algorithm reached an accuracy of 98.54% with an AUC of 100%, while achieving a specificity of 100.0% and sensitivity of 96.5%. The model boasts a perfect score on specificity, while having a slightly lower sensitivity. This means that the model occasionally predicts false negatives, but never false positives. Overall, it performs very well.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":100.0},\\\"Accuracy\\\":{\\\"Model A\\\":98.54},\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"Sensitivity\\\":{\\\"Model A\\\":96.5}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "KE5DC-MAW4E-YWFQ2_141-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"AUC\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Specificity, Sensitivity and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Specificity, Sensitivity and AUC. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 142,
            "narration": "The following were the achieved evaluation metric scores: 96.0%, 98.59%, 97.33%, 94.8% for accuracy, AUC, recall and precision respectively. The model performs very well across all the metrics, leading to balanced and very accurate predictions.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Recall\\\":{\\\"Model A\\\":97.33},\\\"Precision\\\":{\\\"Model A\\\":94.8}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "BFYYW-JBVA9-7FX89_142-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Cab Surge Pricing System",
            "id": 143,
            "narration": "Our method produced an accuracy of 82.24%, precision of 87.11%, recall of 85.82% and an F1-score of 86.46%. The model performs well in general. It achieves a similar accuracy and F1-score, which shows that its predictions are not biased to any of the three classes despite the mild class imbalance.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.46},\\\"Recall\\\":{\\\"Model A\\\":85.82},\\\"Accuracy\\\":{\\\"Model A\\\":82.24},\\\"Precision\\\":{\\\"Model A\\\":87.11}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
            "redeem_code": "33RHR-0H80K-Q5XDF_143-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Recall, Accuracy and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 82.24 and F1-score of 86.46. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 144,
            "narration": "The machine learning algorithm employed on this classification task attained an F1-score of 68.64% and an accuracy of 62.67%, with a specificity and recall of 53.25% and 69.2% respectively. The model performs sub-optimally in general. With a similar specificity and recall, the model does not exhibit a bias, but its accuracy is simply low.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":69.2},\\\"F1-score\\\":{\\\"Model A\\\":68.64},\\\"Accuracy\\\":{\\\"Model A\\\":62.67},\\\"Specificity\\\":{\\\"Model A\\\":53.25}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "G2AN7-F3893-FE5PC-144-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Specificity\":\"2\",\"Recall\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Specificity and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Specificity and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 145,
            "narration": "The evaluation metrics achieved were as follows: recall: 78.18; specificity: 54.72%; F1-score: 66.78%; accuracy: 65.21%. The overall performance of the model was moderate. It exhibited a slight bias towards predicting the positive class, with a higher recall than specificity.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":65.21},\\\"Specificity\\\":{\\\"Model A\\\":54.72},\\\"F1-score\\\":{\\\"Model A\\\":66.78},\\\"Recall\\\":{\\\"Model A\\\":78.18}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "U4MK0-@QYY6-MRXG5_145-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"4\",\"Specificity\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Specificity, F1-score and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 65.21 and Recall of 78.18. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Hotel Satisfaction",
            "id": 147,
            "narration": "This model achieves recall, accuracy , auc and precision scores of 77.52%, 82.7%, 88.67% and 84.66% respectively. A high AUC of 88.67% implies that this model has a good ability to tell apart the positive and negative classes, whereas a recall of 77.52% means that of all members of the target class, this model was able to correctly identify 77.52% of them.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
            "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Car Acceptability Valuation",
            "id": 148,
            "narration": "AUC: 99.42%, Accuracy: 97.11%, Recall: 95.96% and Precision: 94.06% all indicate that this model is a very strong performer Despite the class imbalance, the model is able to achieve almost perfect accuracy, precision, and recall scores. These scores mean that the model is able to very effectively identify both class C1 and C2",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.11},\\\"AUC\\\":{\\\"Model A\\\":99.42},\\\"Recall\\\":{\\\"Model A\\\":95.96},\\\"Precision\\\":{\\\"Model A\\\":94.06}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
            "redeem_code": "9N8UD-B52CT-QXDNN-148-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Job Change of Data Scientists",
            "id": 149,
            "narration": "This model scored Precision, Accuracy, F1-score and recall of 55.23%, 75.75%, 63.19% and 51.3% respectively The scores achieved indicate that this model has almost no predictive ability. Accuracy (75.75%) is only marginally higher than the proportion of the majority class, and precision (55.23%), F1-score (53.19%) and recall (51.3%) are all only marginally better than random choice.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":53.19},\\\"Accuracy\\\":{\\\"Model A\\\":75.75},\\\"Recall\\\":{\\\"Model A\\\":51.3},\\\"Precision\\\":{\\\"Model A\\\":55.23}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
            "redeem_code": "FF36V-0HUPK-26A2Y_149-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"3\",\"F1-score\":\"1\",\"Recall\":\"1\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 150,
            "narration": "Trained on this very imbalanced dataset, this model is able to achieve precision of 40.82%, recall of 83.33%, auc of 84.46% and accuracy of 87.11%. A high auc indicates a fair ability to tell class c1 and c2 apart, however it is more pertinent to focus on the very low precision which means that only 40.82% of the positive cases were labelled as positive. A recall of 83.33% means that of those predicted as positive, only <rec_diff> of them were actually negative.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":40.82},\\\"Recall\\\":{\\\"Model A\\\":83.33},\\\"Accuracy\\\":{\\\"Model A\\\":87.11},\\\"AUC\\\":{\\\"Model A\\\":84.46}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "BECXA-EMA5V-AP7J7-150-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Recall\":\"4\",\"AUC\":\"4\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, AUC and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 151,
            "narration": "This model scores very highly for auc (94.5%) and highly for precision (85.56%), recall (87.03%) and accuracy (86.53%). A very high auc score indicates a very strong ability to sort out the examples under class c1 and c2 and a high precision and recall scores mean that of all the samples that were predicted as belonging to class C2, only a few actually belonged to class C1.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"Accuracy\\\":{\\\"Model A\\\":86.53},\\\"AUC\\\":{\\\"Model A\\\":94.5},\\\"Precision\\\":{\\\"Model A\\\":85.56}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "B2VL4-0PF1F-FRFH7_151-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 85.56 and AUC of 94.5. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Paris House Classification",
            "id": 152,
            "narration": "The learning algorithm obtained an accuracy of 91.56% with an F1-score of 75.49% (calculated from the recall and precision scores 83.12 and 69.15, respectively), on this classification task. The accuracy is high but the F1-score is much lower. This lower F1-score better reflects that the precision is much lower than the recall, suggesting that the model is making mistakes by giving many false positives.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.15},\\\"Accuracy\\\":{\\\"Model A\\\":91.56},\\\"F1-score\\\":{\\\"Model A\\\":75.49},\\\"Recall\\\":{\\\"Model A\\\":83.12}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
            "redeem_code": "EV3YY-JMX87-D9D6G-152-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "2.25.71.194",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Tic-Tac-Toe Strategy",
            "id": 153,
            "narration": "An AUC score of 99.16%, matched with an Accuracy of 96.53% were achieved by the classifier on the given ML task. Its F1-score was 94.62%, made up of a precision score of 89.8%. The very high AUC suggests that the model was able to pick out which outcome was more likely. After categorisation the performance decreases slightly with a very respectable accuracy of 96.53%, while also achieving a high accuracy and F1-score. This can be considered a reliable prediction.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Accuracy\\\":{\\\"Model A\\\":96.53},\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"F1-score\\\":{\\\"Model A\\\":94.62}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
            "redeem_code": "0V@K0-GRK51-Y9U1U-153-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\",\"AUC\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Accuracy and AUC. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Australian Credit Approval",
            "id": 154,
            "narration": "84.78%, 84.91%, 77.59% and 91.11% were the accuracy, precision, recall and AUC scores achieved by the model under consideration. A recall and precision of 77.59% and 84.91% respectively shows that the models prediction are mostly balanced without a major bias towards either category, since the values are mostly similar. The scores are not very high, however neither is the models accuracy. The predictions can therefore be considered as mostly well balanced although not completely reliable.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"AUC\\\":{\\\"Model A\\\":91.11},\\\"Accuracy\\\":{\\\"Model A\\\":84.78}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
            "redeem_code": "VFFV5-HXL4B-AL08W_154-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, AUC and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 77.59 and Precision of 84.91. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 155,
            "narration": "The performance of classification algorithm fore this ML task is captured by the evaluation metrics with the following values: an accuracy of 95.8%, a precision of 95.78% and recall of 95.84%. All of the evaluation metrics have remarkably similar values. This suggests that the model is very well balanced amongst the 4 classification categories. At the same time all three metrics have very high values which suggests that the model performs very well and is reliable.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Precision-score\\\":{\\\"Model A\\\":95.78},\\\"Recall-score\\\":{\\\"Model A\\\":95.84}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "QVMLQ-TL6EL-CPXDD-155-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall-score\":\"5\",\"Precision-score\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Precision-score and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Printer Sales",
            "id": 156,
            "narration": "An accuracy of 86.67, precision of 86.49 F2-score of 86.49 and AUC of 94.31 was achieved by the proposed model. The high and similar values across the AUC, accuracy and precision suggest that the model behaves well in general with balanced predictions across both categories, matched with inaccuracies present across both categories.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":86.49},\\\"AUC\\\":{\\\"Model A\\\":94.31},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"F2-score\\\":{\\\"Model A\\\":86.49}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "L9BUA-FNP46-R@X66-156-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC, Accuracy and Precision? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Concrete Strength Classification",
            "id": 157,
            "narration": "The evaluation metrics scores achieved by the classifier are: 96.34 for AUC, 87.74 for accuracy, 79.22 for precision, and 95.31 for recall. The very high AUC score suggests that the model performs well in general, however, the moderate precision and high recall suggest that the model has a bias towards predicting the positive class, with few false negatives but many false positives.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"AUC\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":95.31}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "YN6TQ-47EPE-L3662-157-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"5\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 158,
            "narration": "The assessment scores achieved are: an F1-score of 86.96, precision of 89.95, accuracy of 88.89 and specificity of 92.61. The models overall performance is very good, since it achieved similarly high values for both the accuracy and F1-score despite the dataset class imbalance.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Accuracy\\\":{\\\"Model A\\\":88.89}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "@@P7D-VPY5P-BYLNM-158-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Accuracy and Specificity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 88.89 and F1-score of 86.96. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "E-Commerce Shipping",
            "id": 159,
            "narration": "In terms of correctly separating the examples under the classes, C1, and C2, the performance of the model reached an accuracy of 67.09%, with a recall of 82.92%, a specificity of 56.02%, and an F1-score of 67.47%. Having a high recall with a low specificity implies that the model has a bias towards predicting positives, with many false positives and fewer false negatives. This unbalanced prediction is generally regarded as bad.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
            "redeem_code": "BL@53-HMVFW-V66M4_159-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Recall\":\"4\",\"Specificity\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Specificity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 82.92 and Specificity of 56.02. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.63",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Food Ordering Customer Churn Prediction",
            "id": 160,
            "narration": "Trained to assort the examples under the different classes, the model is highly accurate with the score of 92.31% and is reflective of the respectable AUC scoring of 93.06%, the models sensitivity however is reduced indicating the true positive rate is also lower  The overall model is highly accurate and 92.31 at determining the examples under the class label C1 however the data is skewed to having more of this in the dataset, the sensitivity however at choosing the examples who are assigned to either C1 or C2 is reduced and provides an area of improvement. The AUC suggests the model is accurately assigning the correct positive and negative values to each category upwards of 93.06% of the time which again indicates the model is good.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":76.92},\\\"Accuracy\\\":{\\\"Model A\\\":92.31},\\\"AUC\\\":{\\\"Model A\\\":93.06},\\\"Precision\\\":{\\\"Model A\\\":86.96}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
            "redeem_code": "A7KAH-AAYUJ-4ANRL_160-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, AUC and Sensitivity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Sensitivity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Advertisement Prediction",
            "id": 161,
            "narration": "The ML model is performing very highly on the given balanced classification task, with all metrics indicating that there are no major areas of improvement. The model was trained on an exact similar proportion split between the two class labels which supports no sampling biases by the model, therefore the true values of 95.67% accuracy, precision at 94.16 and recall and 97.32 all collude an image the model is performing very well at determining differences between C1 and C2  instances/cases accurately and precisely. The AUC at 98.79% suggests an extremely high accuracy in the models predictions of class assignment and is suggestive that the model is very strong at its classification ability.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":97.32},\\\"AUC\\\":{\\\"Model A\\\":98.79},\\\"Accuracy\\\":{\\\"Model A\\\":95.67},\\\"Precision\\\":{\\\"Model A\\\":94.16}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
            "redeem_code": "JMLR9-VHXR2-3J88N_161-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Water Quality Classification",
            "id": 162,
            "narration": "The classification model was able to produce fairly high metrics scores within sensitivity (75.61), specificity (74.8) and accuracy (75.0) however with the reduction seen in the F1-score (60.19) suggests that the recall and precision of the model is reduced, this could be due to the slight imbalance in data for C1 rather than C2.  Accuracy of the model when it comes to correctly sorting and classifying the examples is 75.0% correct of the time which on the unbalanced datasets may possibly be reducing this value. The F1-score, which incorporates both recall and precision is the lowest metrics at 60.19% and therefore there are a significant amount of false positives within the resulting findings.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.61},\\\"F1-score\\\":{\\\"Model A\\\":60.19},\\\"Specificity\\\":{\\\"Model A\\\":74.8},\\\"Accuracy\\\":{\\\"Model A\\\":75.0}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "YQ3@P-69XBT-P23NH_162-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Specificity\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 163,
            "narration": "All metrics are very high, with recall at 91.48 suggesting a fewer than 1 in 10 error rate, F1-score of 91.26%, a combination of both precision and recall, is of course high given those two values are high also. Finally the accuracy of the model in finding and assorting classifications correctly is also high. The model's dataset has been fairly evenly split suggesting that the resulting high result metrics observed can accurately suggest that the model is productive in classifying cases into C1 or C2. The values are suggesting that the model is consistently assorting <10% of the samples into the wrong category however, such as accuracy at 91.37%, and recall at 91.48%",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.06},\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"F1-score\\\":{\\\"Model A\\\":91.26},\\\"Recall\\\":{\\\"Model A\\\":91.48}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "HAHGR-74BFK-H33HK_163-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Broadband Sevice Signup",
            "id": 164,
            "narration": "Despite imbalanced data, the model boasts a high accuracy of 96.58, high recall of 96.78 and a high precision of 95.72%. The fact that the model achieved very high precision and recall rates (and not just high accuracy) shows that the model performs well despite the imbalanced dataset.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Accuracy\\\":{\\\"Model A\\\":96.58},\\\"Precision\\\":{\\\"Model A\\\":95.72}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "@WNH9-R3JFM-9JRF2_164-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 165,
            "narration": "The classifier boasts a fairly high precision reporting at 89.8%, however with recall is low at 28.76 suggesting that the true proportion of actual positives were not identified correctly and therefore the model is performing poorly. The model is characterised on a <|majority_dist|> split into C1 and <|minority_dist|> into C2, and therefore may have influenced the observed result metrics such that the recall rate is significantly lower. Precision is the highest metric at 89.9% rate suggests and overall model which is successful at its given task however the given recall implying that although the model maybe identifying the majority of true positive cases that are correct, it is also choosing many cases that are not",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"Recall\\\":{\\\"Model A\\\":28.76},\\\"AUC\\\":{\\\"Model A\\\":76.92},\\\"Accuracy\\\":{\\\"Model A\\\":55.47}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "Q0QXY-8D0UA-N0URY-165-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\",\"Recall\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Broadband Sevice Signup",
            "id": 166,
            "narration": "This model was able to score 91.75% for precision, 93.07% for accuracy and 92.97% for recall Model A is very effective at predicting both classes, despite the class imbalance. Similar precision and recall scores indicate a balanced model and a very high accuracy shows a generally very proficient model.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.97},\\\"Accuracy\\\":{\\\"Model A\\\":93.07},\\\"Precision\\\":{\\\"Model A\\\":91.75}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
            "redeem_code": "@FV8L-GTDTD-T87EC_166-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 167,
            "narration": "The classifier on this classification problem boasts an AUC score of 74.06, precision of 35.44, sensitivity of 51.85 and accuracy of 69.2. Achieving a sensitivity (sometimes referred to as recall) score of 51.85 indicates that the model captures only correctly classifies about half of the positive labels. The low precision score of 35.44 shows that the model reports a lot of false positives.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":51.85},\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "NJVE7-P@KX6-F6T73_167-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Precision\":\"2\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Sensitivity and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 51.85 and Precision of 35.44. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Annual Income Earnings",
            "id": 168,
            "narration": "This machine learning classification model achieves high accuracy and AUC of 85.86 and 90.88 respectively, but only moderate precision of 55.41 and an F1-score of 64.15. The high accuracy and AUC values alone would indicate that the model performs well, however when the precision and F1-score are also considered we can conclude that the model does not perform as well due to the class imbalance - the moderate precision value highlights that the model is likely incorrectly classifying some C1 samples as C2 samples.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":90.88},\\\"Accuracy\\\":{\\\"Model A\\\":85.86},\\\"F1-score\\\":{\\\"Model A\\\":64.15},\\\"Precision\\\":{\\\"Model A\\\":55.41}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
            "redeem_code": "M4LWM-1807V-JPCU7_168-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Precision and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Precision and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Water Quality Classification",
            "id": 169,
            "narration": "Sensitivity, accuracy, f1 and specificity scores of 48.39%, 61.28%, 41.48% and 66.38% respectively imply a poorly performing model. An F1-score of 41.38% is a good indicator of a very ineffective model. Accuracy and specificity scores of 61.28% and 66.38% should not be misinterpreted and are only as high as they are because of the class imbalance.",
            "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":66.38},\\\"Sensitivity\\\":{\\\"Model A\\\":48.39},\\\"F1-score\\\":{\\\"Model A\\\":41.48},\\\"Accuracy\\\":{\\\"Model A\\\":61.28}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
            "redeem_code": "4KDQP-Y10KK-43A6X-169-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Sensitivity\":\"1\",\"Accuracy\":\"2\",\"F1-score\":\"1\",\"Specificity\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Printer Sales",
            "id": 170,
            "narration": "The given machine learning (ML) model was able to produce with moderate precision and accuracy scores (i.e. 72.97% and 81.39%, respectively), and with the given F2-score of 83.85 incorporating the absent recall metric however suggests that it too is high with the highest metric being AUC implying that  overall  the model is only incorrectly assigning its prediction for a small number of test cases.  The model is marginally skewed to having more records within C1 at <|majority_dist|> to <|minority_dist|> split, however with such minor differences it is unlikely to have impacted the metrics consequently. The precision of the model at 72.97 is likely reflecting on the flaws within the model and therefore the reduction seen in F2-score (scoring at 83.85%), however despite this, the AUC is at 91.07 overally is suggesting that the model is accurately predicting the correct positive classification assortment at a greater than 90% effectiveness.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":72.97},\\\"Accuracy\\\":{\\\"Model A\\\":81.33},\\\"AUC\\\":{\\\"Model A\\\":91.07},\\\"F2-score\\\":{\\\"Model A\\\":83.85}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
            "redeem_code": "CDHDT-W607X-HTBX7-170-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F2-score, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F2-score, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Ethereum Fraud Detection",
            "id": 171,
            "narration": "The classifier recorded very high performance scores across all metrics, with an accuracy of 98.17, precision of 93.21, AUC of 99.34 and recall of 98.56. All four metrics (accuracy, precision, recall and AUC) show extremely high performance - from this we can conclude that the model can accurately classify the majority of the samples as either class C1 or C2.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":98.17},\\\"Recall\\\":{\\\"Model A\\\":98.56},\\\"AUC\\\":{\\\"Model A\\\":99.34},\\\"Precision\\\":{\\\"Model A\\\":93.21}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
            "redeem_code": "0@40W-F@1KD-KAFWQ_171-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, AUC and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 172,
            "narration": "The classification performance level of the model is summed up by the scores across the precision, recall, AUC and accuracy metrics. When trained to separate the observations belonging to each label, it achieves a very high AUC of 94.5, whilst also achieving high values for accuracy, recall and precision with values of 86.53, 87.03 and 85.56 respectively. The model achieves an AUC of 94.5, showing that the separation of the model's class predictions is high. Coupled with a recall of 87.03, which shows that the model must have a relatively low number of false negatives, we can conclude that the model performs well (although there is a little room for improvement considering this dataset is perfectly balanced).",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.56},\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"AUC\\\":{\\\"Model A\\\":94.5},\\\"Accuracy\\\":{\\\"Model A\\\":86.53}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "0FT39-A7RGT-VWLX6-172-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Recall\":\"4\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 94.5 and Recall of 87.03. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 173,
            "narration": "For accuracy, this classification model scored 71.52%, specificity 94.96%, sensitivity 59.06% and auc 84.98%. With such a high specificity and a low sensitivity, this means that the model is very effective at correctly picking out class C1 test observations but at a cost of only being correct with 59.06% of the time when labelling part of C2",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Specificity\\\":{\\\"Model A\\\":94.96},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"AUC\\\":{\\\"Model A\\\":84.98}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "K5JJP-77CTC-B0Q8V-173-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Specificity\":\"5\",\"Sensitivity\":\"2\",\"AUC\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Specificity, Sensitivity and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Specificity of 94.96 and Sensitivity of 59.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Student Job Placement",
            "id": 174,
            "narration": "The highest metric of 96.53 AUC suggests that the model is predicting the correct class label with fewer prediction error, this is coupled with high precision (92.59%), accuracy (88.37%) and recall (89.29) suggesting an overall strong and effective model. With such high precision and accuracy metrics we can infer that the model is correctly annotating records and assorting them into the correct classification as presented 96.53% AUC rate. The model is fairly productive at singling out these cases with precision of 92.59 and accuracy at 88.37 suggesting that the model is picking out these observations correctly and with the 89.29% recall rate of actual positives into the correct categories this is further verified.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.53},\\\"Recall\\\":{\\\"Model A\\\":89.29},\\\"Accuracy\\\":{\\\"Model A\\\":88.37},\\\"Precision\\\":{\\\"Model A\\\":92.59}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "JJR1M-EVD0F-JN84U-174-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 92.59 and Accuracy of 88.37. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Card Fraud Classification",
            "id": 177,
            "narration": "The classification model achieves an extremely high accuracy of 99.94, but only high values of precision (81.19), recall (83.67) and F1-score (82.41), which is important to take into account given the highly imbalanced dataset. Due to the highly imbalanced dataset, the accuracy of the model should largely be ignored (no matter how high it is). The precision and recall values are both fairly high (at 81.19 and 83.67 respectively), and as such the F1-score is naturally high too (as F1-score is calculated from precision and recall). Yet, due to the extremely small number of C2 samples, it is difficult to say whether the model performs well as when taking this into account the precision and recall are perhaps slightly lower than we would like or expected.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":82.41},\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"Accuracy\\\":{\\\"Model A\\\":99.94},\\\"Precision\\\":{\\\"Model A\\\":81.19}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
            "redeem_code": "447QX-AAQVE-C@31H_177-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\",\"F1-score\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "213.205.241.72",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 178,
            "narration": "Evaluations on the ML task show that model's AUC score is 75.2 indicating that it is able to determine with reasonable success the predictive ability to assort this dataset into the classifications of C1 and C2. The sensitivity score is 58.52% suggests of those classified samples, a large proportion of them are not true positives.  The model data is split in <|majority_dist|> and <|minority_dist|>  for C1 and C2 and may have influenced the reduced precision and sensitivity metrics observed here at 43.04% and 58.62% respectively. AUC at 75.2 does suggest that the model is correctly assigning true positives to the correct classification the majority of the time, however with 1 in 4 being wrongly assigned.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":43.04},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "C7QB7-N0JV6-47PN9_178-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Precision\":\"2\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Sensitivity, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Sensitivity, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Airline Passenger Satisfaction",
            "id": 179,
            "narration": "The classifier or model is reporting very highly across all those reported here with recall at 93.12, AUC at 97.81, precision at 91.26 and accuracy at 93.2  The dataset is skewed moderately towards C1 rather than C2 with <|majority_dist|> assigned to C1. Despite this, the very high metrics seen especially within AUC at 97.91% suggesting a very low error rate in assigning samples into the correct classification, the precision, recall and accuracy are above 90% effectiveness and overall provides evidence that the model is good.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":93.12},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Accuracy\\\":{\\\"Model A\\\":93.2},\\\"Precision\\\":{\\\"Model A\\\":91.26}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
            "redeem_code": "K4Y7T-30DB5-N8HWD-179-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Precision and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.49",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 180,
            "narration": "This model scored 59.07%, 56.45%, 61.95% and 71.04% for F1-score, precision, recall and accuracy, respectively. A moderate accuracy score of 71.04% is less impressive due to the class imbalance, an F1-score of 59.07% gives a more accurate picture of the model which overall is not very effective.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Recall\\\":{\\\"Model A\\\":61.95},\\\"F1-score\\\":{\\\"Model A\\\":59.07},\\\"Precision\\\":{\\\"Model A\\\":56.45}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "KAL@Q-G43FX-AY2YW-180-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"1\",\"Precision\":\"1\",\"Recall\":\"2\",\"Accuracy\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 71.04 and F1-score of 59.07. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Mobile Price-Range Classification",
            "id": 181,
            "narration": "The classifier attained an accuracy of about 95.8% with a precision of 95.78 and a Recall-score of 95.48. Based on the accuracy and recall scores, we can conclude that the model achieved a higher performance and as such can correctly predict the class labels of most test cases.",
            "metrics_values": "\"{\\\"Precision-score\\\":{\\\"Model A\\\":95.78},\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Recall-score\\\":{\\\"Model A\\\":95.84}}\"",
            "deleted": false,
            "date_submitted": "20/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
            "redeem_code": "6G0KN-NX1TF-K1QTF-181-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision-score\":\"4\",\"Recall-score\":\"4\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score, Accuracy and Recall-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "86.148.95.68",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Used Cars Price-Range Prediction",
            "id": 182,
            "narration": "The given model attains fairly high scores across the F1-score, accuracy, recall, and precision evaluation metrics. For instance, the accuracy score is 79.8% and the F1-score is 77.06%. Based on these two scores (i.e. accuracy and F1-score), we can confirm that the model has higher classification performance and as such can correctly predict the class labels of close to the majority of test cases relating to all the class labels. (Note: The precision and recall scores were not considered here since the F1-score and accuracy are the most important metric to consider for this balanced dataset. However, we can draw the same conclusion about the model's performance by looking at the scores achieved for them.)",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"Precision\\\":{\\\"Model A\\\":68.58},\\\"F1-score\\\":{\\\"Model A\\\":77.06}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
            "redeem_code": "CUETC-2LJ02-JWJ3P-182-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 87.94 and Precision of 68.58. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Credit Risk Classification",
            "id": 183,
            "narration": "Trained on an imbalanced dataset, the model scores 64.55%, 60.4%, 72.54%, and 65.14%, respectively, across the Precision, F1-score, Specificity, and Accuracy metrics. Since the data was severely imbalanced, this model is shown to have a somewhat poor classification performance across a large number of test cases. The precision and F1-score show that the model has a moderate performance when it comes to predictions related to the examples belonging to the class labels belonging to class C2. However, looking at the accuracy score, there is little trust in the model's prediction decisions. Even, the dummy model constantly predicting label C1 for any given test case can outperform this model in terms of the accuracy and specificity scores.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.4},\\\"Specificity\\\":{\\\"Model A\\\":72.54},\\\"Precision\\\":{\\\"Model A\\\":64.55},\\\"Accuracy\\\":{\\\"Model A\\\":65.14}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
            "redeem_code": "JAP17-X9Q05-GRHAH_183-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"3\",\"Accuracy\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Specificity and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Specificity and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Personal Loan Modelling",
            "id": 184,
            "narration": "On the machine learning classification problem, the model was evaluated based on the scores achieved across the evaluation metrics: F1-score, accuracy, precision, and recall. As shown in the table,  the model got almost perfect classification accuracy of 92.22%, and a moderate recall/sensitivity score of 69.56%. However, it also has low f1 and precision scores of 42.86% and 30.97%, respectively. Judging by the accuracy alone, one can conclude that this model is very effective with its prediction decisions, however, we can forget about the low precision score and moderate recall. The model is shown to have a high false positive rate, implying some examples belonging to the class C1 class are being classified as C2 which is wrong. Therefore based on the above observations, the prediction output of C2 shouldn't be accepted in most cases. More analysis will be required to check if the example's label should be C1 or not. To summarize, the confidence in the model's decisions is low.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.22},\\\"F1-score\\\":{\\\"Model A\\\":42.86},\\\"Precision\\\":{\\\"Model A\\\":30.97},\\\"Recall\\\":{\\\"Model A\\\":69.56}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
            "redeem_code": "CQRPY-J7YBY-BWWH9_184-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"5\",\"Precision\":\"2\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "House Price Classification",
            "id": 185,
            "narration": "The classifier got the scores 85.42%, 86.28%, 87.23%, and 83.67%, based on the F1-score, accuracy, precision, and recall metrics respectively as shown in the table. We can confirm that this model is well balanced since it has very similar scores across all the metrics. This model is likely to misclassify only a few test cases hence its prediction decisions can be somewhat trusted to be true.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.23},\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":85.42},\\\"Accuracy\\\":{\\\"Model A\\\":86.28}}\"",
            "deleted": false,
            "date_submitted": "22/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
            "redeem_code": "956XH-E1ATW-PAMVM-185-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Basketball Players Career Length Prediction",
            "id": 186,
            "narration": "The classification model's assessment scores based on the evaluation metrics are 62.98% for accuracy, 69.36% for precision, and a recall score of 50.0%. Deriving the F1-score based on precision and recall, the model scored just about 58.11%. From the scores across all the metrics, we can confirm that the model will have moderately poor performance as it is likely to misclassify some test cases. The accuracy score of 62.98% is marginally better than the dummy model always assigning the majority class label C1 to any given test case. Finally, there is low confidence in the prediction decisions from this model.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"Accuracy\\\":{\\\"Model A\\\":62.98},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Precision\\\":{\\\"Model A\\\":69.36}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
            "redeem_code": "XQBDH-F7NHR-UUV9C_186-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 58.11 and Accuracy of 62.98. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Bike Sharing Demand",
            "id": 187,
            "narration": "Trained on a balanced dataset, the model scored 96.08% (AUC), 94.72% (Recall) , 82.64% (precision) and 89.12%  as its accuracy score on the ML classification problem as shown in the table. From the accuracy score, there will times that it might misclassify some difficult test cases. However, the false positive and negative rate is very low  judging by the difference in the precision and recall scores. Overall, since the dataset used to train the model has equal proportions of examples for both class labels C1 and C2, one can conclude that this classifier will be very effective at correctly predicting the true class labels for the majority of test cases.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.08},\\\"Recall\\\":{\\\"Model A\\\":94.72},\\\"Precision\\\":{\\\"Model A\\\":82.64},\\\"Accuracy\\\":{\\\"Model A\\\":89.12}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
            "redeem_code": "4V4EK-7GE7G-3Y8Y2-187-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC and Accuracy? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Customer Churn Modelling",
            "id": 188,
            "narration": "The classifier on this ML problem achieved the  scores 81.32%, 55.66%, 64.61% and 48.88% across the following evaluation metrics: accuracy, F1-score, recall and precision, respectively. On the basis of the scores attained across the metrics under consideration, the model is shown to be less effective (than anticipated)  at detecting the test cases belonging to the minority class label C2. The confidence for predictions of C2 is very low as there seem to be many false positive prediction decisions (looking at the recall and precision scores). Based on the fact that the dataset was imbalanced, the accuracy score is of less importance here, however, judging based on this score it can be said that the model is somewhat better than the dummy classifier.  There is more room for improvement for this model.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":64.61},\\\"F1-score\\\":{\\\"Model A\\\":55.66},\\\"Accuracy\\\":{\\\"Model A\\\":81.32},\\\"Precision\\\":{\\\"Model A\\\":48.88}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
            "redeem_code": "RXKE9-LH36N-LKDDX-188-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Recall\":\"3\",\"Precision\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and F1-score? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Employee Attrition",
            "id": 189,
            "narration": "From the table shown, the model scores: accuracy of 55.47%, recall score of 28.76%, AUC score of 76.92 and a high precision score of 89.8% on the classification problem under consideration.  Interestingly, the model is shown to be biased towards predictions related to C2 class label. The confidence in predictions of C2 is high compared to that of C1. Overall, looking at the scores, we can say its performance is somehow poor as it might fail to correctly identify some examples from both classes especially those  related to C1.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"AUC\\\":{\\\"Model A\\\":76.92},\\\"Recall\\\":{\\\"Model A\\\":28.76},\\\"Accuracy\\\":{\\\"Model A\\\":55.47}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
            "redeem_code": "CDMRJ-AQ1NH-8H1XM_189-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"3\",\"Recall\":\"1\",\"Precision\":\"4\",\"Accuracy\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 28.76 and AUC of 76.92. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 190,
            "narration": "The performance of the classifier on this classification problem as evaluated based on the metrics Precision, Sensitivity, AUC and Accuracy, respectively are: 22.78%, 54.54%, 72.19%, and 69.6%. These scores generally indicate the model has a poor classification performance, hence, will fail to correctly identify/classify the majority of test cases belonging to the different possible class labels under consideration. From precision and recall scores, we can judge that the model will have a high false positive rate.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":69.6},\\\"Precision\\\":{\\\"Model A\\\":22.78},\\\"AUC\\\":{\\\"Model A\\\":72.19},\\\"Sensitivity\\\":{\\\"Model A\\\":54.54}}\"",
            "deleted": false,
            "date_submitted": "27/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "CVMLL-AY6JB-H1VLY-190-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"1\",\"Sensitivity\":\"2\",\"AUC\":\"3\",\"Accuracy\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-4",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Sensitivity, AUC and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Sensitivity, AUC and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Vehicle Insurance Claims",
            "id": 191,
            "narration": "For this classification task, the model scores 82.46%, 85.0%, and 70.15%, respectively, on the evaluation metrics Precision, Accuracy and Recall. The scores are pretty high indicating that it can accurately determine the class labels for several test instances. Despite the class imbalance, the model is confident about prediction outputs related to C2(the minority class).",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.0},\\\"Precision\\\":{\\\"Model A\\\":82.46},\\\"Recall\\\":{\\\"Model A\\\":70.15}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
            "redeem_code": "WR4KG-37BD0-RC1TY-191-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-3",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Company Bankruptcy Prediction",
            "id": 192,
            "narration": "The performance of the classification algorithm is very impressive, achieving  scores of 99.16%, 100.0%, 89.12% and 95.08%, respectively, across the metrics AUC, specificity, sensitivity/recall and accuracy. From these scores achieved, the algorithm is shown to have a lower misclassification error and given that the specificity is at a perfect rate of 100.0%, we can be sure that it can accurately separate or classify almost all the test cases related to class C1.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"Sensitivity\\\":{\\\"Model A\\\":89.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.08}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
            "redeem_code": "L0YXQ-@C9RJ-2@UAL-192-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"AUC\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"Accuracy\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and AUC? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 193,
            "narration": "The machine learning classifier or model trained on this classification problem scores 43.04%, 72.4%, 58.62% and 75.2%, respectively, on the evaluation metrics precision, accuracy, sensitivity and AUC. This model has a lower prediction performance than anticipated given its low scores for the precision and sensitivity. The accuracy  is not better than the alternative model that constantly assigns C1 to any given test instance/case. Overall, this model's output prediction decisions shouldn't be taken on the face value.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Precision\\\":{\\\"Model A\\\":43.04},\\\"Accuracy\\\":{\\\"Model A\\\":72.4}}\"",
            "deleted": false,
            "date_submitted": "31/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "RLKHJ-28UMN-VLWUW_193-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Sensitivity\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy, AUC and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Real Estate Investment",
            "id": 194,
            "narration": "The classification performance assessment scores achieved on this task where the test cases are categorized under the class labels C1 and C2 are 92.73%, 91.07, 97.22%, and 96.0%, respectively, based on the metrics Recall, Precision, AUC, and Accuracy. The prediction ability of the classifier can be summarized as very high considering the data disproportion between the two class labels. These scores show that only a few examples will likely be assigned the wrong class label. Furthermore, the precisions and recall/sensitivity scores are very indicative of the low false-positive rate of the model.",
            "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"Recall\\\":{\\\"Model A\\\":92.73},\\\"AUC\\\":{\\\"Model A\\\":97.22}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
            "redeem_code": "8P8EX-MLVM6-7R9ET-194-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision, Accuracy and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 97.22 and Accuracy of 96.0. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Health Care Services Satisfaction Prediction",
            "id": 195,
            "narration": "The classifier was trained to assign test examples under one of the class labels C1 and C2. Performance assessment conducted based on the metrics accuracy, precision, and F1-score produced the scores 63.97%, 60.32%, and 60.8%.  With the dataset having an almost equal proportion of examples under each class label, these scores show that this classifier has a moderate classification performance suggesting it will likely misclassify a fair number of test cases. Irrespective of this pitfall, the performance is at an acceptable level.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
            "redeem_code": "AH6LX-J4826-FRTT1-195-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 2
        },
        {
            "task_name": "Employee Promotion Prediction",
            "id": 196,
            "narration": "The goal of the ML task is to assign test cases one of the class labels C1 and C2. The dataset is imbalanced implying that a large proportion of data have the label C1. As shown in the table, the classifier trained on this problem achieved scores of 95.92% as the recall, 94.15% for the predictive accuracy, and a very low precision score equal to 32.8%. On this problem, the classifier demonstrates a fair prediction performance but the precision score tells a story of a model with a false-positive rate higher than expected. This conclusion is drawn from the fact that there is a huge difference between the precision score and recall score meaning positive prediction output (i.e. when a test instance is assigned the label C2) can't be trusted to be correct for the majority of test cases.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":95.92},\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
            "redeem_code": "3ARW4-BU73N-JH74U_196-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\"}",
            "narrator": 45,
            "model_name": "Model-2",
            "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 129,
            "narration": "The classifier was able to achieve an accuracy of 73.96%, sensitivity of 48.57% and F2-score of 51.82%. Based on the scores, we can assert that the model has a moderate prediction accuracy, however, it has a very sensitivity score with a moderately low F2-score indicating a very poor model overall.",
            "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":51.82},\\\"Sensitivity\\\":{\\\"Model A\\\":48.57},\\\"Accuracy\\\":{\\\"Model A\\\":73.96}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"1\",\"F2-score\":\"1\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 129,
            "narration": "The ability of the machine learning model or classifier to label test samples as either C1 or C2 can be summarized as follows: for the prediction accuracy, the model scored 73.96% with the sensitivity equal to 48.57%; specificity score of 88.52%; precision score of 70.83% and an F1-score of 57.62%. This model has a high specificity but a low sensitivity which indicates that the model was more effective at predicting the class C1 than C2. An F1-score of 57.62% is an indicator of an overall poor model which performs especially poorly on the minority class. In summary, the model struggles to rightly identify test cases belonging to class C2 than C1.",
            "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":57.62},\\\"Precision\\\":{\\\"Model A\\\":70.83},\\\"Specificity\\\":{\\\"Model A\\\":88.52},\\\"Sensitivity\\\":{\\\"Model A\\\":48.57},\\\"Accuracy\\\":{\\\"Model A\\\":73.96}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"1\",\"Specificity\":\"4\",\"Precision\":\"3\",\"F1-score\":\"2\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 129,
            "narration": "The capability of the algorithm to appropriately classify test samples as C1 or C2 was analyzed based on the metrics: accuracy, sensitivity, specificity and precision. Across these metrics, the classifier scored 74.80% for specificity, 83.20% for accuracy, 91.87% for sensitivity, and 88.69% for precision. High precision and sensitivity  scores show that this model has a high F1-score implying that it is very effective in terms of predicting the positive class C2. It has  moderate accuracy and specificity scores but still boasts of a good ability to detect class C1 as well.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.69},\\\"Specificity\\\":{\\\"Model A\\\":74.80},\\\"Sensitivity\\\":{\\\"Model A\\\":91.87},\\\"Accuracy\\\":{\\\"Model A\\\":83.20}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"5\",\"Specificity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The scores achieved by this model are 78.65%, 57.15%, 90.98%, and 66.11% for accuracy, recall, specificity, and F1-score, respectively. For this imbalanced classification task, the model has been trained to assign a label (either C1 or C2) to any given test observation. Very high specificity and low recall show that the model is effective at predicting C1 but not very effective at all at predicting class C2. A moderate accuracy can be explained away by the <|majority_dist|> class imbalance. Overall, this model demonstrates a poor classification ability hence has a high misclassification error.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":57.15},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":66.11},\\\"Specificity\\\":{\\\"Model A\\\":90.98}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"2\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "In the context of the given classification problem (where the objective is assigning a label (either C1 or C2) to any given test observation), the scores achieved by this classifier are 78.65%, 57.15%, 90.98%, and 66.11% for accuracy, recall, specificity, and F1-score, respectively. According to these scores, the model has a moderate classification performance implying that the model will fail to correctly identify a fair amount of test observations/samples. Furthermore, low recall and very high specificity show that the classifier is very good at predicting the label C1, but not very effective (in most cases) at correctly assigning the class C2. Finally, the moderate accuracy can be explained away by the <|majority_dist|> class imbalance.",
            "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":57.15},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":66.11},\\\"Specificity\\\":{\\\"Model A\\\":90.98}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 129,
            "narration": "This ML model's ability to correctly classify test samples as either C1 or C2 was evaluated based on precision, sensitivity, specificity, and predictive accuracy. The scores achieved across the metrics are as follows: the classifier scored 83.20% for accuracy; 91.87% for sensitivity; 74.80% for specificity, and 88.69% for precision. High sensitivity and precision show that this model is very effective at predicting positive class C2, lower but still good accuracy and specificity scores indicate a fair ability to detect class C1 also.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.69},\\\"Specificity\\\":{\\\"Model A\\\":74.80},\\\"Sensitivity\\\":{\\\"Model A\\\":91.87},\\\"Accuracy\\\":{\\\"Model A\\\":83.20}}\"",
            "deleted": false,
            "date_submitted": "19/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
            "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"5\",\"Specificity\":\"3\",\"Precision\":\"4\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "129.234.0.56",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For this classification task, the model has been trained to label any given test observation as either C1 or C2. With respect to classification performance, the model scored accuracy: 76.48%; precision: 79.09%; specificity: 88.52% and F2-score: 72.26%. 76.48% of this model's predictions were correct as deduced from the accuracy.  Scoring a precision of 79.09% suggests only <preci_diff> of true C1 data was misclassified as C2, but the model was also fairly good at recognizing class C2 as shown by the precision and F2-scores.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"Specificity\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "In this classification problem, the model was trained to label certain test cases as either C1 or C2. In terms of classification performance, the model's accuracy is 76.48%, has a precision score of 79.09%; the specificity is 88.52%, and the F2-score is 72.26%. 76.48% of the predictions for this model were accurate as calculated based on accuracy. A precision score of 79.09% shows that of the data belonging to C1 was misclassified as C2. But the model also has a relatively good classification ability for class C2 samples, as evidenced by the F2-score and precision score.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"Specificity\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "On the task of correctly selecting the true labels for any given set of test instances or observations, the model demonstrates a moderate to high classification prowess. Specifically, it scored an accuracy of about 76.48%, a precision score of 79.09% with the F2-score and specificity score equal to 72.26% and 88.52%, respectively. From the precision, specificity, and F2-score, the model is shown to have moderate confidence in  classification decisions across samples drawn from the two class labels.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For accuracy, precision, AUC, and F2-score, the model  scored 80.81, 79.07, 87.62, and 82.13, respectively. A precision of 79.09% implies that 79.09% of C2 predictions actually belonged to C2 (meaning the model is quite precise with its prediction decisions); a good AUC score indicates a good ability to make out the examples between positive and negative classes. An accuracy of 80.81% and an F2-score of 82.12% imply an overall fairly good model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For precision, AUC, accuracy, and F2-score, the model scores were 79.07, 87.62, 80.81, and 82.13, respectively. The 79.09% precision score means that 79.09% of C2 predictions actually were true (indicating that the model is mostly precise with its predictions). Demonstrates excellent ability to differentiate between positive and negative classes as shown by the AUC score. Finally, the accuracy of 80.81% and the F2-score of 82.12% indicate that the overall model is quite good.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classifier has moderately high scores across the evaluation metrics accuracy, precision, F2-score, and AUC. To be specific, for accuracy,  AUC, precision, and F2-score, the model scored 80.81,  87.62, 79.07, and 82.13, respectively. A precision of 79.09% implies that 79.09% of c2 predictions actually belonged to c2; a good AUC score indicates a good ability to recognize the observations under the positive class and the negative class. The F2-score of 82.12% and an accuracy of 80.81%  imply an overall moderately good model.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "With the training objective of choosing the true label of any given test case or observation, the model scored 78.65, 78.43. 90.98 and 60.43 when evaluated based on the metrics accuracy, precision, specificity, and F2-score respectively. As shown, the model has scored a very high specificity of 90.98, implying that it is very effective at setting apart examples belonging to class C1. As for correctly making out the C2 observations, the model shows moderate classification performance as indicated by the precision and F2-score.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For the purpose of training the classifier on the dataset to identify the true class of any given test case or observation, the classification model scored an accuracy of 78.65, a precision score of 78.43% with the specificity score of 90.98 and 60.43 as the F2-score. A very high specificity of 90.98 implies the classifier is quite effective at picking out class C1 observations. Regarding the correct identification of C2 observations, the model exhibits moderate performance as evidenced by the precision and F2-score.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For this classification task, a given test observation or instance is assigned the label either C1 or C2. Evaluations conducted based on the metrics precision, specificity, accuracy, and F2-score show that the model is quite good at performing the classification task. Specifically, the model scored 78.65, 78.43. 90.98 and 60.43, respectively, across the accuracy, precision, specificity, and F2-score. As shown, the classifier has a very high specificity indicating that it is very confident about the C1 predictions. Finally, the model shows a moderate classification performance when picking out the C2 observations as indicated by the precision and F2-scores.",
            "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classification model scored 80.81% for accuracy, 82.93% for sensitivity, 87.62% for AUC and 80.95% for F1-score. The F1-score is a metric that encompasses a model's ability to detect both class C1 and C2, and this model scores a fairly high 80.95%. High scores for accuracy, sensitivity paint a similar picture. Finally, a score of 87.62 for AUC demonstrates a good ability to tell-apart the cases belonging to class C2 from those of class C1.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The scores attained by the classification model were 80.81% accuracy, 82.93% sensitivity, 87.62% AUC, and 80.95% F1-score. The F1-score is a measure that summarizes the ability of the model to correctly detect the C1 and C2 test observations, and the score for this model is quite high at 80.95%. A high level of accuracy and sensitivity show that the model is quite effective. Finally, an AUC score of 87.62 shows the excellent ability of the classifier to separate the class C2 and class C1 test cases.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "As shown, the classifier scored an accuracy of 80.81%, 87.62% for AUC with 82.93% for sensitivity, and 80.95% for F1-score. The F1-score (computed based on the precision and sensitivity scores) is fairly high and it is a metric that takes into account the model's ability to detect examples from both class labels. Besides, the high scores for accuracy, sensitivity depict a similar conclusion and a score of 87.62 for AUC shows that the model has a good ability to classify multiple observations belonging to class C2 from C1.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "As shown in the table, the scores achieved by the model are as follows: accuracy (76.8), sensitivity (83.74), precision (73.05), F1-score (78.03). An F1-score of 78.03% is a good reflection of an overall fairly good model. The sensitivity score is higher than precision, which indicates that some examples from the majority class C1 will be labeled as part of the minority class C2. However, since the difference between these two metrics is not that huge, we can conclude that this model can correctly identify the true label for a moderate number of test cases.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8},\\\"F1-score\\\":{\\\"Model A\\\":78.03},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classifier trained on this classification task attained an accuracy score of 76.8%, a precision score of 73.05%, a sensitivity score of about 83.74%, and an F1-score of 78.03. According to these scores, this classifier demonstrates a fair understanding of the objectives of the ML problem and can accurately generate the true label for a number of test cases with a small margin of error. The difference between the sensitivity and precision scores implies some C2 predictions might be wrong but from the F1-score, we can say that for most cases it will be confident about the final prediction decision.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8},\\\"F1-score\\\":{\\\"Model A\\\":78.03},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"3\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "German Credit Evaluation",
            "id": 197,
            "narration": "The classifier was trained with the objective of grouping or classifying the test examples under the class either C1 or C2. The scores achieved across the metrics are 72.4% (accuracy), 75.2% (AUC), 43.04% (precision) and 58.62% (recall/sensitivity). These assessment scores are lower, indicating that the model has a limited understanding of the classification problem. Consequently, it will fail to correctly identify the correct class labels of most examples, especially those drawn from the label C2, which happens to be the minority class.",
            "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"Precision\\\":{\\\"Model A\\\":43.04}}\"",
            "deleted": false,
            "date_submitted": "14/11/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
            "redeem_code": "56@KH-JJA19-UHKYW-197-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"2\",\"Sensitivity\":\"3\"}",
            "narrator": 45,
            "model_name": "Model-1",
            "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "The classifier trained on the classification task had a score of 76.8% for specificity; 83.74 for sensitivity; 73.05% for precision, and 81.36 for the F2-score. The F2-score is a combination of sensitivity and precision, weighting sensitivity twice as high. Overall, according to the scores, this model is shown to be more effective at avoiding false negatives than it is at avoiding false positives.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Specificity\\\":{\\\"Model A\\\":76.8},\\\"F2-score\\\":{\\\"Model A\\\":81.36},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"F2-score\":\"4\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"2\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "For specificity, sensitivity, and precision scores, the model achieved 88.52%, 70.74%, and 79.07%, respectively. The specificity score means that 88.52% of those predicted as being part of class C1 were actually part of class C1. Besides, the precision and recall scores show that the model is picky with its C2 labeling decisions hence fairly confident about the C2 predictions.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":70.74},\\\"Specificity\\\":{\\\"Model A\\\":88.52},\\\"Precision\\\":{\\\"Model A\\\":79.07}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"5\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        },
        {
            "task_name": "Pima Classification",
            "id": 63,
            "narration": "This model scored 81.11%, 79.67%, 80.33%, and 80.4% for specificity, sensitivity, precision, and accuracy, respectively. Specificity, sensitivity, and precision scores are similar at around the same figure, which indicates a model that performs similarly at predicting both classes at a good level. An accuracy score indicates that of all predictions, 80.4% of them were correct.",
            "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":79.67},\\\"Specificity\\\":{\\\"Model A\\\":81.11},\\\"Accuracy\\\":{\\\"Model A\\\":80.4},\\\"Precision\\\":{\\\"Model A\\\":80.33}}\"",
            "deleted": false,
            "date_submitted": "11/10/2021",
            "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
            "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
            "nb_models": 1,
            "imetric_score_rate": "{\"Specificity\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"Precision\":\"4\"}",
            "model_name": "Model-2",
            "narrator": 45,
            "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
            "narrative_status": 1,
            "date_approved": "01-01-1970",
            "is_paid": 2,
            "user_ip": "81.100.22.24",
            "is_dataset_balanced": 1
        }
    ]
}