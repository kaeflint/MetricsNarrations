[
    {
        "task_name": "Insurance Churn",
        "id": 28,
        "narration": "The classifier achieves a precision score of 45.01% with a recall of about 58.09%. Other scores achieved were 89.91% (accuracy) and 87.58% (AUC). Since the model was trained on an imbalanced dataset, the metrics of importance were precision and recall scores. The scores achieved across these metrics are low, hence the model will have a lower F1-score. This implies that the model will perform poorly in terms of the prediction decisions for the samples drawn for the less common class label C2. Even based on the AUC and accuracy scores, we can conclude that the model has somewhat poor performance.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":89.914},\\\"Recall\\\":{\\\"Model A\\\":58.086},\\\"AUC\\\":{\\\"Model A\\\":87.581},\\\"Precision\\\":{\\\"Model A\\\":45.013}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
        "redeem_code": "V4QTB-B204H-J9VHF-28-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 89.91 and AUC of 87.58. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Student Job Placement",
        "id": 29,
        "narration": "For the evaluation metrics Recall, AUC, Accuracy, and Precision, the model achieved scores of 90.0%, 97.45%, 93.02%, and 100.0%, respectively. Based on the almost perfect scores across the different metrics under consideration, it is valid to conclude that this model will be very effective at correctly predicting the true class label for the majority of the test cases/samples.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.02},\\\"AUC\\\":{\\\"Model A\\\":97.45},\\\"Recall\\\":{\\\"Model A\\\":90.0},\\\"Precision\\\":{\\\"Model A\\\":100.0}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "X8@@3-NN9Y4-L6@BG_29-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving Recall of 90.0 and AUC of 97.45.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 30,
        "narration": "The following are the scores achieved by the classifier on this ML task: Accuracy of 62.98; recall score of 50.0%; precision score of 69.36%. On the basis of the precision and recall scores, the model's F1-score is about 58.11%. Judging from scores across the metrics, we can conclude that the model has somewhat lower performance, and hence will be moderately good at correctly sorting out the true label for the majority of the samples drawn from the different classes, C1 and C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":62.985},\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"F1-score\\\":{\\\"Model A\\\":58.108},\\\"Precision\\\":{\\\"Model A\\\":69.355}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "D3BDR-19LTL-PGNEG-30-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 62.98 and Recall of 50.0. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "House Price Classification",
        "id": 31,
        "narration": "According to the table, the model has a prediction accuracy of 79.41% with precision and recall scores equal to 89.36% and 72.41%, respectively. Based on the precision and recall scores, we can see that the F1-score is 80.01%. However, since the recall is greater than the precision score, some observations labeled as C2 by the model could be from label C1. Given that the model was trained on a balanced dataset, we can say that it has moderate prediction performance and that it can fairly identify the correct class labels for test cases from both class labels.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.412},\\\"Recall\\\":{\\\"Model A\\\":72.414},\\\"F1-score\\\":{\\\"Model A\\\":80.01},\\\"Precision\\\":{\\\"Model A\\\":89.362}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
        "redeem_code": "RGBGM-8UPQT-B2YR4_31-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"F1-score\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, F1-score and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Tic-Tac-Toe Strategy",
        "id": 32,
        "narration": "On this ML problem, the model achieves the scores 79.59% (Precision), and 88.64% (F1-score). Furthermore, it has almost perfect Accuracy and AUC scores of 93.06% and 99.29%, respectively. Based on all the scores, the model is shown to have a somewhat high prediction performance and will be able to correctly identify the majority of test cases from even the minority class (C2). In other words, in most cases, it can correctly tell apart (with moderately high confidence) the unseen observations belonging to the different classes.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.056},\\\"AUC\\\":{\\\"Model A\\\":99.291},\\\"F1-score\\\":{\\\"Model A\\\":88.636},\\\"Precision\\\":{\\\"Model A\\\":79.592}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
        "redeem_code": "2VK9M-WNQYE-25K76-32-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"AUC\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and AUC. (Your answer should capture the implications of achieving AUC of 99.29 and Precision of 79.59.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 33,
        "narration": "The machine learning model trained on the given classification task attained the performance evaluation score of 94.51% when measuring accuracy; 99.1% for AUC, and 91.12% and 90.2% for precision and recall respectively.  The model performed well in general and prediction ability is balanced (i.e. not biased) across the two classes with similar precision and recall values of 91.1% and 90.2% respectively, which was achieved despite the <|majority_dist|>/<|minority_dist|> imbalanced distribution in the dataset across the different classes C1 and C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":94.51},\\\"Recall\\\":{\\\"Model A\\\":90.20},\\\"AUC\\\":{\\\"Model A\\\":99.099},\\\"Precision\\\":{\\\"Model A\\\":91.12}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "EDTU9-KNAVK-GEGTB_33-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 91.09 and Recall of 90.2. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Cab Surge Pricing System",
        "id": 34,
        "narration": "Regarding the F1-score, accuracy, recall, and precision metrics, the model got scores of 88.65%, 83.99%, 83.74%, and 94.18%, respectively. The accuracy is very similar to recall and quite dissimilar to precision, which is substantially higher. This suggests that the precision metric dominates the accuracy measure rather than recall. In summary, the classifier will be able to correctly label test cases from any of the class labels C1, C2 and C3 with a small chance of error.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":83.986},\\\"Recall\\\":{\\\"Model A\\\":83.74},\\\"F1-score\\\":{\\\"Model A\\\":88.653},\\\"Precision\\\":{\\\"Model A\\\":94.18}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
        "redeem_code": "T8NA3-GUQL1-W48VA-34-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 83.74 and Accuracy of 83.99. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "2.25.71.194",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Concrete Strength Classification",
        "id": 35,
        "narration": "Evaluation metric scores of 74.19% for accuracy, 91.11% for recall, 53.25% for precision, and 91.09% for AUC were achieved by the model. Despite training on a balanced dataset, the model has a bias towards predicting the positive C1 class for several test cases, since it has a low precision of 53.25% but a high recall of 91.11%. This implies the  confidence related to class C2 prediction is usually low, making the model less useful than it may seem from the 74.19% accuracy.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.194},\\\"Recall\\\":{\\\"Model A\\\":91.111},\\\"AUC\\\":{\\\"Model A\\\":91.092},\\\"Precision\\\":{\\\"Model A\\\":53.247}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "UV7@U-RGNLU-D71VG-35-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision, Accuracy and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 91.11 and Precision of 53.25. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Employee Attrition",
        "id": 36,
        "narration": "The classifier obtained the following evaluation scores on the given machine learning classification problem: AUC: 84.46%, accuracy: 87.11%, precision: 40.82%, recall: 83.33%. The low precision of the model suggests that the model has a bias towards predicting the negative class label (C1). This is to be expected and remains a challenge when working with a large dataset imbalance, where <|majority_dist|> of the data belong to class C1. This bias implies that the performance of the model is worse than what the moderately high accuracy of 87.11% or the AUC of 84.46% suggests.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.109},\\\"Recall\\\":{\\\"Model A\\\":83.333},\\\"AUC\\\":{\\\"Model A\\\":84.462},\\\"Precision\\\":{\\\"Model A\\\":40.816}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
        "redeem_code": "LREG8-1UHW0-Q817W-36-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, AUC and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 37,
        "narration": "Metric values of 72.0% for accuracy, 73.5% for AUC, 60.47% for sensitivity, and 32.91% for precision were achieved by the model. The model achieves a reasonable AUC of 73.5% showing some degree of understanding. The very low precision of 32.91% with moderate sensitivity (recall) of 60.47% suggests that the model has a bias against predicting the positive class, C2, which is also the minority class with about <|minority_dist|> of examples in the dataset.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":72.0},\\\"Sensitivity\\\":{\\\"Model A\\\":60.465},\\\"AUC\\\":{\\\"Model A\\\":73.499},\\\"Precision\\\":{\\\"Model A\\\":32.911}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "XGT6Y-BJ0YV-4MV4L_37-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"3\",\"Sensitivity\":\"2\",\"Precision\":\"1\",\"Accuracy\":\"2\"}",
        "model_name": "Model-5",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Sensitivity, Precision and AUC? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 38,
        "narration": "The algorithm's ability to tell-apart the examples belonging to the different class labels was evaluated based on the metrics accuracy, recall, F1-score, and precision. It achieved the following scores: accuracy equal to 71.04%; F1-score of 56.5%, precision of 50.81%, and a recall score of 63.64%. On such an imbalanced dataset, only the F1-score, precision and recall are important when making a decision about how good the model is. From the scores across the different metrics, we can conclude that the model has a moderate false-positive rate, and only a few examples from class label C2 can be correctly classified.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Recall\\\":{\\\"Model A\\\":63.64},\\\"F1-score\\\":{\\\"Model A\\\":56.50},\\\"Precision\\\":{\\\"Model A\\\":50.81}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "UN099-UM@EN-LX4JU-38-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
        "model_name": "Model-6",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, F1-score, Precision and Accuracy. (You should consider the implications of the model's score across each metric. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Paris House Classification",
        "id": 39,
        "narration": "On these metrics Accuracy, Precision, F1-score and Recall, the model achieved 93.88%, 67.66%, 80.61% and 99.69%, respectively. According to the F1-score, it can be said that the model has a moderate classification performance. It can successfully produce the correct label for most test cases. However, some cases from class C1 will be labeled as C2 judging based on the difference between the precision and recall scores.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.88},\\\"Recall\\\":{\\\"Model A\\\":99.69},\\\"F1-score\\\":{\\\"Model A\\\":80.61},\\\"Precision\\\":{\\\"Model A\\\":67.66}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
        "redeem_code": "P6L66-M@4H6-6YK@M-39-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"3\",\"F1-score\":\"4\",\"Recall\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, F1-score and Recall. (Your answer should capture the implications of achieving Accuracy of 93.88 and Precision of 67.66.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Paris House Classification",
        "id": 40,
        "narration": "From the table shown, we can say the model has a 78.65% Recall score, 83.48% F1-score, 88.94 precision, and an Accuracy score of 93.38%. This model despite being trained on an imbalanced dataset, is shown to do pretty well at picking out a large number of examples belonging to the different class labels. Based on the precision score (88.94%) and recall score (78.65%), we can say that it has a lower false-positive rate. It goes to show that the model doesn't frequently label test observations as C2, but when it does, it is usually correct.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":83.48},\\\"Precision\\\":{\\\"Model A\\\":88.94}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
        "redeem_code": "7F8VR-PD5M8-QG7Q8-40-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"F1-score\":\"4\",\"Precision\":\"4\",\"Recall\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, F1-score and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 41,
        "narration": "Across the metrics: AUC, Recall, Precision, and Accuracy, the model achieved very high scores (i.e., 98.59, 97.33, 94.8, and 96.0, respectively). According to these scores, the model is very confident regarding its prediction decisions for unseen cases from any of the class labels. In simple terms, it can correctly classify a larger number of test cases belonging to the different classes under consideration, and the misclassification rate is <acc_diff>.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Recall\\\":{\\\"Model A\\\":97.333},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Precision\\\":{\\\"Model A\\\":94.805}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "1CC3F-2YAR6-@HWD0_41-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 97.33 and Accuracy of 96.0. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Broadband Sevice Signup",
        "id": 42,
        "narration": "These are the scores the model achieved across the following metrics: Accuracy (93.07%); Precision (91.75%), and Recall (92.97%). Given the fact that it was trained on imbalanced data, its prediction performance is very high with almost perfect scores across the metrics. This implies that the model will be very effective at correctly predicting the actual or true labels for the majority of test cases.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.073},\\\"Recall\\\":{\\\"Model A\\\":92.966},\\\"Precision\\\":{\\\"Model A\\\":91.746}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
        "redeem_code": "N1NQ6-MEHMY-FVQLG_42-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision and Recall. (You should consider the implications of the model's score across each metric. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.201",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 43,
        "narration": "On this ML problem, the model has a recall of 71.74% and a precision score equal to 57.9%. Besides, it has an accuracy of 81.5%. Judging from the scores, the model demonstrates a fairly moderate prediction performance. It has a high chance of mislabeling some test observations drawn from the class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":71.739},\\\"Precision\\\":{\\\"Model A\\\":57.895}}\"",
        "deleted": false,
        "date_submitted": "08/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "JM18F-9N8UX-FM0H6_43-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"3\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 57.9 and Recall of 71.74. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Personal Loan Modelling",
        "id": 44,
        "narration": "According to the table shown, the algorithm achieved almost perfect scores for accuracy (97.99%) and recall (99.19). Besides, it also has a high F1-score and precision score, respectively, equal to 88.17% and 79.36%. Judging by these high scores, we can say the model can confidently generate the true label for a large number of test cases. However, not all C2 predictions are actually true considering the difference between precision and recall scores.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.994},\\\"Recall\\\":{\\\"Model A\\\":99.194},\\\"F1-score\\\":{\\\"Model A\\\":88.172},\\\"Precision\\\":{\\\"Model A\\\":79.355}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "J6R3B-UNXYA-37HMB_44-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Hotel Satisfaction",
        "id": 45,
        "narration": "This ML algorithm achieved almost perfect scores across the Recall, AUC, Accuracy, and Precision evaluation metrics. With the model being trained on a somewhat balanced dataset, it is not surprising to see such high scores. These scores achieved by the model indicate that it can confidently and accurately predict the actual label for a larger number of test cases.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.97},\\\"Recall\\\":{\\\"Model A\\\":91.502},\\\"AUC\\\":{\\\"Model A\\\":97.432},\\\"Precision\\\":{\\\"Model A\\\":92.365}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
        "redeem_code": "BPFG6-VPX65-E5EKP_45-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Real Estate Investment",
        "id": 46,
        "narration": "As shown in the table above, the model has an accuracy of 95.11%, recall of 94.12%, AUC of 96.12%, and a precision score of 85.71%. With such high scores across the metrics, the model is almost certain to make just a few mistakes. That is, it has low misclassification error/rate close to about <acc_diff>. Furthermore, the prediction performance is very impressive considering the fact that it was trained on such an imbalanced dataset.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.11},\\\"Precision\\\":{\\\"Model A\\\":85.71},\\\"Recall\\\":{\\\"Model A\\\":94.12}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
        "redeem_code": "K7LMJ-BDK1T-DNDKJ-46-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 47,
        "narration": "The following are the performance evaluation metrics employed to assess the classification capability of the algorithm: AUC, Accuracy, Recall, and Precision. For the AUC and accuracy, it achieved 98.37% and 94%, respectively. The precision score is 89.61% and an almost perfect recall of 98.57%. Trained on a balanced dataset, the classifier's performance is not that surprising. Overall, this model is likely to have a lower misclassification error as indicated by the scores. This implies that it will be highly effective at correctly predicting the correct class label for several test cases.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":98.57},\\\"Accuracy\\\":{\\\"Model A\\\":94.0},\\\"Precision\\\":{\\\"Model A\\\":89.61},\\\"AUC\\\":{\\\"Model A\\\":98.37}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "NHYBL-BC65X-C4V8P_47-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Air Quality Prediction",
        "id": 48,
        "narration": "For this multi-class classification task (where a given test case is labeled as either C1 or C2 or C3 or C4), the model has close to perfect score across all the evaluation metrics under consideration (that is, Accuracy = 97.54%; Precision = 97.69%; F1-score = 97.32%; and Recall = 96.95%). From the classification performance, it is valid to say this model is very effective at correctly recognizing  test cases drawn from all the class labels with a lower misclassification error rate.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":97.69},\\\"Accuracy\\\":{\\\"Model A\\\":97.54},\\\"F1-score\\\":{\\\"Model A\\\":97.32},\\\"Recall\\\":{\\\"Model A\\\":96.95}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
        "redeem_code": "NKQH7-N6K0K-A1K8U_48-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-5",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Ethereum Fraud Detection",
        "id": 49,
        "narration": "Evaluated based on the metrics Precision, AUC, Accuracy and Recall, respectively, the classifier achieved the scores of 93.2%, 99.34%, 98.17% and 98.56.  Trained on an imbalance dataset, these scores are impressive and very good indicative of the high classification performance of the model. It has a very low false positive error rate as indicated by the very high precision score.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":93.21},\\\"AUC\\\":{\\\"Model A\\\":99.34},\\\"Accuracy\\\":{\\\"Model A\\\":98.17},\\\"Recall\\\":{\\\"Model A\\\":98.56}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
        "redeem_code": "U4PUE-AY3XX-5YVF4-49-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 93.21 and AUC of 99.34. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Flight Price-Range Classification",
        "id": 50,
        "narration": "The evaluation performance score achieved are as follows: (a) Accuracy: 83.15% (b) F2-score: 79.41 (c) Recall: 79.36%  (d) Precision: 79.71%. According to the scores above, the algorithm employed to solve this ML task has a moderately high classification performance and will be able to correctly classify most test samples.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.71},\\\"Accuracy\\\":{\\\"Model A\\\":83.15},\\\"Recall\\\":{\\\"Model A\\\":79.36},\\\"F2-score\\\":{\\\"Model A\\\":79.41}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
        "redeem_code": "X0DG2-168@U-76E11_50-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\",\"Precision\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Recall, F2-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, F2-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Water Quality Classification",
        "id": 51,
        "narration": "According to the table shown, the model achieved an Accuracy of 77.44%, Specificity score of 76.21%, a Sensitivity score (i.e. Recall) equal to 81.25%, and an F1-score of 63.72%. This model trained on an imbalanced dataset has a moderate classification performance hence might misclassify some test samples especially those drawn from the class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.44},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
        "redeem_code": "B4PHL-6Y4AH-VUJ0G-51-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"F1-score\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Specificity, Sensitivity and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 63.72 and Sensitivity of 81.25. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 52,
        "narration": "Trained on a balanced dataset, this model achieves F1-score(77.06%), Precision(68.58%), Recall(87.94%) and Accuracy(79.8%). These scores imply that the model will be somewhat good at separating the test samples into their respective class label. From the accuracy and F1-score, there is a chance that a number of test cases might be mislabeled. For example, according to the recall and precision scores, some C1 examples might be mislabeled as C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"F1-score\\\":{\\\"Model A\\\":77.06},\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Precision\\\":{\\\"Model A\\\":68.58}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "4YE64-BMDAR-RDXWJ-52-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Precision, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Precision, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Cab Surge Pricing System",
        "id": 53,
        "narration": "The classifier enjoys an accuracy of 83.99%, an F1-score of 88.65%, precision equal to 94.18%, and a recall score of 83.74%. For this multi-class problem, a valid conclusion that can be made about the model is that, it has a high classification performance, hence will be able to correctly classify test samples from different class labels.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":88.65},\\\"Precision\\\":{\\\"Model A\\\":94.18},\\\"Recall\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":83.99}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
        "redeem_code": "7XFCM-BRE@6-30CF7-53-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"5\",\"Recall\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 54,
        "narration": "The table shows the scores achieved by the model across the metrics under consideration. For the prediction accuracy metric, the model achieved a score of 69.2%. Sensitivity equal to 51.85%, AUC of 74.06%, and a very low precision score of 35.44%. Due to the fact the model is being trained on an imbalanced dataset, only the recall (sensitivity) and precision scores are important. This model performs poorly on the classification problem. It has a very high false-positive rate, hence will find it difficult to correctly classify test samples, especially those from the class label C2.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44},\\\"Sensitivity\\\":{\\\"Model A\\\":51.85}}\"",
        "deleted": false,
        "date_submitted": "10/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "RE@@2-LBJH8-L6R22_54-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Precision\":\"2\",\"Accuracy\":\"2\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 55,
        "narration": "On this ML classification task, the model scored 50.01% (recall), 62.98% (accuracy) and 69.36% (precision). From the recall and precision, we can see that the model achieves an F1-score of 58.11%. Even though the model was trained on imbalanced data, we can say that the model might find it difficult to accurately identify the labels for test cases drawn randomly from any of the class labels. In summary, we can conclude that this model has low predictive power.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.36},\\\"Recall\\\":{\\\"Model A\\\":50.01},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Accuracy\\\":{\\\"Model A\\\":62.98}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "9V2TG-4J0M5-UHY68_55-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"2\",\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, F1-score, Accuracy and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 50.0 and Accuracy of 62.98. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Credit Card Fraud Classification",
        "id": 56,
        "narration": "On this ML problem, the algorithm employed achieved accuracy equal to 99.95%, with the F1-score, precision, and recall, respectively, equal to 84.32%, 77.23%, and 92.86%. This classification problem is one of the extreme cases of class imbalance, with almost all the examples belonging to the class label C1. Therefore, the accuracy of 99.95% is not a good indicator of how well the algorithm performs across the examples from both classes. It is the F1-score (balance between the recall and precision scores) that is very important here. From the F1-score, we can draw the conclusion that overall the algorithm has moderate performance and will struggle a bit when it comes to examples belonging to the minority class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.95},\\\"Precision\\\":{\\\"Model A\\\":77.23},\\\"F1-score\\\":{\\\"Model A\\\":84.32},\\\"Recall\\\":{\\\"Model A\\\":92.86}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
        "redeem_code": "8583H-9JTAY-4FH7G_56-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Credit Card Fraud Classification",
        "id": 56,
        "narration": "The algorithm's prediction prowess is summarized by the F1-score, precision, and recall, respectively, equal to 84.32%, 77.23%, and 92.86%. Also, the accuracy of predictions is equal to 99.95%. For this classification problem the majority all the examples belong to the class label C1. Hence, making judgments about the overall performance of the algorithm based on the accuracy of 99.95% is not ideal. The overall performance is correctly reflected by the F1-score (balance between the recall and precision scores). Overall, the algorithm has the tendency to predict the majority of examples as C1 even though their actual label is C2. That is, the algorithm has moderate classification performance and will struggle a bit when it comes to examples belonging to the minority class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.95},\\\"Precision\\\":{\\\"Model A\\\":77.23},\\\"F1-score\\\":{\\\"Model A\\\":84.32},\\\"Recall\\\":{\\\"Model A\\\":92.86}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
        "redeem_code": "8583H-9JTAY-4FH7G_56-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"3\",\"Recall\":\"4\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Printer Sales",
        "id": 57,
        "narration": "This classifier was trained on a close-to-balanced dataset and it attains an accuracy of 86.67%; a very high AUC score of 94.03; a Precision score of 83.78, and finally, an F2-score of 87.57%. According to the scores as mentioned, we can see that this model has a high classification performance and as such will be quite good at accurately differentiating between examples from both class labels under consideration.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":94.03},\\\"Precision\\\":{\\\"Model A\\\":83.78},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"F2-score\\\":{\\\"Model A\\\":87.57}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
        "redeem_code": "RWJPN-TUCYN-JK80V_57-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"AUC\":\"5\",\"F2-score\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, AUC and F2-score. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "E-Commerce Shipping",
        "id": 58,
        "narration": "From the metrics table shown, the model attains an accuracy of 67.09%, a marginal or low Specificity of 56.02%; recall score of 82.92% with an F1-score of just 67.47%. The model in general demonstrates a somewhat moderate performance. Besides, scores across the metrics show that it might fail at classifying some examples that are likely difficult to distinguish. Overall, from the F1-scoreand recall scores, we can draw the conclusion that it might have a close to high false positive rate.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
        "redeem_code": "JN@96-EXNET-4JV8W-58-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Specificity\":\"2\",\"Recall\":\"4\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 59,
        "narration": "When trained to assign the label either C1 or C2 to different test cases, the machine learning model's predictive power is characterized by scores across the metrics: precision, accuracy, recall, and F1-score. For the precision metric, it achieved, 91.06%. 91.48% for the recall score with 91.26% as the F1-score. Finally, it has an accuracy of about 91.37%. As shown by the scores, the model has a very high classification performance and as such can be trusted to make valid and correct predictions even for samples that might be difficult to sort out. In summary, the model is shown to be effective and there is a lower chance of misclassification error occurring (i.e. about <acc_diff>%).",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":91.26},\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"Precision\\\":{\\\"Model A\\\":91.06},\\\"Recall\\\":{\\\"Model A\\\":91.48}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "5E1QH-CKT87-M4R81_59-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Real Estate Investment",
        "id": 60,
        "narration": "Evaluated based on the Accuracy, AUC, Precision, and Recall metrics, the model achieved 85.78 (accuracy), 91.96 (AUC), 46.43 (precision), and 92.86 (recall). Since it was trained on an imbalanced dataset, the metrics of greater interest will be precision and recall. The low precision and very high recall score indicate that a lot of cases were labeled as C2. While some of them were true, a lot of them were also from C1.  In conclusion, from these scores, we can draw the conclusion that this model has  moderate performance with a somewhat high false-positive rate given that some examples of the majority class C1 are being misclassified as C2.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"Accuracy\\\":{\\\"Model A\\\":85.78},\\\"Precision\\\":{\\\"Model A\\\":46.43},\\\"AUC\\\":{\\\"Model A\\\":91.96}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
        "redeem_code": "WHAMV-DUCX6-4QGDL-60-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Precision\":\"2\",\"Recall\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 61,
        "narration": "As shown in the metrics table, the model achieved a classification accuracy of 77.12%, recall, and precision scores, respectively, equal to 43.86, and 64.1. This model has low classification performance considering the precision and recall scores. This indicates that it would likely have many examples from the C2 class misclassified as C1. Therefore, it is not very effective for this machine learning problem.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":43.86},\\\"Recall\\\":{\\\"Model A\\\":64.1},\\\"Accuracy\\\":{\\\"Model A\\\":77.12}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "W2CAG-FDLWM-R0JRM-61-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"2\",\"Recall\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Annual Income Earnings",
        "id": 62,
        "narration": "The evaluation metrics employed are AUC, precision, F1-score, and Accuracy. On the AUC, it has a score of 90.02% with accuracy also equal to 85.09%. This model has a moderate F1-score and a precision score of 65.31% and 61.47%, respectively. Only the precision score and F1-score are important to assess the performance of the model. This is because the data was imbalanced. Based on these metrics, we can make the assessment that this model demonstrates moderate classification performance and will likely misclassify a small number of examples drawn from the positive class C2 as C1. However, a balanced precision and recall score is a good indicator of how effective the model could be.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":65.31},\\\"Precision\\\":{\\\"Model A\\\":61.47},\\\"AUC\\\":{\\\"Model A\\\":90.02},\\\"Accuracy\\\":{\\\"Model A\\\":85.09}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
        "redeem_code": "NQG8K-H7YFQ-FLBLH-62-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"F1-score\":\"3\",\"Accuracy\":\"4\",\"AUC\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Suspicious Bidding Identification",
        "id": 63,
        "narration": "On this machine learning classification problem, the model scored an accuracy of 95.9%, a recall and precision scores of 76.19% and 91.43%, respectively. Since the data is imbalanced, the best indicator of the performance of the model on this classification problem is the F1-score which is derived from precision and recall. We can verify that the model has a high F1-score of about 83.12%. According to the F1-score, the model is shown to be effective as there is little chance of cases belonging to class label C1 being classified as C2 (i.e., low false-positive rate). The model is sure about the correctness or preciseness of its prediction decisions.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.19},\\\"Accuracy\\\":{\\\"Model A\\\":95.9},\\\"F1-score\\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":91.43}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"5\",\"Recall\":\"3\",\"Precision\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Food Ordering Customer Churn Prediction",
        "id": 64,
        "narration": "For this classification problem, the ML model has an AUC score of about 89.13%, with an accuracy of 89.74%. However, the metrics of higher interest for this problem are the sensitivity (or the recall) and the precision scores. For these metrics, the model achieved 65.22% (precision) and 78.95% (sensitivity).  As a model trained on an imbalanced dataset, it performed moderately well at classifying examples/samples from both class labels. There is some sort of a fair balance between its recall (sensitivity)  and precision which indicates how good the model could be.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":89.13},\\\"Accuracy\\\":{\\\"Model A\\\":89.74},\\\"Precision\\\":{\\\"Model A\\\":65.22},\\\"Sensitivity\\\":{\\\"Model A\\\":78.95}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
        "redeem_code": "WP0XW-UW7C1-210RB-64-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Sensitivity and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Company Bankruptcy Prediction",
        "id": 65,
        "narration": "The values in the table summarize the prediction performance the model achieved based on the scores across the different evaluation metrics. It has almost perfect scores across all the metrics. The accuracy is 95.19%, specificity of 97.53%, AUC score of 98.4% and sensitivity score of 91.99%. According to the scores achieved, it would be safe to conclude that this model is highly effective at correctly assigning the correct class labels to test cases with little room for misclassification. Actually, from the accuracy the misclassification error rate is only <acc_diff>%.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.19},\\\"Specificity\\\":{\\\"Model A\\\":97.53},\\\"Sensitivity\\\":{\\\"Model A\\\":91.99},\\\"AUC\\\":{\\\"Model A\\\":98.4}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
        "redeem_code": "8P5C3-Q03X1-H8CRK_65-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Specificity and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 98.4 and Accuracy of 95.19. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Air Quality Prediction",
        "id": 66,
        "narration": "Evaluated based on the Recall, F1-score, Accuracy, and Precision, the model achieved 77.42% (Recall), 86.64% (F1-score), 86.5 (Accuracy), and 98.36 (precision). The very high precision and fairly high recall score demonstrate that the model is quite confident about the prediction of the C2 class. From these scores, we can conclude that the model demonstrates a high classification ability and will be able to correctly classify most of the samples belonging to each class label under consideration.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.42},\\\"F1-score\\\":{\\\"Model A\\\":86.64},\\\"Accuracy\\\":{\\\"Model A\\\":86.5},\\\"Precision\\\":{\\\"Model A\\\":98.36}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
        "redeem_code": "2Q88Y-UJPDF-EYHMV_66-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"3\",\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, F1-score, Accuracy and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 98.36 and Recall of 77.42. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Wine Quality Prediction",
        "id": 67,
        "narration": "The classification algorithm achieves 78.87% as the precision score, accuracy of 75.74%, and recall of 75.68%. Looking at the difference between recall and precision, we can draw the assertion that this model is quite confident about the C2 predictions. From these scores, we say that this model is fairly accurate and would be able to correctly predict the true label for test cases from the class labels C1 and C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":75.74},\\\"Recall\\\":{\\\"Model A\\\":75.68},\\\"Precision\\\":{\\\"Model A\\\":78.87}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "4N3LG-KK5HE-A4W1D_67-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 68,
        "narration": "From the table, we can see that the model is characterized by the AUC and accuracy scores of 74.17% and 71.6%, respectively. As for the precision and sensitivity (recall) scores, the model only manages the scores of 50.63% and 55.56%.  Judging based on these scores, the model shows relatively poor classification performance. It will marginally outperform the dummy model that predicts only the majority class label C1 for all test cases. In summary, the performance of the model is not impressive and as such can't be really trusted to always make correct classification predictions.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":50.63},\\\"Accuracy\\\":{\\\"Model A\\\":71.6},\\\"Sensitivity\\\":{\\\"Model A\\\":55.56},\\\"AUC\\\":{\\\"Model A\\\":74.17}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "Y3J5V-6M@EF-EGT4F_68-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Sensitivity\":\"2\",\"AUC\":\"2\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Mobile Price-Range Classification",
        "id": 69,
        "narration": "The learning algorithm trained on this ML task under consideration achieves the classification performance of 89.57% (recall or sensitivity), 89.42% (Precision-score), and 89.4% (accuracy). The high precision and recall scores demonstrate that the model is fairly picky with its C2 predictions but very certain when it does label cases as C2. In summary, e can see that this model has high prediction confidence and can correctly predict the true label for the majority of test cases/samples.",
        "metrics_values": "\"{\\\"Precision-score\\\":{\\\"Model A\\\":89.42},\\\"Accuracy\\\":{\\\"Model A\\\":89.4},\\\"Recall-score\\\":{\\\"Model A\\\":89.57}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
        "redeem_code": "3DT9X-UA4TB-QQMUW-69-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision-score\":\"5\",\"Accuracy\":\"5\",\"Recall-score\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score and Recall-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Water Quality Classification",
        "id": 70,
        "narration": "From the table shown, the model is shown to achieve 76.21% (Specificity), 63.72% (F1-score), and 81.25% (Sensitivity or Recall). In addition, it has an accuracy of  77.44%. The performance of the model in terms of splitting apart examples belonging to class label C2 is relatively moderate as shown by the F1-score and the Sensitivity. For the identification of C1's test sample, it does quite well as shown by the Specificity score. The above assertions are made based on the fact that the model was trained on an imbalanced dataset where the majority of examples belonged to the class label C1.",
        "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":76.21},\\\"F1-score\\\":{\\\"Model A\\\":63.72},\\\"Sensitivity\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":77.44}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
        "redeem_code": "MM3R7-D0LDT-XJ7X2_70-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"3\",\"Sensitivity\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Specificity and Sensitivity. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Company Bankruptcy Prediction",
        "id": 71,
        "narration": "The classification algorithm employed to solve this machine learning task attains the scores 59.06% (sensitivity or recall), 94.96% (Specificity), 84.98% (AUC score), and 71.52% (Accuracy). Based on the sensitivity and Specificity scores, it is obvious that this algorithm will be effective in terms of correctly telling-apart examples belonging to class label C1 and might struggle a bit when classifying examples under the class label C2. The Specificity also shows that the classifier's accuracy is dominated by the correct predictions of the C1's samples.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":84.98},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Specificity\\\":{\\\"Model A\\\":94.96}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
        "redeem_code": "JPLPR-AT2KK-1WJ3V_71-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"3\",\"AUC\":\"4\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Sensitivity, AUC and Specificity. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 72,
        "narration": "On the ML classification task under consideration, the evaluation scores of the learning algorithm are as follows: 78.89% for the F1-score, 89.95% for the precision score metric, a specificity of 91.24%, and an accuracy of 80.17%. With the model trained on a heavily imbalanced dataset, the  F1-score, specificity, and precision scores are the best assessors of the classification performance of the model.  The specificity score shows that this model can relatively pick out examples from C1 from the population with a much higher degree of certainty. The precision score and F1-score also tell us that this model is somewhat confident about its predictions for the test cases belonging to the class label C2.",
        "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":91.24},\\\"Accuracy\\\":{\\\"Model A\\\":80.17},\\\"F1-score\\\":{\\\"Model A\\\":78.89},\\\"Precision\\\":{\\\"Model A\\\":89.95}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "GTN7L-G9WW7-VK@P9_72-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"5\",\"Specificity\":\"5\",\"Accuracy\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Specificity and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 89.95 and Accuracy of 80.17. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Employee Promotion Prediction",
        "id": 73,
        "narration": "With reference to the classification problem's objective, the classifier achieved an accuracy of 93.04%, a recall score of 81.85%, and a very low precision score of 23.69%.  Since the dataset used to train the model was imbalanced, we are only interested in the precision and recall scores. Based on these metrics' scores, the model is shown to have a very high false-positive and as such the confidence in the output prediction of the class label, C2 is very low. On the other hand, there is high confidence pertaining to the prediction output of the majority class label C1.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":23.69},\\\"Accuracy\\\":{\\\"Model A\\\":93.04},\\\"Recall\\\":{\\\"Model A\\\":81.85}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
        "redeem_code": "68Q36-J5XWC-EYL22-73-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Bike Sharing Demand",
        "id": 74,
        "narration": "This classifier achieves almost perfect scores for the Recall (93.76%),  and AUC (95.96%). Besides, for the precision and accuracy scores, the model attains 83.1%, and 88.89%, respectively. Considering all the scores mentioned above, the model is shown to have relatively high confidence in the prediction decisions for the majority of test cases. It has a low false-positive rate.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":88.89},\\\"Precision\\\":{\\\"Model A\\\":83.1},\\\"AUC\\\":{\\\"Model A\\\":95.96},\\\"Recall\\\":{\\\"Model A\\\":93.76}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
        "redeem_code": "2G3WD-T10LW-9C4YD_74-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\",\"AUC\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and AUC. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Ethereum Fraud Detection",
        "id": 75,
        "narration": "Looking at the results table, the model achieved accuracy and AUC scores of 95.84% and 98.01%, respectively. In addition, the precision score and recall (sensitivity) scores respectively are 87.1% and 93.9%. Trained on an imbalanced dataset, the results are quite impressive. The precision and recall scores indicate the model will likely have a high F1-score demonstrating its effectiveness at correctly predicting the class labels for the majority of the test cases. It has high confidence in its prediction outputs.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.84},\\\"Precision\\\":{\\\"Model A\\\":87.1},\\\"AUC\\\":{\\\"Model A\\\":98.01},\\\"Recall\\\":{\\\"Model A\\\":93.9}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
        "redeem_code": "91QCH-3A85T-FNENX-75-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision and AUC? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Food Ordering Customer Churn Prediction",
        "id": 76,
        "narration": "The algorithm trained on this imbalanced dataset achieved a sensitivity (recall) score of 80.01% with a precision score equal to 86.96%. Besides, it has an AUC score of 94.73% and an accuracy score of 93.16%.  The model has a fairly high prediction performance as indicated by the recall (sensitivity) and precision scores. Basically, the model has a lower false-positive rate. Furthermore, if we were to go by the accuracy and AUC scores, we can say it will have a lower chance of misclassifying most test samples.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":86.96},\\\"AUC\\\":{\\\"Model A\\\":94.73},\\\"Sensitivity\\\":{\\\"Model A\\\":80.01},\\\"Accuracy\\\":{\\\"Model A\\\":93.16}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
        "redeem_code": "JCJNF-MQA@Y-RPXJ1_76-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Sensitivity\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-5",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, AUC and Sensitivity? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Cab Surge Pricing System",
        "id": 77,
        "narration": "On this multi-class classification problem, the model has a recall score of 85.82%, an accuracy score of about 82.24%, and a precision score of 87.11%. From the recall and precision, the F1-score achieved by the model is about 86.46%. From these scores, a valid conclusion that could be made here is that this model has a moderate to high performance and can correctly identify the true class label for most test samples drawn from the different class labels C1, C2, and C3.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.46},\\\"Precision\\\":{\\\"Model A\\\":87.11},\\\"Accuracy\\\":{\\\"Model A\\\":82.24},\\\"Recall\\\":{\\\"Model A\\\":85.82}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
        "redeem_code": "W5G1E-7CHWU-1DWB5-77-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\",\"Precision\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Accuracy, F1-score and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, F1-score and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Suspicious Bidding Identification",
        "id": 78,
        "narration": "Evaluation of the classification performance is based on the following evaluation metrics:  F1-score, Recall, Precision, and Accuracy. For the accuracy, the model scored 96.53%, for the precision it scored 91.43% with the recall score equal to 80.03%. According to the recall and precision scores, we can verify that it has an F1-score of about 85.33%.\n Trained on a severely imbalanced dataset, these scores are quite impressive. It has a lower false-positive rate hence the confidence in predictions related to the minority class label C2, is very high. The above conclusion is based on the precision and recall scores. The accuracy though might not be that important when dealing with such imbalanced data offer some form of support to the claims about the confidence level of the model's output predictions.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":80.03},\\\"F1-score\\\":{\\\"Model A\\\":85.33},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":96.53}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
        "redeem_code": "LVLQW-HA20W-DX54K-78-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Recall and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Recall and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Concrete Strength Classification",
        "id": 79,
        "narration": "Trained on a balanced dataset, the model scored almost perfect scores for the AUC (96.34%) and Recall (95.31%) metrics. Furthermore, the accuracy score is 87.74% and the precision score is 79.22%. The model does fairly well at correctly classifying most test cases. As indicated by the precision and recall scores, it should be noted that this model has a tendency of labeling some cases belonging to C1 as C2. In summary, the algorithm has moderately high confidence in its prediction decisions.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Recall\\\":{\\\"Model A\\\":95.31},\\\"AUC\\\":{\\\"Model A\\\":96.34}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "H3HGT-CJFAF-ETP8L_79-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 80,
        "narration": "The classifier scored close to perfect scores across all the metrics (i.e. Precision, AUC, Accuracy and Recall). From the results table, we can see that it scored 94.06% (Precision), 99.42% (AUC), 97.11% (accuracy), and 95.96% (sensitivity/recall). Surprisingly, these scores were achieved even though the dataset was imbalanced.  From the precision and recall scores, we can assert that the learning algorithm is very confident about its prediction decisions for samples belonging to the class label C2. Finally, the accuracy and AUC show that it has a lower misclassification error.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":94.06},\\\"Accuracy\\\":{\\\"Model A\\\":97.11},\\\"Recall\\\":{\\\"Model A\\\":95.96},\\\"AUC\\\":{\\\"Model A\\\":99.42}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "PK731-LG4HB-CRN93_80-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 99.42 and Accuracy of 97.11. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Hotel Satisfaction",
        "id": 81,
        "narration": "The machine learning algorithm trained to solve this classification problem achieved a score of 84.38% for the accuracy, a score of 90.03% (AUC),  82.27% (Precision) and 81.8% (recall). Judging from these scores, the algorithm is shown to be quite effective at correctly choosing the true labels for most test cases. There is a balance between the recall and precision scores hence the confidence in predictions related to the label C2 is high.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":82.27},\\\"Accuracy\\\":{\\\"Model A\\\":84.38},\\\"AUC\\\":{\\\"Model A\\\":90.03},\\\"Recall\\\":{\\\"Model A\\\":81.8}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
        "redeem_code": "7H98A-F4TUL-MR5WP-81-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"AUC\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Accuracy, Precision and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and AUC. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "E-Commerce Shipping",
        "id": 82,
        "narration": "The scores achieved by the model on this classification problem are: (1) accuracy equal to  67.09%. (2) Specificity score of 56.02%. (3) recall (sensitivity) score of 82.92%. (4) F1-score of 67.47%. The model was trained on an imbalanced dataset, therefore, these results indicate the it has a weak prediction power. From the recall and F1-score, we can make the conclusion that this model will have a low precision hence will have a somewhat high false-positive rate. Therefore, it will fail in most cases to correctly identify the examples belonging to the class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
        "deleted": false,
        "date_submitted": "12/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
        "redeem_code": "WBBV0-6LQXX-RHK19-82-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Specificity\":\"3\",\"Recall\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, F1-score and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Health Care Services Satisfaction Prediction",
        "id": 83,
        "narration": "For this classification problem, the model scored 55.56% precision with a moderate F1-score of 60.87%. Besides, it has an accuracy of about 66.91%. Based on the scores above, the model is relatively unreliable in terms of its predictions. Furthermore from  the precision score, it is valid to say the model will have a high false positive rate.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.87},\\\"Precision\\\":{\\\"Model A\\\":55.56},\\\"Accuracy\\\":{\\\"Model A\\\":66.91}}\"",
        "deleted": false,
        "date_submitted": "13/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
        "redeem_code": "AF0DK-KVV7A-P7F3F-83-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, F1-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 66.91 and F1-score of 60.87. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Paris House Classification",
        "id": 84,
        "narration": "Given the table above, we can confirm that the model scored: 83.12% for the recall metric, 69.15% precision score, and an accuracy score of 91.56%. From the recall and precision scores, the model has a fairly high F1-score of 75.49%. The model is fairly confident with its predictions with the samples from the minority class label C2 as indicated by the F1-score. Since the dataset is severely imbalanced, the accuracy score is less significant when judging the classification performance of the model.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":91.56},\\\"Recall\\\":{\\\"Model A\\\":83.12},\\\"Precision\\\":{\\\"Model A\\\":69.15},\\\"F1-score\\\":{\\\"Model A\\\":75.49}}\"",
        "deleted": false,
        "date_submitted": "13/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
        "redeem_code": "QW3LB-DJ51K-F52V7_84-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: F1-score, Accuracy and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 85,
        "narration": "This model scored 88.89% on accuracy metric, almost perfect  Specificity score of 92.61%. In addition, the precision and F1-scores are 89.95%, and 86.96%, respectively. The accuracy score is not important metric for this analysis since the data is quite imbalanced.  Therefore based on the Specificity, precision and F1-score, we can argue that this model will be quite effective in terms of its prediction power for the minority class C2 and the majority class C1.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"Accuracy\\\":{\\\"Model A\\\":88.89}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "3APUV-AXY5G-18Q7M_85-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"F1-score\":\"5\",\"Precision\":\"5\",\"Specificity\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Concrete Strength Classification",
        "id": 86,
        "narration": "For this classification problem, the model scored 91.09% AUC, 74.19% Accuracy, 53.25% precision and the recall of 91.11%. The dataset is pretty balance as such all the metrics here can be used to make valid conclusions about it's classification performance on this ML task. From the Precision and recall score, we can say that this model has a moderate performance will likely make some classification errors in relation to correctly sorting or separating the test cases belonging to the label C2. This assertion or conclusion is supported by the values of the AUC and accuracy.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":53.25},\\\"AUC\\\":{\\\"Model A\\\":91.09},\\\"Accuracy\\\":{\\\"Model A\\\":74.19},\\\"Recall\\\":{\\\"Model A\\\":91.11}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "5DPK5-@LC@T-5YANM-86-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"3\",\"Accuracy\":\"3\",\"Recall\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Job Change of Data Scientists",
        "id": 87,
        "narration": "In the case of this classification task, the model has the scores: Accuracy (77.66%), precision (42.12%), recall (57.09%) and 48.48% (F1-score). With the model trained on an imbalance dataset, the accuracy can be ignored when deciding if the model is effective or  not. As shown by the scores across the F1-score, Precision and Recall, this model performs quite poorly in terms of predictions related to the class label C2. From the precision and recall, we can see that the false positive is higher than the true positive predictions. Even though the accuracy might not be important here, we can also conclude that this model is not different from the dummy model that keeps assigning the same class label, C1, to any given input. That is there is marginal difference between the accuracy of this model and that of the dummy model.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":42.12},\\\"Recall\\\":{\\\"Model A\\\":57.09},\\\"F1-score\\\":{\\\"Model A\\\":48.48},\\\"Accuracy\\\":{\\\"Model A\\\":77.66}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
        "redeem_code": "8B91Q-MH7DL-W06V0-87-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Precision\":\"2\",\"Recall\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, F1-score, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, F1-score, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 88,
        "narration": "On this ML classification task, the model boasts a high accuracy score of 81.5%, a low precision score of 45.61% with a recall score of 81.25%. This model was trained on an imbalance dataset so decisions on the effectiveness of the model should be made based on the recall (sensitivity) and precision. From the scores across these metrics, we can make the conclusion that the model will not be that good at correctly predicting the true labels for a greater number of samples belonging to label C2. Besides, the model marginally outperforms the dummy model that constantly assigns the majority class label (C1) to all given input test cases.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Accuracy\\\":{\\\"Model A\\\":81.5},\\\"Recall\\\":{\\\"Model A\\\":81.25}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "R0@26-@FTMC-EN9A8-88-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"3\",\"Precision\":\"2\",\"Accuracy\":\"3\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 45.61 and Accuracy of 81.5. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Real Estate Investment",
        "id": 89,
        "narration": "With the model trained on a severely imbalanced dataset, it scored the following scores across the metrics Accuracy, Recall, Precision,  and AUC, respectively, 85.78%, 92.86%, 46.43%, and 91.96%. By just looking at the precision and recall scores, this model has a high false-positive rate hence low confidence in the predictions associated with the minority label, C2. On the other hand, It performs quite well as it can correctly choose the true label for the majority of samples related to C1.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":46.43},\\\"AUC\\\":{\\\"Model A\\\":91.96},\\\"Recall\\\":{\\\"Model A\\\":92.86},\\\"Accuracy\\\":{\\\"Model A\\\":85.78}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
        "redeem_code": "C7KA7-BKH5E-Q8JB4_89-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\",\"AUC\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, Recall and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 46.43 and Recall of 92.86. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 90,
        "narration": "The dataset used to train the model was imbalanced with a larger proportion belonging to the class label C1. Therefore, C2 is the minority class here and it happens to be the positive label. Evaluating the model based on the different metrics produced the scores 74.17% (AUC), 55.56% (sensitivity), 50.63% (precision) and 71.6% (accuracy).  From the accuracy and AUC score, we can see that this model doesn't significantly outperform the dummy classifier (which assigns the label C1 to any given input). The model seems to performs poorly on predictions related to the label C2. In summary, this modelis not as effective as desired and is likely to have low confidence in its prediction decisions.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":55.56},\\\"AUC\\\":{\\\"Model A\\\":74.17},\\\"Precision\\\":{\\\"Model A\\\":50.63},\\\"Accuracy\\\":{\\\"Model A\\\":71.6}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "XU2TE-HKXPR-X9RAK-90-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Sensitivity\":\"3\",\"AUC\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC, Accuracy and Sensitivity? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Personal Loan Modelling",
        "id": 91,
        "narration": "According to the metrics table, this model scored 77.15% (F1-score), 91.96% (recall), 96.29% (accuracy) and finally, a moderate precision of 66.45% on this machine learning problem under consideration here.  Not much information is given about the distribution of the dataset across the two class labels however, judging by the values, the model is shown to be fairly accurate with its prediction decisions for the majority of test cases. However, caution should be taken when dealing with prediction outputs related to the class label C2. This is due to the score achieved for the precision evaluation metric.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":91.96},\\\"Accuracy\\\":{\\\"Model A\\\":96.29},\\\"Precision\\\":{\\\"Model A\\\":66.45},\\\"F1-score\\\":{\\\"Model A\\\":77.15}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "N@LRQ-V33DP-19MDB_91-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"3\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and Precision? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Employee Promotion Prediction",
        "id": 92,
        "narration": "The learning algorithm explored here has high accuracy (93.04%) and recall (81.85%) scores, However, it scored poorly in terms of its precision (23.69%). These scores were achieved on an imbalanced dataset. This implies that the model has a very low confidence in terms of its C2 predictions. This is based on the precision and recall (also known as sensitivity) score achieved.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":81.85},\\\"Accuracy\\\":{\\\"Model A\\\":93.04},\\\"Precision\\\":{\\\"Model A\\\":23.69}}\"",
        "deleted": false,
        "date_submitted": "14/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
        "redeem_code": "M@R8U-71VBP-KWJML-92-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"5\",\"Recall\":\"4\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.120.217.114",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Air Quality Prediction",
        "id": 93,
        "narration": "Trained to assign the class label C1, C2, C3 and C4 to any given input example, the model achieved Precision, Recall,  F1-score, and Accuracy metric scores of 97.96%, 96.95%, 97.32%, and  97.54%, respectively. As shown above, the model achieved almost perfect scores across the different evaluation metrics. This demonstrates that this model will be very effective at correctly outputing the true label for any given input test case.  The confidence of its prediction decision is very high.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.54},\\\"Recall\\\":{\\\"Model A\\\":96.95},\\\"F1-score\\\":{\\\"Model A\\\":97.32},\\\"Precision\\\":{\\\"Model A\\\":97.69}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>The distribution of the data across the class labels C1, C2, C3, and C4 are 32.22%, 29.27%, 27.91% and 10.6% .",
        "redeem_code": "TUB0K-C0KM4-QEV3G-93-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
        "model_name": "Model-5",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Wine Quality Prediction",
        "id": 94,
        "narration": "Trained to classify any given input as either C1 or C2, this model has an accuracy of 74.26%, precision score and recall score of 73.71% and 76.21%, respectively. The classification performance of the model is fairly high with a clear balance between the precision and recall scores. The model is relatively confident about its prediction decisions for example cases related to class label C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71},\\\"Recall\\\":{\\\"Model A\\\":76.21}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "M7TKQ-Q9KX2-E9AFB_94-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall and Precision. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Flight Price-Range Classification",
        "id": 95,
        "narration": "Under this classification problem, the model was evaluated based on its scores across the following metrics: Accuracy, Recall, F2-score and Precision. With respective to the accuracy, the model scored 80.23%. For the precision and recall (sometimes referred to as the sensitivity score), the model scored 76.77%, 74.53%. The F2-score computed based on the recall and precision scores is equal to 74.57%. The model performs fairly well in terms of correctly predicting the true label for test cases related to any of the class labels under consideration. In summary, we can be assured that this model will be able to assign the correct label to the majority of the test examples.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
        "redeem_code": "RTUJ1-JBLJR-EH6C4-95-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"F2-score\":\"4\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Recall and Precision? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 96,
        "narration": "Across the following metrics: F1-score, Specificity, Accuracy and Precision, the model scored 57.94%, 70.46%, 60.78%, and 65.61%, respectively. Trained on an imbalanced dataset, the scores achieved by the model are not that impressive. Considering the accuracy score, this model performed poorly compared to the dummy model that keeps assigning the majority class label C1 to any given test case. However, due to the distribution of the data across the two class labels, the F1-score and precision metrics are more suitable for the analysis. Finally, the model has a moderate confidence regarding the C2 prediction decision for the test samples.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":57.94},\\\"Precision\\\":{\\\"Model A\\\":65.61},\\\"Specificity\\\":{\\\"Model A\\\":70.46},\\\"Accuracy\\\":{\\\"Model A\\\":60.78}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "0KUNK-4QRGH-44K9M-96-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Specificity\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"3\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Specificity, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Specificity, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Suspicious Bidding Identification",
        "id": 97,
        "narration": "Evaluated based on the metrics Recall, Precision, Accuracy and F1-score, the model achieved the scores  94.12%, 91.43%, 98.42% and 92.75%, respectively on this classification problem. Relatively, the classification performance of the model is very high. This implies that for the majority of test cases, the confidence in the final prediction decision will be very high irrespective of the output class label.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
        "redeem_code": "QJ48F-2T7X5-AQ0KC-97-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Ethereum Fraud Detection",
        "id": 98,
        "narration": "The ML algorithm was trained on this task to predict the class labels C1 and C2. The evaluation metrics employed to assess its classification power were  Recall, Accuracy, Precision and AUC. With the accuracy and AUC scores of  95.58, and 98.04, respectively, it scored 92.16% (for the recall/sensitivity) and  87.78% (precision). Since the dataset was imbalanced, it will be wise to analyze the performance based on the balance between the Recall and precision. The recall and precision are both high hence we can conclude that the learning algorithm has a lower false positive rate, hence, the prediction of the class label C2 for any given test example is likely to be correct. Basically, we can trust the model to a certain degree to make the best prediction decision for the majority of test samples.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.16},\\\"Accuracy\\\":{\\\"Model A\\\":95.58},\\\"AUC\\\":{\\\"Model A\\\":98.04},\\\"Precision\\\":{\\\"Model A\\\":87.78}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
        "redeem_code": "2JQ1J-TJQAL-DYGW6_98-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\",\"Precision\":\"4\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Accuracy and AUC? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Job Change of Data Scientists",
        "id": 100,
        "narration": "The learning algorithm's  recall score is 56.22% , precision score is 35.29%, and accuracy score of 77.0% on this classification task. The F1-score derived from the precision and recall is just 43.36%. From the distribution of the dataset between the two class labels (C1 and C2), we can verify that this algorithm's performance will be identical to the random classifier that always assigns the class label C1 to any given test case. The model has a very low precision and recall scores hence will fail to correctly classify the majority of the cases belonging to the minority label C2. This assertion is further supported by the trade-off score, F1-score.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":35.29},\\\"Accuracy\\\":{\\\"Model A\\\":77.0},\\\"Recall\\\":{\\\"Model A\\\":56.22},\\\"F1-score\\\":{\\\"Model A\\\":43.36}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
        "redeem_code": "10A60-N8DAW-QB0HF-100-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"Recall\":\"2\",\"Accuracy\":\"2\",\"F1-score\":\"2\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Insurance Churn",
        "id": 101,
        "narration": "When trained on the given imbalanced dataset, the model has the scores 34.14%, 92.22%, 66.92%, and 90.46% across the metrics Precision, AUC, Recall and Accuracy, respectively. The precision and recall scores show how poor the performance of the model at correctly assigning C2 is. The model has high false positive rate hence the prediction confidence rated to the minority class label C2 is low. Even with the high accuracy and AUC scores, this model can't be trust when it comes to the test cases belonging to C2.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":34.14},\\\"AUC\\\":{\\\"Model A\\\":92.22},\\\"Recall\\\":{\\\"Model A\\\":66.92},\\\"Accuracy\\\":{\\\"Model A\\\":90.46}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
        "redeem_code": "MJF2R-9QC89-AV7KM_101-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"AUC\":\"5\",\"Recall\":\"3\",\"Accuracy\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, Recall and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Tic-Tac-Toe Strategy",
        "id": 102,
        "narration": "Evaluated on the metrics AUC, accuracy, precision, and F1-score, the classification algorithm achieved close to perfect scores 99.83%, 98.61%, 95.92%, and 97.92%, respectively, on the given ML task. The high values across these metrics indicate that this model can effectively and correctly identify the true labels for the majority of the test cases and the confidence-level in its predictions is very high.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":97.92},\\\"AUC\\\":{\\\"Model A\\\":99.83},\\\"Precision\\\":{\\\"Model A\\\":95.92},\\\"Accuracy\\\":{\\\"Model A\\\":98.61}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
        "redeem_code": "7EN31-0RN@5-HHU7F_102-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Precision, Accuracy and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Australian Credit Approval",
        "id": 103,
        "narration": "The model trained on this ML task scores 91.11%,  84.78%, 84.91% and 77.59%, respectively, across the metrics AUC, Accuracy, Precision and Recall. The training dataset was fairly balanced between the two class labels C1 and C2. From these scores, we can conclude that the learning algorithm employed to solve the ML task is very effective and confident with the majority of its prediction decisions. The model outperforms the dummy model that always assign C1 to any given input sample by a larger margin.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"Accuracy\\\":{\\\"Model A\\\":84.78},\\\"AUC\\\":{\\\"Model A\\\":91.11}}\"",
        "deleted": false,
        "date_submitted": "15/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
        "redeem_code": "40EBJ-MM7P2-H4KJD_103-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 91.11 and Precision of 84.91. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "185.201.60.254",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Wine Quality Prediction",
        "id": 104,
        "narration": "The classification performance on this ML task as evaluated based on the Precision, Accuracy and Recall are 73.71%, 74.26%, and 76.21%, respectively. These scores are high indicating that this model is somewhat effective and  can accurately identify most of the test cases with small margin of error.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.21},\\\"Accuracy\\\":{\\\"Model A\\\":74.26},\\\"Precision\\\":{\\\"Model A\\\":73.71}}\"",
        "deleted": false,
        "date_submitted": "16/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "8V93K-VY676-5J20J_104-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Personal Loan Modelling",
        "id": 105,
        "narration": "On the machine learning problem under consideration, the model scored 90.32% (precision), 94.6% (F1-score), 99.29% (recall) and 99.03% (Accuracy). These scores are very high. Based on the above performance scores, we can conclude that the model is very effective and can accurately distinguish the majority of the test samples with a small margin of misclassification error. Besides, \nthe precision and recall scores, it is obvious that the model has a very low false positive rate hence is very confident about its prediction decisions.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":99.03},\\\"Precision\\\":{\\\"Model A\\\":90.32},\\\"F1-score\\\":{\\\"Model A\\\":94.6},\\\"Recall\\\":{\\\"Model A\\\":99.29}}\"",
        "deleted": false,
        "date_submitted": "16/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "NLYKP-HQY57-K772A_105-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\",\"Accuracy\":\"5\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Card Fraud Classification",
        "id": 106,
        "narration": "With a larger proportion of the dataset belonging to the class label C1, the model evaluated based on the following metrics precision, F1-score, accuracy and recall, respectively, achieved 63.37%, 73.56%, 99.92%, and 87.67%. According to the scores, one can conclude that the performance of the model is not impressive. The accuracy score indicates this model is not that different from the dummy model that always assigns the same label (C1) to any given input example. However, only the precision, recall and F1-score are important here for this assessment. From these scores, we can conclude that this model has a moderate false positive rate and the prediction output of C2 might need further investigation.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":73.56},\\\"Precision\\\":{\\\"Model A\\\":63.37},\\\"Accuracy\\\":{\\\"Model A\\\":99.92},\\\"Recall\\\":{\\\"Model A\\\":87.67}}\"",
        "deleted": false,
        "date_submitted": "16/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
        "redeem_code": "R632M-@BR@0-QWQQ0_106-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Recall\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, F1-score, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 63.37 and Recall of 87.67. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Annual Income Earnings",
        "id": 107,
        "narration": "The performance of the classifier/model on this binary classification task was assessed based on the Precision, AUC, F1-score and Accuracy scores.  The accuracy score is  85.11% and  90.07% for the AUC  metric. Furthermore, the precision and F1-score are 63.95% and 66.23%, respectively. From the  F1-score, we can estimate that the recall score will be identical to the precision score. Therefore saying the model has a low false positive classification is a valid statement. Overall, we can conclude that this model achieved a moderate performance hence can accurately classify a decent number of test cases.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"Accuracy\\\":{\\\"Model A\\\":85.11}}\"",
        "deleted": false,
        "date_submitted": "16/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
        "redeem_code": "@6Q1G-9P3P4-QFPND_107-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"AUC\":\"4\",\"F1-score\":\"3\",\"Accuracy\":\"4\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, AUC, F1-score and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, AUC, F1-score and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Health Care Services Satisfaction Prediction",
        "id": 109,
        "narration": "The performance of the model on this classification problem as evaluated based on F1-score, Accuracy, and Precision scored: 66.18%, 60.32% and 62.3%, respectively. A valid conclusion is: the model has a moderate classification performance hence is likely to misclassify a significant number of test cases.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":62.3},\\\"Accuracy\\\":{\\\"Model A\\\":66.18}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
        "redeem_code": "8XW97-L043D-8HY7Q_109-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 110,
        "narration": "The classification performance of the ML algorithm explored on this ML task can be summarized as: Recall (81.25%), low Precision (45.61%), and Accuracy (81.5%). Since the dataset is imbalanced, we can conclude that the model has moderately low classification performance as the difference between the recall and precision indicates there is a high false positive rate. Hence predictions output of label C2 should be taken with a grain of salt.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":45.61},\\\"Recall\\\":{\\\"Model A\\\":81.25},\\\"Accuracy\\\":{\\\"Model A\\\":81.5}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "WN6X6-PL20R-937TG-110-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"2\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Suspicious Bidding Identification",
        "id": 111,
        "narration": "The classifier or algorithm attains very high scores across all the metrics under consideration. Specifically, the recall score of 94.12%, the accuracy score is 98.42%, precision score of 91.43% and F1-score of 92.75%. Judging by these scores attained, it is fair to conclude that this model can accurately distinguish several test cases with little  misclassification error. Besides, the F1-score indicates the model's classification confidence of output predictions related to label C2 is very high.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
        "redeem_code": "J@PN2-LPKE4-NMUMQ_111-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"Recall\":\"5\",\"F1-score\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Customer Churn Modelling",
        "id": 112,
        "narration": "On this ML problem, the model's performance was evaluated as accuracy (83.56%), precision (45.23%), sensitivity score (76.63%) and 56.89% for the F1-score. The model's prediction performance according to the scores above can be summarized as moderately low (weak) given the difference between the precision, and recall scores.  There is a high false positive rate as a number of samples belonging to class label C1 are likely to be misclassified as C2.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":76.63},\\\"Accuracy\\\":{\\\"Model A\\\":83.56},\\\"Precision\\\":{\\\"Model A\\\":45.23},\\\"F1-score\\\":{\\\"Model A\\\":56.89}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
        "redeem_code": "QTDRK-2R61C-KV85W_112-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"2\",\"F1-score\":\"3\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Recall, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 113,
        "narration": "Evaluated based on the accuracy, recall, precision and AUC, the ML algorithm scored 92.78%, 81.15%,  98.02%, and 96.38%, respectively on this classification problem where a given input sample is classified under either class C1 or class C2. These results/scores are very impressive based the fact that the dataset was imbalanced. With such high scores for precision and recall, the classification performance of this model can be summarized simply as almost perfect as only a small number of samples are likely to be misclassified. This is a very model with high confidence in its prediction decisions related to the two-class labels under consideration.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":98.02},\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":81.15},\\\"AUC\\\":{\\\"Model A\\\":96.38}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "H@PTU-6AXJA-Q9Q5R_113-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"4\",\"Accuracy\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, AUC and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Airline Passenger Satisfaction",
        "id": 114,
        "narration": "Trained on somewhat balanced dataset, the model scores 97.91% (AUC), 93.2% (accuracy), 93.12% (recall) and 91.26% (precision score). These results/scores are very impressive as one can conclude that this model is almost perfect with higher confidence in its prediction decisions. In summary, only a  small number of test cases are likely to be misclassified as indicated by the accuracy, recall and precision.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Precision\\\":{\\\"Model A\\\":91.26},\\\"Accuracy\\\":{\\\"Model A\\\":93.2},\\\"Recall\\\":{\\\"Model A\\\":93.12}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
        "redeem_code": "L3800-W0KMY-C14ET_114-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 93.2 and Recall of 93.12. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Employee Attrition",
        "id": 115,
        "narration": "The evaluation scores achieved by the model on this ML classification problem as shown in the table are: Accuracy (86.72%), Recall (94.12%), AUC (85.39%) and Precision (32.65%). On this imbalanced dataset classification problem, these scores are lower than expected indicating how poor the model is at correctly identifying the true class label for the majority of test cases related to label C2. The above conclusion is drawn by simply looking at the precision, recall and distribution of the data across the two class labels.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":86.72},\\\"AUC\\\":{\\\"Model A\\\":85.39},\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"Precision\\\":{\\\"Model A\\\":32.65}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
        "redeem_code": "MD6TR-AYUX6-@H3RX_115-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Recall\":\"4\",\"AUC\":\"3\",\"Precision\":\"1\"}",
        "model_name": "Model-3",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 86.72 and Recall of 94.12. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Broadband Sevice Signup",
        "id": 116,
        "narration": "On this imbalanced classification problem, this learning algorithm has an accuracy of  96.58%, a recall score, and a precision score equal to 96.78% and 95.72%, respectively. Judging by the scores achieved, we can conclude that this model has a very high classification performance and will be very effective at correctly predicting the labels for the majority of the test cases. This is because from the precision score of 96.78% with the recall score of 95.72%, the confidence in the predictions related to any of the class labels is very high.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":95.72},\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Accuracy\\\":{\\\"Model A\\\":96.58}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
        "redeem_code": "Y7FKM-JE0EL-KY8G3-116-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 117,
        "narration": "On this classification with a balanced distribution of the data between the class labels, the model achieves high scores across the metrics under consideration. For example, the accuracy is 94.0% with the AUC score equal to 98.37%.  These scores show how good the model is when predicting the true label for the majority of the test cases related to any of the class labels. Furthermore, the high precision and recall scores of 89.61% and 98.57%, respectively, show that there is high confidence in predictions related to the label C2. In summary, there is a lower chance of misclassification.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":98.57},\\\"AUC\\\":{\\\"Model A\\\":98.37},\\\"Precision\\\":{\\\"Model A\\\":89.61},\\\"Accuracy\\\":{\\\"Model A\\\":94.0}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "T@9UM-PJLHE-EEWN8_117-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"5\",\"Accuracy\":\"5\"}",
        "model_name": "Model-1",
        "narrator": 45,
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 94.0 and AUC of 98.37. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Mobile Price-Range Classification",
        "id": 118,
        "narration": "In view of the classification objective under consideration, the model attains high scores across all the evaluation metrics. For the accuracy, it scored 96.0%, 95.98% for the precision-score and 96.08% recall-score.  It is fair to conclude that the classification performance/power of this model is very impressive and the chances of misclassifying any given input test case is very low.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision-score\\\":{\\\"Model A\\\":95.98},\\\"Recall-score\\\":{\\\"Model A\\\":96.08}}\"",
        "deleted": false,
        "date_submitted": "18/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
        "redeem_code": "WY9L6-W@@56-2Y9LY_118-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall-score\":\"5\",\"Accuracy\":\"5\",\"Precision-score\":\"5\"}",
        "model_name": "Model-4",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall-score, Accuracy and Precision-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Accuracy and Precision-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Airline Passenger Satisfaction",
        "id": 120,
        "narration": "The algorithm employed to separate the test cases the distinct classes (C1 and C2) scores highly across all metrics; scoring 89.69% for Accuracy, 88.39% for Recall, 87.83% for Precision and 95.52% for AUC 89.59% accuracy implies that 89.59% of all predictions made were correct. An AUC of 95.52% means that the model is well balanced and is able to effectively tell-apart the observations under positive and negative classes.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.83},\\\"Recall\\\":{\\\"Model A\\\":88.39},\\\"AUC\\\":{\\\"Model A\\\":95.52},\\\"Accuracy\\\":{\\\"Model A\\\":89.59}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
        "redeem_code": "TQ5Y5-9MUQU-07D2B_120-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"4\",\"AUC\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 89.59 and AUC of 95.52. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 121,
        "narration": "An accuracy of 96.0%, precision of 94.8%, recall of 97.33% and AUC of 98.59% was achieved. The model attained a very high performance across all the evaluation metrics. Its predictions can be treated as reliable.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Recall\\\":{\\\"Model A\\\":97.33},\\\"Precision\\\":{\\\"Model A\\\":94.8}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "99Q5J-CEDC7-QMV7K_121-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 122,
        "narration": "For the metrics Precision, Accuracy, F1-score and Specificity, the model scored 89.95%, 80.17%, 78.79% and 91.24% respectively A very high precision and specificity indicate good performance in predicting the negative class, but a lower accuracy and F1-score indicate that the model was less able to predict the positive, minority class.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":78.89},\\\"Accuracy\\\":{\\\"Model A\\\":80.17},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Specificity\\\":{\\\"Model A\\\":91.24}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "BY7EL-9E79H-D5T1X_122-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"3\",\"F1-score\":\"4\",\"Specificity\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Annual Income Earnings",
        "id": 123,
        "narration": "We achieved the following performance values using the model: Accuracy 87.27, AUC 92.32, Precision 67.18, F1-score of 70.68 on this classification task. Despite the high accuracy and AUC, the low precision shows that the model gets many false positives. This is not surprising given the dataset imbalance, with only 24% of the data belonging to class C2 (positive), yet it has to be taken into consideration when deploying the model.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":70.68},\\\"AUC\\\":{\\\"Model A\\\":92.32},\\\"Precision\\\":{\\\"Model A\\\":67.18},\\\"Accuracy\\\":{\\\"Model A\\\":87.27}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
        "redeem_code": "4EPVC-WGABT-TNE89-123-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"F1-score\":\"3\",\"AUC\":\"4\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, AUC and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Health Care Services Satisfaction Prediction",
        "id": 124,
        "narration": "The F1-score, accuracy and precision are 60.8%, 63.97% and 60.32%, respectively. The given F1-score and accuracy scoring is indicative of a model with fairly good signs of being accurate and precises in determining C1 and C2. However, the models only perform decently well, with still room for improvement, and with similar precision and accuracy scores suggesting a combined issue with the model.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
        "redeem_code": "RGKYV-ND62W-88LR8-124-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"F1-score\":\"3\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, F1-score and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 60.8 and Accuracy of 63.97. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Hotel Satisfaction",
        "id": 125,
        "narration": "An AUC of 88.67, accuracy of 82.7, recall of 77.52 and precision of 84.66 was achieved by the model. With all the metrics being of a similar value, the model performs evenly across the two categories. Nonetheless, the achieved scores are sub-optimal and more research is needed to improve the models performance.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"AUC\\\":{\\\"Model A\\\":88.67},\\\"Recall\\\":{\\\"Model A\\\":77.52}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
        "redeem_code": "TE827-GEXW7-1X90P_125-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"3\",\"Recall\":\"3\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 126,
        "narration": "This model did not perform well, with very low F1-score (56.5%) and precision (50.81%) and only marginally better recall (63.64%) and accuracy (71.04%). The F1-score of 56.5% is a good indicator of an overall non-effective performance from this model. A precision of only 50.81% shows that it has almost no ability to identify the positive class and a moderate accuracy is mostly down to the class imbalance.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Precision\\\":{\\\"Model A\\\":50.81},\\\"Recall\\\":{\\\"Model A\\\":63.64},\\\"F1-score\\\":{\\\"Model A\\\":56.5}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "B5DU9-75@TN-U8JTL-126-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"1\",\"Recall\":\"1\",\"Precision\":\"1\",\"Accuracy\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-6",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Recall, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Recall, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 127,
        "narration": "The machine learning algorithm employed to solve the task boasts an accuracy of 77.0%, yet its precision is only 43.86%, while the recall is 64.1%. Despite the moderately high accuracy of the model, its low precision and recall suggest that its prediction is not very trustworthy. This is most likely caused by the class imbalance, where the model gains a lot of its accuracy from being biased towards predicting negatives.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":64.1},\\\"Precision\\\":{\\\"Model A\\\":43.86},\\\"Accuracy\\\":{\\\"Model A\\\":77.0}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "E1BNU-C9N3V-B8YY0_127-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"3\",\"Recall\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Flight Price-Range Classification",
        "id": 128,
        "narration": "The accuracy of the model is moderately high, with precision, recall, and F2-score following marginally behind however overall the model's performance can be considered favorably in classifying a large number of test samples.  The model has overall very good performance with achieving high F2-score indicating that as recall or accuracy is weighted more significantly, it is suggestive that the model is good at determining correct class labels most of the time. The precision of 76.77 is below the 80.23 of accuracy, albeit very close together, however suggesting the model is struggling to perform well on the precision metric and may provide an avenue for improvement.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":76.77},\\\"Recall\\\":{\\\"Model A\\\":74.53},\\\"Accuracy\\\":{\\\"Model A\\\":80.23},\\\"F2-score\\\":{\\\"Model A\\\":74.57}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>40.03% of the data belong to class C1, 39.81% belong to class C2 and 20.16% belong to class C3.",
        "redeem_code": "4@61G-707H5-L5GCQ-128-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\",\"F2-score\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Recall, Accuracy and F2-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F2-score of 74.57 and Precision of 76.77. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Australian Credit Approval",
        "id": 129,
        "narration": "The algorithm trained on this task was able to achieve 84.06% accuracy, 74.6% recall, 88.68% precision and 92.21% auc. The algoritm was fairly effective with an accuracy of 84.06% on this somewhat balanced dataset providing a good indicator of the overall prediction capability. Scoring 88.68% precision means that the false positive rate was only <preci_diff>.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.68},\\\"Accuracy\\\":{\\\"Model A\\\":84.06},\\\"AUC\\\":{\\\"Model A\\\":92.21},\\\"Recall\\\":{\\\"Model A\\\":74.6}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
        "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Recall\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 130,
        "narration": "On this balanced dataset the model was a fairly good performer/classifier (Accuracy 79.8%, F1-score 77.06%) but was more effective at catching positive cases (recall 87.94%) than it was at avoiding false negatives (precision 68.58%). This model scored 79.8% accuracy which implies a moderately good performance overall, however when looking at the precision (68.58%) as well it implies that the model is not very effective at avoiding false negatives.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":77.06},\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Precision\\\":{\\\"Model A\\\":68.58}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "60Y44-0KFAL-V7VYR_130-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"F1-score\":\"3\",\"Recall\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and Precision? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Job Change of Data Scientists",
        "id": 131,
        "narration": "The classification algorithm has moderately high accuracy however precision is low thereby suggesting a flaw in the model, this is apparent in an F1-score of 46.98. The model has fairly high accuracy with good recall score, however, it has an overall low precision and therefore is an area that strongly requires improvement before deployment. The F1-score of 46.98 is apparent of this low precision score of 40.17 further providing evidence of the model inability to provide values which are precise, albeit highly accurate",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":77.38},\\\"Recall\\\":{\\\"Model A\\\":56.58},\\\"F1-score\\\":{\\\"Model A\\\":46.98},\\\"Precision\\\":{\\\"Model A\\\":40.17}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
        "redeem_code": "WHN4F-V7A3N-8UWGM_131-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Annual Income Earnings",
        "id": 132,
        "narration": "This model has scored AUC of 90.07%, precision of 63.95%, F1-score of 66.23% and accuracy of 85.11%. Considering this dataset is very imbalanced, a high accuracy of 85.11% and a high auc of 90.07% is less impressive. An F1-score of 66.23%, which is similar to precision (63.95%), indicates an overall poor performance from this model.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.11},\\\"AUC\\\":{\\\"Model A\\\":90.07},\\\"F1-score\\\":{\\\"Model A\\\":66.23},\\\"Precision\\\":{\\\"Model A\\\":63.95}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
        "redeem_code": "7Q3YE-NAQD3-225D7_132-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"4\",\"Precision\":\"2\",\"F1-score\":\"2\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, F1-score and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 85.11 and F1-score of 66.23. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 133,
        "narration": "On this classification task, the model was evaluated based on the Recall, accuracy, AUC and precision scores. Recall of 93.18% and a precision score 81.19  with an accuracy of 92.78%  suggest the model is less precise but it is more accurate. This assertion is supported by the AUC with 96.03, however, the model is good at analyzing the dataset for this classification task/problem.  The overall performance of the model is capturing the accuracy of the dataset is considered high at 92.78 however this value is decreased by the precision value of 81.19. This suggest that the model is accurately able to identify true positive cases however the reduction seen in precision suggest that it produces errors as a result of this.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"Recall\\\":{\\\"Model A\\\":93.18},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"AUC\\\":{\\\"Model A\\\":96.03}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "V49AX-9X0AW-A81HD_133-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 81.19 and Accuracy of 92.78. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 134,
        "narration": "Recall of 93.18 and accuracy of 92.78 with a precision value 81.19 suggest the model is more accurate than it is precise, this value is backed up by the AUC with 96.03 however overall the model is good at analyzing the dataset.  The overall performance of the model is capturing the accuracy of the dataset is considered high at 92.78 however this value is reduced by the precision value of 81.19. This suggests that the model is accurately able to identify true positive cases however the reduction seen in precision suggests that it produces some misclassification errors as a result of this.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.78},\\\"AUC\\\":{\\\"Model A\\\":96.03},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"Recall\\\":{\\\"Model A\\\":93.18}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "J42KL-24QMR-W656D_134-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 81.19 and Accuracy of 92.78. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Paris House Classification",
        "id": 135,
        "narration": "This dataset is very imbalanced, however this model was still able to achieve high scores of 78.64%, 93.38%, 88.94% and 83.48% for recall, accuracy, precision and F1-score respectively An accuracy of 93.38% means that 93.38% of all predictions were correct, however in an imbalanced dataset such as this, a high accuracy is less indicative of overall performance. A high precision of 88.94% shows a low false positive rate of <preci_diff> and a high recall of 78.64% means a low false negative rate also. This is summarised with an F1-score of 83.48% which is an average of recall and  precision.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":93.38},\\\"Recall\\\":{\\\"Model A\\\":78.64},\\\"Precision\\\":{\\\"Model A\\\":88.94},\\\"F1-score\\\":{\\\"Model A\\\":83.48}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
        "redeem_code": "B92UV-6LCVQ-AA1P5_135-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"F1-score\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Accuracy, Precision and F1-score. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Employee Promotion Prediction",
        "id": 136,
        "narration": "The classification algorithm is reporting very highly for recall and accuracy however very low in precision suggesting a large amount of true positive however also a large quantity of false positives.  The model is very highly accurate to the dataset at 94.15 which entails that most test cases would have  been accurately identified/classified. However, the very low precision score of 32.8 suggest that a large quanity of test cases maybe identified prematurely or not at all suggesting a major flaw in the model.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15},\\\"Recall\\\":{\\\"Model A\\\":95.92}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
        "redeem_code": "0DFX1-G18TD-H9Y8L_136-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"1\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 32.8 and Accuracy of 94.15. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Suspicious Bidding Identification",
        "id": 137,
        "narration": "Precision (91.43%), accuracy (98.42%), F1-score (92.75%) and recall (94.12%) scores indicate a very effective model all round. Despite an imbalanced dataset, this model is still able to achieve a very good performance. 98.42% of overall predictions were correct and an F1-score of 92.75% indicate a very balanced as well as high scoring model.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":94.12},\\\"F1-score\\\":{\\\"Model A\\\":92.75},\\\"Precision\\\":{\\\"Model A\\\":91.43},\\\"Accuracy\\\":{\\\"Model A\\\":98.42}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 89.32% of the data belonging to class C1 and 10.68% belonging to class C2",
        "redeem_code": "GJ502-4LTWD-NHGHY-137-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"F1-score\":\"5\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Insurance Churn",
        "id": 138,
        "narration": "On this extremely imbalanced dataset, a high auc (90.05%) and accuracy (90.43%) mean little. Very low recall and precision scores of 66.83% and 33.76% respectively indicate a very ineffective model overall. An AUC of 90.05% means that the model can fairly accurately make out which observation belongs to the positive and negative classes, although it is not the best metric for total judgement.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":66.83},\\\"Precision\\\":{\\\"Model A\\\":33.76},\\\"AUC\\\":{\\\"Model A\\\":90.05},\\\"Accuracy\\\":{\\\"Model A\\\":90.43}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 88.3% of the data belonging to class C1 and 11.7% belonging to class C2",
        "redeem_code": "FCCFM-V7EUT-A4@@5-138-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"3\",\"Accuracy\":\"4\",\"Recall\":\"2\",\"Precision\":\"1\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 66.83 and AUC of 90.05. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 139,
        "narration": "The learning algorithm employed scores very highly across all metrics: F1-score 92.61%, Accuracy 92.74%, Recall 93.26%, Precision 91.97% on this ML classification task. This model is a very effective performer all round: an F1-score of 92.61% is defined as the mean of recall (93.26%) and precision (91.97%), so therefore in this case the model has shown to be very effective. The dataset is balanced, so therefore a very high accuracy of 92.74% is a good measure of very good performance.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":92.61},\\\"Recall\\\":{\\\"Model A\\\":93.26},\\\"Accuracy\\\":{\\\"Model A\\\":92.74},\\\"Precision\\\":{\\\"Model A\\\":91.97}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "MG6F9-CCTPP-1@9@9-139-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Card Fraud Classification",
        "id": 140,
        "narration": "The algorithm employed to solve this artificial intelligence problem got an accuracy of 99.94%, with a precision and recall of 81.19% and 83.67% respectively, leading to an F1-score of 82.41%. Despite achieving a really high accuracy, the model scored lower on the precision and recall. However, given the extremely large dataset imbalance, with only 0.17% of examples belonging to class 2, the F1-score of 82.41% can be considered as very good, with the model yielding reliable results.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":82.41},\\\"Precision\\\":{\\\"Model A\\\":81.19},\\\"Accuracy\\\":{\\\"Model A\\\":99.94}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
        "redeem_code": "T470Q-NQ6VT-RURM9_140-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Company Bankruptcy Prediction",
        "id": 141,
        "narration": "The classification algorithm reached an accuracy of 98.54% with an AUC of 100%, while achieving a specificity of 100.0% and sensitivity of 96.5%. The model boasts a perfect score on specificity, while having a slightly lower sensitivity. This means that the model occasionally predicts false negatives, but never false positives. Overall, it performs very well.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":100.0},\\\"Accuracy\\\":{\\\"Model A\\\":98.54},\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"Sensitivity\\\":{\\\"Model A\\\":96.5}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
        "redeem_code": "KE5DC-MAW4E-YWFQ2_141-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"AUC\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Specificity, Sensitivity and AUC </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Specificity, Sensitivity and AUC. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 142,
        "narration": "The following were the achieved evaluation metric scores: 96.0%, 98.59%, 97.33%, 94.8% for accuracy, AUC, recall and precision respectively. The model performs very well across all the metrics, leading to balanced and very accurate predictions.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":98.59},\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Recall\\\":{\\\"Model A\\\":97.33},\\\"Precision\\\":{\\\"Model A\\\":94.8}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "BFYYW-JBVA9-7FX89_142-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Cab Surge Pricing System",
        "id": 143,
        "narration": "Our method produced an accuracy of 82.24%, precision of 87.11%, recall of 85.82% and an F1-score of 86.46%. The model performs well in general. It achieves a similar accuracy and F1-score, which shows that its predictions are not biased to any of the three classes despite the mild class imbalance.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.46},\\\"Recall\\\":{\\\"Model A\\\":85.82},\\\"Accuracy\\\":{\\\"Model A\\\":82.24},\\\"Precision\\\":{\\\"Model A\\\":87.11}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2</b> and <b>C3</b></p>43.1% of the data belongs to class C1, 36.2% belonging to class C2 and 20.7% belonging to class C3",
        "redeem_code": "33RHR-0H80K-Q5XDF_143-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Recall, Accuracy and F1-score) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 82.24 and F1-score of 86.46. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "E-Commerce Shipping",
        "id": 144,
        "narration": "The machine learning algorithm employed on this classification task attained an F1-score of 68.64% and an accuracy of 62.67%, with a specificity and recall of 53.25% and 69.2% respectively. The model performs sub-optimally in general. With a similar specificity and recall, the model does not exhibit a bias, but its accuracy is simply low.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":69.2},\\\"F1-score\\\":{\\\"Model A\\\":68.64},\\\"Accuracy\\\":{\\\"Model A\\\":62.67},\\\"Specificity\\\":{\\\"Model A\\\":53.25}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
        "redeem_code": "G2AN7-F3893-FE5PC-144-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Specificity\":\"2\",\"Recall\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Specificity and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Specificity and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "E-Commerce Shipping",
        "id": 145,
        "narration": "The evaluation metrics achieved were as follows: recall: 78.18; specificity: 54.72%; F1-score: 66.78%; accuracy: 65.21%. The overall performance of the model was moderate. It exhibited a slight bias towards predicting the positive class, with a higher recall than specificity.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":65.21},\\\"Specificity\\\":{\\\"Model A\\\":54.72},\\\"F1-score\\\":{\\\"Model A\\\":66.78},\\\"Recall\\\":{\\\"Model A\\\":78.18}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
        "redeem_code": "U4MK0-@QYY6-MRXG5_145-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"4\",\"Specificity\":\"2\",\"F1-score\":\"3\",\"Accuracy\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Specificity, F1-score and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 65.21 and Recall of 78.18. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Hotel Satisfaction",
        "id": 147,
        "narration": "This model achieves recall, accuracy , auc and precision scores of 77.52%, 82.7%, 88.67% and 84.66% respectively. A high AUC of 88.67% implies that this model has a good ability to tell apart the positive and negative classes, whereas a recall of 77.52% means that of all members of the target class, this model was able to correctly identify 77.52% of them.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":84.66},\\\"Accuracy\\\":{\\\"Model A\\\":82.7},\\\"Recall\\\":{\\\"Model A\\\":77.52},\\\"AUC\\\":{\\\"Model A\\\":88.67}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 56% of the data belonging to class C1 and 44% belonging to class C2",
        "redeem_code": "WN3EW-B46L5-@7M56_147-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"3\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Accuracy, AUC and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 88.67 and Recall of 77.52. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Car Acceptability Valuation",
        "id": 148,
        "narration": "AUC: 99.42%, Accuracy: 97.11%, Recall: 95.96% and Precision: 94.06% all indicate that this model is a very strong performer Despite the class imbalance, the model is able to achieve almost perfect accuracy, precision, and recall scores. These scores mean that the model is able to very effectively identify both class C1 and C2",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":97.11},\\\"AUC\\\":{\\\"Model A\\\":99.42},\\\"Recall\\\":{\\\"Model A\\\":95.96},\\\"Precision\\\":{\\\"Model A\\\":94.06}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 70% of the data belonging to class C1 and 30% belonging to class C2",
        "redeem_code": "9N8UD-B52CT-QXDNN-148-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\",\"Precision\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Job Change of Data Scientists",
        "id": 149,
        "narration": "This model scored Precision, Accuracy, F1-score and recall of 55.23%, 75.75%, 63.19% and 51.3% respectively The scores achieved indicate that this model has almost no predictive ability. Accuracy (75.75%) is only marginally higher than the proportion of the majority class, and precision (55.23%), F1-score (53.19%) and recall (51.3%) are all only marginally better than random choice.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":53.19},\\\"Accuracy\\\":{\\\"Model A\\\":75.75},\\\"Recall\\\":{\\\"Model A\\\":51.3},\\\"Precision\\\":{\\\"Model A\\\":55.23}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.1% of the data belonging to class C1 and 24.9% belonging to class C2",
        "redeem_code": "FF36V-0HUPK-26A2Y_149-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Accuracy\":\"3\",\"F1-score\":\"1\",\"Recall\":\"1\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy, F1-score and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy, F1-score and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Employee Attrition",
        "id": 150,
        "narration": "Trained on this very imbalanced dataset, this model is able to achieve precision of 40.82%, recall of 83.33%, auc of 84.46% and accuracy of 87.11%. A high auc indicates a fair ability to tell class c1 and c2 apart, however it is more pertinent to focus on the very low precision which means that only 40.82% of the positive cases were labelled as positive. A recall of 83.33% means that of those predicted as positive, only <rec_diff> of them were actually negative.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":40.82},\\\"Recall\\\":{\\\"Model A\\\":83.33},\\\"Accuracy\\\":{\\\"Model A\\\":87.11},\\\"AUC\\\":{\\\"Model A\\\":84.46}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
        "redeem_code": "BECXA-EMA5V-AP7J7-150-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Recall\":\"4\",\"AUC\":\"4\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, AUC and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Bike Sharing Demand",
        "id": 151,
        "narration": "This model scores very highly for auc (94.5%) and highly for precision (85.56%), recall (87.03%) and accuracy (86.53%) A very high auc score indicates a very strong ability to sort out the examples under class c1 and c2 and a high precision of 85.56% means that of all the samples that were predicted as belonging to class c1, only 14.44% actually belonged to class C2",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"Accuracy\\\":{\\\"Model A\\\":86.53},\\\"AUC\\\":{\\\"Model A\\\":94.5},\\\"Precision\\\":{\\\"Model A\\\":85.56}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
        "redeem_code": "B2VL4-0PF1F-FRFH7_151-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 85.56 and AUC of 94.5. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Paris House Classification",
        "id": 152,
        "narration": "The learning algorithm obtained an accuracy of 91.56% with an F1-score of 75.49 and Recall and Precision of 83.12 and 69.15, respectively, on this classification task. The accuracy is high but the F1-score is much lower. This lower F1-score better reflects that the precision is much lower than the recall, suggesting that the model is making mistakes by giving many false positives.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":69.15},\\\"Accuracy\\\":{\\\"Model A\\\":91.56},\\\"F1-score\\\":{\\\"Model A\\\":75.49},\\\"Recall\\\":{\\\"Model A\\\":83.12}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 81.0% of the data belongs to class C1, about 19.0% belonging to class C2.",
        "redeem_code": "EV3YY-JMX87-D9D6G-152-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Recall\":\"4\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Accuracy and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "2.25.71.194",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Tic-Tac-Toe Strategy",
        "id": 153,
        "narration": "An AUC score of 99.16%, matched with an Accuracy of 96.53% were achieved by the classifier on the given ML task. Its F1-score was 94.62%, made up of a precision score of 89.8%. The very high AUC suggests that the model was able to pick out which outcome was more likely. After categorisation the performance decreases slightly with a very respectable accuracy of 96.53%, while also achieving a high accuracy and F1-score. This can be considered a reliable prediction.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Accuracy\\\":{\\\"Model A\\\":96.53},\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"F1-score\\\":{\\\"Model A\\\":94.62}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>65.3% of the data belongs to class C1 and 34.7% of the data belong to class C2",
        "redeem_code": "0V@K0-GRK51-Y9U1U-153-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"F1-score\":\"4\",\"Accuracy\":\"4\",\"AUC\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Accuracy and AUC. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Australian Credit Approval",
        "id": 154,
        "narration": "84.78%, 84.91%, 77.59% and 91.11% were the accuracy, precision, recall and AUC scores achieved by the model under consideration. A recall and precision of 77.59% and 84.91% respectively shows that the models prediction are mostly balanced without a major bias towards either category, since the values are mostly similar. The scores are not very high, however neither is the models accuracy. The predictions can therefore be considered as mostly well balanced although not completely reliable.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":77.59},\\\"Precision\\\":{\\\"Model A\\\":84.91},\\\"AUC\\\":{\\\"Model A\\\":91.11},\\\"Accuracy\\\":{\\\"Model A\\\":84.78}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balance with 55.5% of the data belonging to class C1 and 44.5% belonging to class C2",
        "redeem_code": "VFFV5-HXL4B-AL08W_154-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\",\"Recall\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Precision, AUC and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 77.59 and Precision of 84.91. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Mobile Price-Range Classification",
        "id": 155,
        "narration": "The performance of classification algorithm fore this ML task is captured by the evaluation metrics with the following values: an accuracy of 95.8%, a precision of 95.78% and recall of 95.84%. All of the evaluation metrics have remarkably similar values. This suggests that the model is very well balanced amongst the 4 classification categories. At the same time all three metrics have very high values which suggests that the model performs very well and is reliable.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Precision-score\\\":{\\\"Model A\\\":95.78},\\\"Recall-score\\\":{\\\"Model A\\\":95.84}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
        "redeem_code": "QVMLQ-TL6EL-CPXDD-155-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall-score\":\"5\",\"Precision-score\":\"5\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall-score, Precision-score and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Printer Sales",
        "id": 156,
        "narration": "An accuracy of 86.67, precision of 86.49 F2-score of 86.49 and AUC of 94.31 was achieved by the proposed model. The high and similar values across the AUC, accuracy and precision suggest that the model behaves well in general with balanced predictions across both categories, matched with inaccuracies present across both categories.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":86.49},\\\"AUC\\\":{\\\"Model A\\\":94.31},\\\"Accuracy\\\":{\\\"Model A\\\":86.67},\\\"F2-score\\\":{\\\"Model A\\\":86.49}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
        "redeem_code": "L9BUA-FNP46-R@X66-156-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"4\",\"F2-score\":\"4\",\"AUC\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC, Accuracy and Precision? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Concrete Strength Classification",
        "id": 157,
        "narration": "The evaluation metrics scores achieved by the classifier are: 96.34 for AUC, 87.74 for accuracy, 79.22 for precision, and 95.31 for recall. The very high AUC score suggests that the model performs well in general, however, the moderate precision and high recall suggest that the model has a bias towards predicting the positive class, with few false negatives but many false positives.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.22},\\\"Accuracy\\\":{\\\"Model A\\\":87.74},\\\"AUC\\\":{\\\"Model A\\\":96.34},\\\"Recall\\\":{\\\"Model A\\\":95.31}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "YN6TQ-47EPE-L3662-157-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"5\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and AUC? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 158,
        "narration": "The assessment scores achieved are: an F1-score of 86.96, precision of 89.95, accuracy of 88.89 and specificity of 92.61. The models overall performance is very good, since it achieved similarly high values for both the accuracy and F1-score despite the dataset class imbalance.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":86.96},\\\"Specificity\\\":{\\\"Model A\\\":92.61},\\\"Precision\\\":{\\\"Model A\\\":89.95},\\\"Accuracy\\\":{\\\"Model A\\\":88.89}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "@@P7D-VPY5P-BYLNM-158-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Precision\":\"4\",\"Accuracy\":\"4\",\"Specificity\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Accuracy and Specificity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 88.89 and F1-score of 86.96. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "E-Commerce Shipping",
        "id": 159,
        "narration": "In terms of correctly separating the examples under the different class labels C1 and C2, the performance of the model reached an accuracy of 67.09%, with a recall of 82.92%, a specificity of 56.02%, and an F1-score of 67.47%. Having a high recall with a low specificity implies that the model has a bias towards predicting positives, with many false positives and fewer false negatives. This unbalanced prediction is generally regarded as bad.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":67.09},\\\"Specificity\\\":{\\\"Model A\\\":56.02},\\\"Recall\\\":{\\\"Model A\\\":82.92},\\\"F1-score\\\":{\\\"Model A\\\":67.47}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>59.7% and 40.3% are the proportions of the training data belonging to class labels C1 and C2, respectively.",
        "redeem_code": "BL@53-HMVFW-V66M4_159-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"2\",\"Recall\":\"4\",\"Specificity\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Specificity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 82.92 and Specificity of 56.02. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.63",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Food Ordering Customer Churn Prediction",
        "id": 160,
        "narration": "Trained to assort the examples under the different classes, the model is highly accurate with the score of 92.31% and is reflective of the respectable AUC scoring of 93.06%, the models sensitivity however is reduced indicating the true positive rate is also lower  The overall model is highly accurate and 92.31 at determining the examples under the class label C1 however the data is skewed to having more of this in the dataset, the sensitivity however at choosing the examples who are assigned to either C1 or C2 is reduced and provides an area of improvement. The AUC suggests the model is accurately assigning the correct positive and negative values to each category upwards of 93.06% of the time which again indicates the model is good.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":76.92},\\\"Accuracy\\\":{\\\"Model A\\\":92.31},\\\"AUC\\\":{\\\"Model A\\\":93.06},\\\"Precision\\\":{\\\"Model A\\\":86.96}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 77.6% of the data belongs to class C1, about 22.4% belonging to class C2.",
        "redeem_code": "A7KAH-AAYUJ-4ANRL_160-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"4\",\"AUC\":\"5\",\"Sensitivity\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, AUC and Sensitivity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Sensitivity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Advertisement Prediction",
        "id": 161,
        "narration": "The ML model is performing very highly on the given balanced classification task, with all metrics indicating that there are no major areas of improvement. The model was trained on an exact similar proportion split between the two class labels which supports no sampling biases by the model, therefore the true values of 95.67% accuracy, precision at 94.16 and recall and 97.32 all collude an image the model is performing very well at determining differences between C1 and C2  instances/cases accurately and precisely. The AUC at 98.79% suggests an extremely high accuracy in the models predictions of class assignment and is suggestive that the model is very strong at its classification ability.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":97.32},\\\"AUC\\\":{\\\"Model A\\\":98.79},\\\"Accuracy\\\":{\\\"Model A\\\":95.67},\\\"Precision\\\":{\\\"Model A\\\":94.16}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.% of the data belonging to class C1 and 50.% belonging to class C2",
        "redeem_code": "JMLR9-VHXR2-3J88N_161-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Water Quality Classification",
        "id": 162,
        "narration": "The classification model was able to produce fairly high metrics scores within sensitivity (75.61), specificity (74.8) and accuracy (75.0) however with the reduction seen in the F1-score (60.19) suggests that the recall and precision of the model is reduced, this could be due to the slight imbalance in data for C1 rather than C2.  Accuracy of the model when it comes to correctly sorting and classifying the examples is 75.0% correct of the time which on the unbalanced datasets may possibly be reducing this value. The F1-score, which incorporates both recall and precision is the lowest metrics at 60.19% and therefore there are a significant amount of false positives within the resulting findings.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":75.61},\\\"F1-score\\\":{\\\"Model A\\\":60.19},\\\"Specificity\\\":{\\\"Model A\\\":74.8},\\\"Accuracy\\\":{\\\"Model A\\\":75.0}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
        "redeem_code": "YQ3@P-69XBT-P23NH_162-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Sensitivity\":\"4\",\"Specificity\":\"4\",\"Accuracy\":\"4\",\"F1-score\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 163,
        "narration": "All metrics are very high, with recall at 91.48 suggesting a fewer than 1 in 10 error rate, F1-score of 91.26%, a combination of both precision and recall, is of course high given those two values are high also. Finally the accuracy of the model in finding and assorting classifications correctly is also high. The model's dataset has been fairly evenly split suggesting that the resulting high result metrics observed can accurately suggest that the model is productive in classifying cases into C1 or C2. The values are suggesting that the model is consistently assorting <10% of the samples into the wrong category however, such as accuracy at 91.37%, and recall at 91.48%",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":91.06},\\\"Accuracy\\\":{\\\"Model A\\\":91.37},\\\"F1-score\\\":{\\\"Model A\\\":91.26},\\\"Recall\\\":{\\\"Model A\\\":91.48}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "HAHGR-74BFK-H33HK_163-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"F1-score\":\"5\",\"Accuracy\":\"5\",\"Precision\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Broadband Sevice Signup",
        "id": 164,
        "narration": "Despite imbalanced data, the model boasts a high accuracy of 96.58, high recall of 96.78 and a high precision of 95.72%. The fact that the model achieved very high precision and recall rates (and not just high accuracy) shows that the model performs well despite the imbalanced dataset.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":96.78},\\\"Accuracy\\\":{\\\"Model A\\\":96.58},\\\"Precision\\\":{\\\"Model A\\\":95.72}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
        "redeem_code": "@WNH9-R3JFM-9JRF2_164-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Recall, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Employee Attrition",
        "id": 165,
        "narration": "The classifier boasts a fairly high precision reporting at 89.8%, however with recall is low at 28.76 suggesting that the true proportion of actual positives were not identified correctly and therefore the model is performing poorly. The model is characterised on a <|majority_dist|> split into C1 and <|minority_dist|> into C2, and therefore may have influenced the observed result metrics such that the recall rate is significantly lower. Precision is the highest metric at 89.9% rate suggests and overall model which is successful at its given task however the given recall implying that although the model maybe identifying the majority of true positive cases which are correct, it is also choosing many cases which are not",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"Recall\\\":{\\\"Model A\\\":28.76},\\\"AUC\\\":{\\\"Model A\\\":76.92},\\\"Accuracy\\\":{\\\"Model A\\\":55.47}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
        "redeem_code": "Q0QXY-8D0UA-N0URY-165-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Precision\":\"4\",\"AUC\":\"4\",\"Recall\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Broadband Sevice Signup",
        "id": 166,
        "narration": "This model was able to score 91.75% for precision, 93.07% for accuracy and 92.97% for recall Model A is very effective at predicting both classes, despite the class imbalance. Similar precision and recall scores indicate a balanced model and a very high accuracy shows a generally very proficient model.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":92.97},\\\"Accuracy\\\":{\\\"Model A\\\":93.07},\\\"Precision\\\":{\\\"Model A\\\":91.75}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 64.8% of the data belonging to class C1 and 35.2% belonging to class C2",
        "redeem_code": "@FV8L-GTDTD-T87EC_166-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"Accuracy\":\"5\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 167,
        "narration": "The classifier on this classification problem boasts an AUC score of 74.06, precision of 35.44, sensitivity of 51.85 and accuracy of 69.2. Achieving a sensitivity (sometimes referred to as recall) score of 51.85 indicates that the model captures only correctly classifies about half of the positive labels. The low precision score of 35.44 shows that the model reports a lot of false positives.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":51.85},\\\"AUC\\\":{\\\"Model A\\\":74.06},\\\"Accuracy\\\":{\\\"Model A\\\":69.2},\\\"Precision\\\":{\\\"Model A\\\":35.44}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "NJVE7-P@KX6-F6T73_167-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"4\",\"Precision\":\"2\",\"Sensitivity\":\"3\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Precision, Sensitivity and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 51.85 and Precision of 35.44. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Annual Income Earnings",
        "id": 168,
        "narration": "This machine learning classification model achieves high accuracy and AUC of 85.86 and 90.88 respectively, but only moderate precision of 55.41 and an F1-score of 64.15. The high accuracy and AUC values alone would indicate that the model performs well, however when the precision and F1-score are also considered we can conclude that the model does not perform as well due to the class imbalance - the moderate precision value highlights that the model is likely incorrectly classifying some C1 samples as C2 samples.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":90.88},\\\"Accuracy\\\":{\\\"Model A\\\":85.86},\\\"F1-score\\\":{\\\"Model A\\\":64.15},\\\"Precision\\\":{\\\"Model A\\\":55.41}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.9% of the data belonging to class C1 and 24.1% belonging to class C2",
        "redeem_code": "M4LWM-1807V-JPCU7_168-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Precision\":\"3\",\"F1-score\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, AUC, Precision and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, AUC, Precision and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Water Quality Classification",
        "id": 169,
        "narration": "Sensitivity, accuracy, f1 and specificity scores of 48.39%, 61.28%, 41.48% and 66.38% respectively imply a poorly performing model. An F1-score of 41.38% is a good indicator of a very ineffective model. Accuracy and specificity scores of 61.28% and 66.38% should not be misinterpreted and are only as high as they are because of the class imbalance.",
        "metrics_values": "\"{\\\"Specificity\\\":{\\\"Model A\\\":66.38},\\\"Sensitivity\\\":{\\\"Model A\\\":48.39},\\\"F1-score\\\":{\\\"Model A\\\":41.48},\\\"Accuracy\\\":{\\\"Model A\\\":61.28}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat imbalance with 61.0% of the data belongs to class C1, 39.0% belonging to class C2.",
        "redeem_code": "4KDQP-Y10KK-43A6X-169-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Sensitivity\":\"1\",\"Accuracy\":\"2\",\"F1-score\":\"1\",\"Specificity\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Sensitivity, Accuracy, F1-score and Specificity. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Printer Sales",
        "id": 170,
        "narration": "The given machine learning (ML) model was able to produce with moderate precision and accuracy scores (i.e. 72.97% and 81.39%, respectively), and with the given F2-score of 83.85 incorporating the absent recall metric however suggests that it too is high with the highest metric being AUC implying that  overall  the model is only incorrectly assigning its prediction for a small number of test cases.  The model is marginally skewed to having more records within C1 at <|majority_dist|> to <|minority_dist|> split, however with such minor differences it is unlikely to have impacted the metrics consequently. The precision of the model at 72.97 is likely reflecting on the flaws within the model and therefore the reduction seen in F2-score (scoring at 83.85%), however despite this, the AUC is at 91.07 overally is suggesting that the model is accurately predicting the correct positive classification assortment at a greater than 90% effectiveness.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":72.97},\\\"Accuracy\\\":{\\\"Model A\\\":81.33},\\\"AUC\\\":{\\\"Model A\\\":91.07},\\\"F2-score\\\":{\\\"Model A\\\":83.85}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somewhat balanced with 54.8% of the data belonging to class C1 and 45.2% belonging to class C2",
        "redeem_code": "CDHDT-W607X-HTBX7-170-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"4\",\"AUC\":\"5\",\"Accuracy\":\"4\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F2-score, AUC, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F2-score, AUC, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Ethereum Fraud Detection",
        "id": 171,
        "narration": "The classifier recorded very high performance scores across all metrics, with an accuracy of 98.17, precision of 93.21, AUC of 99.34 and recall of 98.56. All four metrics (accuracy, precision, recall and AUC) show extremely high performance - from this we can conclude that the model can accurately classify the majority of the samples as either class C1 or C2.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":98.17},\\\"Recall\\\":{\\\"Model A\\\":98.56},\\\"AUC\\\":{\\\"Model A\\\":99.34},\\\"Precision\\\":{\\\"Model A\\\":93.21}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 77.16% of the data belonging to class C1 and 22.14% belonging to class C2",
        "redeem_code": "0@40W-F@1KD-KAFWQ_171-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"5\",\"Precision\":\"5\",\"AUC\":\"5\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Accuracy, Precision, AUC and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Accuracy, Precision, AUC and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Bike Sharing Demand",
        "id": 172,
        "narration": "The classification performance level of the model is summed up by the scores across the precision, recall, AUC and accuracy metrics. When trained to separate the observations belonging to the different class labels, it achieves a very high AUC of 94.5, whilst also achieving high values for accuracy, recall and precision with values of 86.53, 87.03 and 85.56 respectively. The model achieves an AUC of 94.5, showing that the separation of the model's class predictions is high. Coupled with a recall of 87.03, which shows that the model must have a relatively low number of false negatives, we can conclude that the model performs well (although there is a little room for improvement considering this dataset is perfectly balanced).",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":85.56},\\\"Recall\\\":{\\\"Model A\\\":87.03},\\\"AUC\\\":{\\\"Model A\\\":94.5},\\\"Accuracy\\\":{\\\"Model A\\\":86.53}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
        "redeem_code": "0FT39-A7RGT-VWLX6-172-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"AUC\":\"5\",\"Recall\":\"4\",\"Precision\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 94.5 and Recall of 87.03. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Company Bankruptcy Prediction",
        "id": 173,
        "narration": "For accuracy, this classification model scored 71.52%, specificity 94.96%, sensitivity 59.06% and auc 84.98%. With such a high specificity and a low sensitivity, this means that the model is very effective at correctly picking out class C1 test observations but at a cost of only being correct with 59.06% of the time when labelling part of C2",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.52},\\\"Specificity\\\":{\\\"Model A\\\":94.96},\\\"Sensitivity\\\":{\\\"Model A\\\":59.06},\\\"AUC\\\":{\\\"Model A\\\":84.98}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
        "redeem_code": "K5JJP-77CTC-B0Q8V-173-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Specificity\":\"5\",\"Sensitivity\":\"2\",\"AUC\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Specificity, Sensitivity and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Specificity of 94.96 and Sensitivity of 59.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Student Job Placement",
        "id": 174,
        "narration": "The highest metric of 96.53 AUC suggests that the model is predicting the correct class label with fewer prediction error, this is coupled with high precision (92.59%), accuracy (88.37%) and recall (89.29) suggesting an overall strong and effective model. With such high precision and accuracy metrics we can infer that the model is correctly annotating records and assorting them into the correct classification as presented 96.53% AUC rate. The model is fairly productive at singling out these cases with precision of 92.59 and accuracy at 88.37 suggesting that the model is picking out these observations correctly and with the 89.29% recall rate of actual positives into the correct categories this is further verified.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.53},\\\"Recall\\\":{\\\"Model A\\\":89.29},\\\"Accuracy\\\":{\\\"Model A\\\":88.37},\\\"Precision\\\":{\\\"Model A\\\":92.59}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "JJR1M-EVD0F-JN84U-174-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"5\",\"AUC\":\"5\",\"Accuracy\":\"4\",\"Recall\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, AUC, Accuracy and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 92.59 and Accuracy of 88.37. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Card Fraud Classification",
        "id": 177,
        "narration": "The classification model achieves an extremely high accuracy of 99.94, but only high values of precision (81.19), recall (83.67) and F1-score (82.41), which is important to take into account given the highly imbalanced dataset. Due to the highly imbalanced dataset, the accuracy of the model should largely be ignored (no matter how high it is). The precision and recall values are both fairly high (at 81.19 and 83.67 respectively), and as such the F1-score is naturally high too (as F1-score is calculated from precision and recall). Yet, due to the extremely small number of C2 samples, it is difficult to say whether the model performs well as when taking this into account the precision and recall are perhaps slightly lower than we would like or expected.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":82.41},\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"Accuracy\\\":{\\\"Model A\\\":99.94},\\\"Precision\\\":{\\\"Model A\\\":81.19}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 99.8% of the data belonging to class C1 and 0.17% belonging to class C2",
        "redeem_code": "447QX-AAQVE-C@31H_177-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Recall\":\"4\",\"Accuracy\":\"5\",\"F1-score\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Recall, Accuracy and F1-score </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Recall, Accuracy and F1-score. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "213.205.241.72",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 178,
        "narration": "Evaluations on the ML task show that model's AUC score is 75.2 indicating that it is able to determine with reasonable success the predictive ability to assort this dataset into the classifications of C1 and C2. The sensitivity score is 58.52% suggests of those classified samples, a large proportion of them are not true positives.  The model data is split in <|majority_dist|> and <|minority_dist|>  for C1 and C2 and may have influenced the reduced precision and sensitivity metrics observed here at 43.04% and 58.62% respectively. AUC at 75.2 does suggest that the model is correctly assigning true positives to the correct classification the majority of the time, however with 1 in 4 being wrongly assigned.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":43.04},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "C7QB7-N0JV6-47PN9_178-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"4\",\"Sensitivity\":\"3\",\"Precision\":\"2\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: AUC, Sensitivity, Precision and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: AUC, Sensitivity, Precision and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Airline Passenger Satisfaction",
        "id": 179,
        "narration": "The classifier or model is reporting very highly across all those reported here with recall at 93.12, AUC at 97.81, precision at 91.26 and accuracy at 93.2  The dataset is skewed moderately towards C1 rather than C2 with <|majority_dist|> assigned to C1. Despite this, the very high metrics seen especially within AUC at 97.91% suggesting a very low error rate in assigning samples into the correct classification, the precision, recall and accuracy are above 90% effectiveness and overall provides evidence that the model is good.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":93.12},\\\"AUC\\\":{\\\"Model A\\\":97.91},\\\"Accuracy\\\":{\\\"Model A\\\":93.2},\\\"Precision\\\":{\\\"Model A\\\":91.26}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is somwewhat imbalance with 56.67% of the data belonging to class C1 and 43.33% belonging to class C2",
        "redeem_code": "K4Y7T-30DB5-N8HWD-179-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"AUC\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics. </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Recall, AUC, Precision and Accuracy. (You should consider the implications of the model's score across each metric.) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.49",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 180,
        "narration": "This model scored 59.07%, 56.45%, 61.95% and 71.04% for F1-score, precision, recall and accuracy, respectively A moderate accuracy score of 71.04% is less impressive due to the class imbalance, an F1-score of 59.07% gives a more accurate picture of the model which overall is not very effective",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":71.04},\\\"Recall\\\":{\\\"Model A\\\":61.95},\\\"F1-score\\\":{\\\"Model A\\\":59.07},\\\"Precision\\\":{\\\"Model A\\\":56.45}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "KAL@Q-G43FX-AY2YW-180-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"1\",\"Precision\":\"1\",\"Recall\":\"2\",\"Accuracy\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Precision, Recall and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Accuracy of 71.04 and F1-score of 59.07. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Mobile Price-Range Classification",
        "id": 181,
        "narration": "The classifier attained an accuracy of about 95.8% with a precision of 95.78 and a Recall-score of 95.48. Based on the accuracy and recall scores, we can conclude that the model achieved a higher performance and as such can correctly predict the class labels of most test cases.",
        "metrics_values": "\"{\\\"Precision-score\\\":{\\\"Model A\\\":95.78},\\\"Accuracy\\\":{\\\"Model A\\\":95.8},\\\"Recall-score\\\":{\\\"Model A\\\":95.84}}\"",
        "deleted": false,
        "date_submitted": "20/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1, C2, C3</b> and <b>C4</b></p>",
        "redeem_code": "6G0KN-NX1TF-K1QTF-181-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision-score\":\"4\",\"Recall-score\":\"4\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision-score, Accuracy and Recall-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "86.148.95.68",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Used Cars Price-Range Prediction",
        "id": 182,
        "narration": "The given model attains fairly high scores across the F1-score, Accuracy, Recall, and Precision evaluation metrics. For instance, the accuracy score is 79.8% and the F1-score is 77.06%. Based on these two scores (i.e. accuracy and F1-score), we can confirm that the model has higher classification performance and as such can correctly predict the class labels of close to the majority of test cases relating to all the class labels. (Note: The precision and recall scores were not considered here since the F1-score and accuracy are the most important metric to consider for this balanced dataset. However, we can draw the same conclusion about the model's performance by looking at the scores achieved for them.)",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":87.94},\\\"Accuracy\\\":{\\\"Model A\\\":79.8},\\\"Precision\\\":{\\\"Model A\\\":68.58},\\\"F1-score\\\":{\\\"Model A\\\":77.06}}\"",
        "deleted": false,
        "date_submitted": "22/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has  50.7% of the data belonging to class C1 and 49.3% belonging to class C2",
        "redeem_code": "CUETC-2LJ02-JWJ3P-182-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"4\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Recall and Precision) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 87.94 and Precision of 68.58. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Credit Risk Classification",
        "id": 183,
        "narration": "Trained on an imbalanced dataset, the model scores 64.55%, 60.4%, 72.54%, and 65.14%, respectively, across the Precision, F1-score, Specificity, and Accuracy metrics. Since the data was severely imbalanced, this model is shown to have a somewhat poor classification performance across a large number of test cases. The precision and F1-score show that the model has a moderate performance when it comes to predictions related to the examples belonging to the class labels belonging to class C2. However, looking at the accuracy score, there is little trust in the model's prediction decisions. Even, the dummy model constantly predicting label C1 for any given test case can outperform this model in terms of the accuracy and specificity scores.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":60.4},\\\"Specificity\\\":{\\\"Model A\\\":72.54},\\\"Precision\\\":{\\\"Model A\\\":64.55},\\\"Accuracy\\\":{\\\"Model A\\\":65.14}}\"",
        "deleted": false,
        "date_submitted": "22/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 80% of the data belonging to class C1 and 20% belonging to class C2",
        "redeem_code": "JAP17-X9Q05-GRHAH_183-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"3\",\"F1-score\":\"3\",\"Specificity\":\"3\",\"Accuracy\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, F1-score, Specificity and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, F1-score, Specificity and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Personal Loan Modelling",
        "id": 184,
        "narration": "On the machine learning classification problem, the model was evaluated based on the scores achieved across the evaluation metrics: F1-score, Accuracy, Precision, and Recall. As shown in the table,  the model got almost perfect classification accuracy of 92.22%, and a moderate recall/sensitivity score of 69.56%. However, it also has low f1 and precision scores of 42.86% and 30.97%, respectively. Judging by the accuracy alone, one can conclude that this model is very effective with its prediction decisions, however, we can forget about the low precision score and moderate recall. The model is shown to have a high false positive rate, implying some examples belonging to the class C1 class are being classified as C2 which is wrong. Therefore based on the above observations, the prediction output of C2 shouldn't be accepted in most cases. More analysis will be required to check if the example's label should be C1 or not. To summarize, the confidence in the model's decisions is low.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":92.22},\\\"F1-score\\\":{\\\"Model A\\\":42.86},\\\"Precision\\\":{\\\"Model A\\\":30.97},\\\"Recall\\\":{\\\"Model A\\\":69.56}}\"",
        "deleted": false,
        "date_submitted": "22/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>",
        "redeem_code": "CQRPY-J7YBY-BWWH9_184-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"5\",\"Precision\":\"2\",\"Recall\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Precision and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Precision and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "House Price Classification",
        "id": 185,
        "narration": "The classifier got the scores 85.42%, 86.28%, 87.23%, and 83.67%, based on the F1-score, accuracy, precision, and recall metrics respectively as shown in the table. We can confirm that this model is well balanced since it has very similar scores across all the metrics. This model is likely to misclassify only a few test cases hence its prediction decisions can be somewhat trusted to be true.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":87.23},\\\"Recall\\\":{\\\"Model A\\\":83.67},\\\"F1-score\\\":{\\\"Model A\\\":85.42},\\\"Accuracy\\\":{\\\"Model A\\\":86.28}}\"",
        "deleted": false,
        "date_submitted": "22/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>50.6% of the data belonging to class C1 and 49.4% belonging to class C2",
        "redeem_code": "956XH-E1ATW-PAMVM-185-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Recall\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Precision, Recall and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Basketball Players Career Length Prediction",
        "id": 186,
        "narration": "The classification model's assessment scores based on the evaluation metrics are 62.98% for accuracy, 69.36% for precision, and a recall score of 50.0%. Deriving the F1-score based on precision and recall, the model scored just about 58.11%. From the scores across all the metrics, we can confirm that the model will have moderately poor performance as it is likely to misclassify some test cases. The accuracy score of 62.98% is marginally better than the dummy model always assigning the majority class label C1 to any given test case. Finally, there is low confidence in the prediction decisions from this model.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":50.0},\\\"Accuracy\\\":{\\\"Model A\\\":62.98},\\\"F1-score\\\":{\\\"Model A\\\":58.11},\\\"Precision\\\":{\\\"Model A\\\":69.36}}\"",
        "deleted": false,
        "date_submitted": "27/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with about 62.0% of the data belongs to class C1, about 38.0% belonging to class C2.",
        "redeem_code": "XQBDH-F7NHR-UUV9C_186-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"2\",\"Precision\":\"3\",\"Recall\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e F1-score, Accuracy, Precision and Recall) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving F1-score of 58.11 and Accuracy of 62.98. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Bike Sharing Demand",
        "id": 187,
        "narration": "Trained on a balanced dataset, the model scored 96.08% (AUC), 94.72% (Recall) , 82.64% (precision) and 89.12%  as its accuracy score on the ML classification problem as shown in the table. From the accuracy score, there will times that it might misclassify some difficult test cases. However, the false positive and negative rate is very low  judging by the difference in the precision and recall scores. Overall, since the dataset used to train the model has equal proportions of examples for both class labels C1 and C2, one can conclude that this classifier will be very effective at correctly predicting the true class labels for the majority of test cases.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":96.08},\\\"Recall\\\":{\\\"Model A\\\":94.72},\\\"Precision\\\":{\\\"Model A\\\":82.64},\\\"Accuracy\\\":{\\\"Model A\\\":89.12}}\"",
        "deleted": false,
        "date_submitted": "27/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is balanced with 50.0% of the data belonging to class C1 and 50.0% belonging to class C2",
        "redeem_code": "4V4EK-7GE7G-3Y8Y2-187-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Recall\":\"5\",\"Precision\":\"4\",\"Accuracy\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: AUC and Accuracy? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Customer Churn Modelling",
        "id": 188,
        "narration": "The classifier on this ML problem achieved the  scores 81.32%, 55.66%, 64.61% and 48.88% across the following evaluation metrics: accuracy, F1-score, recall and precision, respectively. On the basis of the scores attained across the metrics under consideration, the model is shown to be less effective (than anticipated)  at detecting the test cases belonging to the minority class label C2. The confidence for predictions of C2 is very low as there seem to be many false positive prediction decisions (looking at the recall and precision scores). Based on the fact that the dataset was imbalanced, the accuracy score is of less importance here, however, judging based on this score it can be said that the model is somewhat better than the dummy classifier.  There is more room for improvement for this model.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":64.61},\\\"F1-score\\\":{\\\"Model A\\\":55.66},\\\"Accuracy\\\":{\\\"Model A\\\":81.32},\\\"Precision\\\":{\\\"Model A\\\":48.88}}\"",
        "deleted": false,
        "date_submitted": "27/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 76% of the data belonging to class C1 and 24% belonging to class C2",
        "redeem_code": "RXKE9-LH36N-LKDDX-188-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"F1-score\":\"2\",\"Recall\":\"3\",\"Precision\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Recall, Precision and F1-score? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Employee Attrition",
        "id": 189,
        "narration": "From the table shown, the model scores: accuracy of 55.47%, recall score of 28.76%, AUC score of 76.92 and a high precision score of 89.8% on the classification problem under consideration.  Interestingly, the model is shown to be biased towards predictions related to C2 class label. The confidence in predictions of C2 is high compared to that of C1. Overall, looking at the scores, we can say its performance is somehow poor as it might fail to correctly identify some examples from both classes especially those  related to C1.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":89.8},\\\"AUC\\\":{\\\"Model A\\\":76.92},\\\"Recall\\\":{\\\"Model A\\\":28.76},\\\"Accuracy\\\":{\\\"Model A\\\":55.47}}\"",
        "deleted": false,
        "date_submitted": "27/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 82.9% of the data belonging to class C1 and 17.1% belonging to class C2",
        "redeem_code": "CDMRJ-AQ1NH-8H1XM_189-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"3\",\"Recall\":\"1\",\"Precision\":\"4\",\"Accuracy\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e AUC, Recall, Precision and Accuracy) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Recall of 28.76 and AUC of 76.92. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 190,
        "narration": "The performance of the classifier on this classification problem as evaluated based on the metrics Precision, Sensitivity, AUC and Accuracy, respectively are: 22.78%, 54.54%, 72.19%, and 69.6%. These scores generally indicate the model has a poor classification performance, hence, will fail to correctly identify/classify the majority of test cases belonging to the different possible class labels under consideration. From precision and recall scores, we can judge that the model will have a high false positive rate.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":69.6},\\\"Precision\\\":{\\\"Model A\\\":22.78},\\\"AUC\\\":{\\\"Model A\\\":72.19},\\\"Sensitivity\\\":{\\\"Model A\\\":54.54}}\"",
        "deleted": false,
        "date_submitted": "27/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "CVMLL-AY6JB-H1VLY-190-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"1\",\"Sensitivity\":\"2\",\"AUC\":\"3\",\"Accuracy\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-4",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Sensitivity, AUC and Accuracy </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Sensitivity, AUC and Accuracy. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Vehicle Insurance Claims",
        "id": 191,
        "narration": "For this classification task, the model scores 82.46%, 85.0%, and 70.15%, respectively, on the the evaluation metrics Precision, Accuracy and Recall. The scores are pretty high indicating that it can accurately determine the class labels for several test instances. Despite the class imbalance, the model is confident about prediction outputs related to C2( the minority class label).",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":85.0},\\\"Precision\\\":{\\\"Model A\\\":82.46},\\\"Recall\\\":{\\\"Model A\\\":70.15}}\"",
        "deleted": false,
        "date_submitted": "31/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 75.3% of the data belonging to class C1 and 24.7% belonging to class C2",
        "redeem_code": "WR4KG-37BD0-RC1TY-191-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"4\",\"Accuracy\":\"4\",\"Recall\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-3",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: Precision, Accuracy and Recall </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: Precision, Accuracy and Recall. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Company Bankruptcy Prediction",
        "id": 192,
        "narration": "The performance of the classification algorithm is very impressive, achieving  scores of 99.16%, 100.0%, 89.12% and 95.08%, respectively, across the metrics AUC, specificity, sensitivity/recall and accuracy. From these scores achieved, the algorithm is shown to have a lower misclassification error and given that the specificity is at a perfect rate of 100.0%, we can be sure that it can accurately separate or classify almost all the test cases related to class label C1.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":99.16},\\\"Specificity\\\":{\\\"Model A\\\":100.0},\\\"Sensitivity\\\":{\\\"Model A\\\":89.12},\\\"Accuracy\\\":{\\\"Model A\\\":95.08}}\"",
        "deleted": false,
        "date_submitted": "31/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset for this ML problem has 58.8% of the examples belonging to class C1 and 41.2% belonging to class C2",
        "redeem_code": "L0YXQ-@C9RJ-2@UAL-192-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"AUC\":\"5\",\"Specificity\":\"5\",\"Sensitivity\":\"5\",\"Accuracy\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy and AUC? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 193,
        "narration": "The machine learning classifier or model trained on this classification problem scores 43.04%, 72.4%, 58.62% and 75.2%, respectively, on the evaluation metrics precision, accuracy, sensitivity and AUC. This model has a lower prediction performance than anticipated given its low scores for the precision and sensitivity. The accuracy  is not better than the alternative model that constantly assigns C1 to any given test instance/case. Overall, this model's output prediction decisions shouldn't be taken on the face value.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Precision\\\":{\\\"Model A\\\":43.04},\\\"Accuracy\\\":{\\\"Model A\\\":72.4}}\"",
        "deleted": false,
        "date_submitted": "31/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "RLKHJ-28UMN-VLWUW_193-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Precision\":\"2\",\"Accuracy\":\"3\",\"AUC\":\"3\",\"Sensitivity\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Precision, Accuracy, AUC and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Real Estate Investment",
        "id": 194,
        "narration": "The classification performance assessment scores achieved on this task where the test cases are categorized under the class labels C1 and C2 are 92.73%, 91.07, 97.22%, and 96.0%, respectively, based on the metrics Recall, Precision, AUC, and Accuracy. The prediction ability of the classifier can be summarized as very high considering the data disproportion between the two class labels. These scores show that only a few examples will likely be assigned the wrong class label. Furthermore, the precisions and recall/sensitivity scores are very indicative of the low false-positive rate of the model.",
        "metrics_values": "\"{\\\"Accuracy\\\":{\\\"Model A\\\":96.0},\\\"Precision\\\":{\\\"Model A\\\":91.07},\\\"Recall\\\":{\\\"Model A\\\":92.73},\\\"AUC\\\":{\\\"Model A\\\":97.22}}\"",
        "deleted": false,
        "date_submitted": "14/11/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced with 74.8% of the data belonging to class C1 and 25.2% belonging to class C2",
        "redeem_code": "8P8EX-MLVM6-7R9ET-194-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Recall\":\"5\",\"Precision\":\"5\",\"Accuracy\":\"5\",\"AUC\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Recall, Precision, Accuracy and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving AUC of 97.22 and Accuracy of 96.0. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Health Care Services Satisfaction Prediction",
        "id": 195,
        "narration": "The classifier was trained to assign test examples under one of the class labels C1 and C2. Performance assessment conducted based on the metrics accuracy, precision, and F1-score produced the scores 63.97%, 60.32%, and 60.8%.  With the dataset having an almost equal proportion of examples under each class label, these scores show that this classifier has a moderate classification performance suggesting it will likely misclassify a fair number of test cases. Irrespective of this pitfall, the performance is at an acceptable level.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":60.32},\\\"Accuracy\\\":{\\\"Model A\\\":63.97},\\\"F1-score\\\":{\\\"Model A\\\":60.8}}\"",
        "deleted": false,
        "date_submitted": "14/11/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset has 53.2% of the data belongs to class C1, 46.8% belonging to class C2.",
        "redeem_code": "AH6LX-J4826-FRTT1-195-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 2
    },
    {
        "task_name": "Employee Promotion Prediction",
        "id": 196,
        "narration": "The goal of the ML task is to assign test cases one of the class labels C1 and C2. The dataset is imbalanced implying that a large proportion of data have the label C1. As shown in the table, the classifier trained on this problem achieved scores of 95.92% as the recall, 94.15% for the predictive accuracy, and a very low precision score equal to 32.8%. On this problem, the classifier demonstrates a fair prediction performance but the precision score tells a story of a model with a false-positive rate higher than expected. This conclusion is drawn from the fact that there is a huge difference between the precision score and recall score meaning positive prediction output (i.e. when a test instance is assigned the class label C2) can't be trusted to be correct for the majority of test cases.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":95.92},\\\"Precision\\\":{\\\"Model A\\\":32.8},\\\"Accuracy\\\":{\\\"Model A\\\":94.15}}\"",
        "deleted": false,
        "date_submitted": "14/11/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 91.47% of the data belonging to class C1 and 8.53% belonging to class C2",
        "redeem_code": "3ARW4-BU73N-JH74U_196-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Precision\":\"2\",\"Recall\":\"5\"}",
        "narrator": 45,
        "model_name": "Model-2",
        "narrative_question": "<li> Provide a sentence stating the scores the model achieved across across the different evaluation metrics as shown in the table containing the metrics' scores above. </li> <li> What are the implications of the scores of the following metrics: Accuracy, Precision and Recall? </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 129,
        "narration": "The classifier was able to achieve an accuracy of 73.96%, sensitivity of 48.57% and F2-score of 51.82%. Based on the scores, we can assert that the model has a moderate prediction accuracy, however, it has a very sensitivity score with a moderately low F2-score indicating a very poor model overall. ",
        "metrics_values": "\"{\\\"F2-score\\\":{\\\"Model A\\\":51.82},\\\"Sensitivity\\\":{\\\"Model A\\\":48.57},\\\"Accuracy\\\":{\\\"Model A\\\":73.96}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
        "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"1\",\"F2-score\":\"1\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 129,
        "narration": "The ability of the machine learning model or classifier rightly label test samples as either C1 or C2 can be summarized as follows: for the prediction accuracy, the model scored 73.96% with the sensitivity equal to 48.57%; specificity score of 88.52%; precision score of 70.83% and an F1-score of 57.62%. This model has a high specificity but a low sensitivity which indicates that the model was more effective at predicting the class C1 than C2. An F1-score of 57.62% is an indicator of an overall poor model which performs especially poorly on the minority class. In summary, the model struggles to rightly identify test cases belonging to class C2 than C1.",
        "metrics_values": "\"{\\\"F1-score\\\":{\\\"Model A\\\":57.62},\\\"Precision\\\":{\\\"Model A\\\":70.83},\\\"Specificity\\\":{\\\"Model A\\\":88.52},\\\"Sensitivity\\\":{\\\"Model A\\\":48.57},\\\"Accuracy\\\":{\\\"Model A\\\":73.96}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
        "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"Sensitivity\":\"1\",\"Specificity\":\"4\",\"Precision\":\"3\",\"F1-score\":\"2\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 129,
        "narration": "The capability of the algorithm to appropriately classify test samples as C1 or C2 was analyzed based on the metrics: accuracy, sensitivity, specificity and precision. Across these metrics, the classifier scored 74.80% for specificity, 83.20% for accuracy, 91.87% for sensitivity, and 88.69% for precision. High precision and sensitivity  scores show that this model has a high F1-score implying that it is very effective in terms of predicting the positive class C2. It has  moderate accuracy and specificity scores but still boasts of a good ability to detect class C1 as well.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.69},\\\"Specificity\\\":{\\\"Model A\\\":74.80},\\\"Sensitivity\\\":{\\\"Model A\\\":91.87},\\\"Accuracy\\\":{\\\"Model A\\\":83.20}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
        "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"5\",\"Specificity\":\"3\",\"Precision\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The scores achieved by this model are 78.65%, 57.15%, 90.98%, and 66.11% for accuracy, recall, specificity, and F1-score, respectively. For this imbalanced classification task, the model has been trained to assign a class label (either C1 or C2) to any given test observation. Very high specificity and low recall show that the model is effective at predicting C1 but not very effective at all at predicting class C2. A moderate accuracy can be explained away by the <|majority_dist|> class imbalance. Overall, this model demonstrates a poor classification ability hence has a high misclassification error.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":57.15},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":66.11},\\\"Specificity\\\":{\\\"Model A\\\":90.98}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"2\",\"Accuracy\":\"3\",\"Recall\":\"2\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "In the context of the given classification problem (where the objective is assigning a class label (either C1 or C2) to any given test observation), the scores achieved by this classifier are 78.65%, 57.15%, 90.98%, and 66.11% for accuracy, recall, specificity, and F1-score, respectively. According to these scores, the model has a moderate classification performance implying that the model will fail to correctly identify a fair amount of test observations/samples. Furthermore,  low recall and very high specificity show that the classifier is very good at predicting the label C1 but not very effective (in most cases) at correctly assigning the class C2. Finally, the moderate accuracy can be explained away by the <|majority_dist|> class imbalance.",
        "metrics_values": "\"{\\\"Recall\\\":{\\\"Model A\\\":57.15},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"F1-score\\\":{\\\"Model A\\\":66.11},\\\"Specificity\\\":{\\\"Model A\\\":90.98}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"4\",\"Recall\":\"3\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 129,
        "narration": "This ML model's ability to correctly classify test samples as either C1 or C2 was evaluated based on the precision, sensitivity, specificity, and predictive accuracy. The scores achieved across the metrics are as follows: the classifier scored 83.20% for accuracy, 91.87% for sensitivity, 74.80% for specificity, and 88.69% for precision. High sensitivity and precision show that this model is very effective at predicting the positive class C2, lower but still good accuracy and specificity scores indicate a fair ability to detect class C1 also.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":88.69},\\\"Specificity\\\":{\\\"Model A\\\":74.80},\\\"Sensitivity\\\":{\\\"Model A\\\":91.87},\\\"Accuracy\\\":{\\\"Model A\\\":83.20}}\"",
        "deleted": false,
        "date_submitted": "19/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalanced belonging to class C1 (65%),  and C2 (35%)",
        "redeem_code": "VKAYD-WGMGG-H7AT5_129-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"4\",\"Sensitivity\":\"5\",\"Specificity\":\"3\",\"Precision\":\"4\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, Recall, Precision and AUC) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Precision of 88.68 and Accuracy of 84.06. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "129.234.0.56",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For this classification task, the model has been trained to label any given test observation as either C1 or C2. With respect to the classification performance, the model has scored accuracy: 76.48%, precision: 79.09%, specificity: 88.52% and F2-score: 72.26%. 76.48% of this model's predictions were correct as deduced from the accuracy. Scoring a precision of 79.09% suggests only <preci_diff> of true C1 data was misclassified as C2, but the model was also fairly good at recognizing class C2 as shown by the precision and F2-scores.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"Specificity\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "In this classification problem, the model was trained to label certain test cases as either C1 or C2. In terms of classification performance, the model's accuracy is 76.48%, has a precision score of 79.09%, the specificity is 88.52%, and the F2-score is 72.26%. 76.48% of the predictions for this model were accurate as calculated based on accuracy. A precision score of 79.09% shows that <preci_diff> of the data belonging to C1 was misclassified as C2, but the model also has a relatively good classification ability for the class C2 samples as evidenced by the  F2-score and precision score.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"Specificity\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "On the task of correctly selecting the true labels for any given set of test instances or observations, the model demonstrates a moderate to high classification prowess. Specifically, it scored an accuracy of about 76.48%, a precision score of 79.09% with the F2-score and specificity score equal to 72.26% and 88.52%, respectively. From the precision, specificity, and F2-score, the model is shown to have moderate confidence in the classification decisions across samples drawn from the two class labels. ",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.09},\\\"Accuracy\\\":{\\\"Model A\\\":76.48},\\\"F2-score\\\":{\\\"Model A\\\":72.26},\\\"Specificity\\\":{\\\"Model A\\\":88.52}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Specificity\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For accuracy, precision, AUC, and F2-score the model has scored 80.81, 79.07, 87.62, and 82.13 respectively. A precision of 79.09% implies that 79.09% of C2 predictions actually belonged to C2 (meaning the model is quite precise with its prediction decisions), a good AUC score indicates a good ability to make out the examples between positive and negative classes. An accuracy of 80.81% and an F2-score of 82.12% imply an overall fairly good model.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For precision, AUC, accuracy, and F2-score, the model scores were 79.07, 87.62, 80.81, and 82.13, respectively. 79.09% precision score means that 79.09% of C2 predictions actually were true (indicating that the model is mostly precise with its predictions). Demonstrates excellent ability to differentiate positive and negative classes as shown by the AUC score. Finally, nn accuracy of 80.81% with an F2-score of 82.12% indicate that the overall model is quite good.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"3\",\"Precision\":\"3\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The classifier has moderately high scores across the evaluation metrics accuracy, precision, F2-score, and AUC. To be specific, for accuracy,  AUC, precision, and F2-score the model has scored 80.81,  87.62, 79.07, and 82.13, respectively. A precision of 79.09% implies that 79.09% of c2 predictions actually belonged to c2, a good AUC score indicates a good ability to recognize the observations under the positive class and the negative class. An F2-score of 82.12% and accuracy of 80.81%  imply an overall moderately good model.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":79.07},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F2-score\\\":{\\\"Model A\\\":82.13},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"4\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "With the training objective of choosing the true label of any given test case or observation, the model has scored 78.65, 78.43. 90.98 and 60.43 when evaluated based on the metrics accuracy, precision, specificity, and F2-score respectively. As shown, the model has scored a very high specificity of 90.98 implying that it is very effective at setting apart the examples belonging to class C1. As for correctly making out the C2 observations, the model shows a moderate classification performance as indicated by the precision and F2-score.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For the purpose of training the classifier on the dataset to identify the true class label of any given test case or observation, the classification model scored an accuracy of 78.65, a precision score of 78.43% with the specificity score of 90.98 and 60.43 as the F2-score. A very high specificity of 90.98 implies the classifier is quite effective at picking out class C1 observations. Regarding the correct identification of C2 observations, the model exhibits moderate performance as evidenced by the precision and F2-score.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"3\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For this classification task, a given test observation or instance is assigned the label either C1 or C2. Evaluations conducted based on the metrics precision, specificity, accuracy, and F2-score show that the model is quite good at performing the classification task. Specifically, the model scored 78.65, 78.43. 90.98 and 60.43, respectively, across the accuracy, precision, specificity, and F2-score. As shown, the classifier has a very high specificity indicating that it is very confident about the C1 predictions. Finally, the model shows a moderate classification performance when picking out the C2 observations as indicated by the precision and F2-scores.",
        "metrics_values": "\"{\\\"Precision\\\":{\\\"Model A\\\":78.43},\\\"Accuracy\\\":{\\\"Model A\\\":78.65},\\\"Specificity\\\":{\\\"Model A\\\":90.98},\\\"F2-score\\\":{\\\"Model A\\\":60.43}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"3\",\"Accuracy\":\"4\",\"Precision\":\"4\",\"Specificity\":\"5\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The classification model scored 80.81% for accuracy, 82.93% for sensitivity, 87.62% for AUC and 80.95% for F1-score. The F1-score is a metric that encompasses a model's ability to detect both class C1 and C2, and this model scores a fairly high 80.95%. High scores for accuracy, sensitivity paint a similar picture. Finally, a score of 87.62 for AUC demonstrates a good ability to tell-apart the cases belonging to class C2 from those of class C1.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The scores attained by the classification model were 80.81% accuracy, 82.93% sensitivity, 87.62% AUC, and 80.95% F1-score. The F1-score is a measure that summarizes the ability of the model to correctly detect the C1 and C2 test observations, and the score for this model is quite high at 80.95%. A high level of accuracy and sensitivity show that the model is quite effective. Finally, an AUC score of 87.62 shows the excellent ability of the classifier to separate the class C2 and class C1 test cases.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "As shown, the classifier scored an accuracy of 80.81%, 87.62% for AUC with 82.93% for sensitivity, and 80.95% for F1-score. The F1-score (computed based on the precision and sensitivity scores) is fairly high and it is a metric that takes into account the model's ability to detect examples from both class labels. Besides, the high scores for accuracy, sensitivity depict a similar conclusion and a score of 87.62 for AUC shows that the model has a good ability to classify multiple observations belonging to class C2 from C1.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":82.93},\\\"Accuracy\\\":{\\\"Model A\\\":80.81},\\\"F1-score\\\":{\\\"Model A\\\":80.95},\\\"AUC\\\":{\\\"Model A\\\":87.62}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"AUC\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "As shown in the table, the scores achieved by the model are as follows: accuracy (76.8), sensitivity (83.74), precision (73.05), F1-score (78.03). An F1-score of 78.03% is a good reflection of an overall fairly good model. The sensitivity score is higher than precision which indicates that the some examples from the majority class C1 will be labeled as part of the minority class C2. However, since the difference between these two metrics is not that huge, we can conclude that this model can correctly identify the true label for a moderate number of test cases.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8},\\\"F1-score\\\":{\\\"Model A\\\":78.03},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The classifier trained on this classification task attained an accuracy score of 76.8%, a precision score of 73.05%, a sensitivity score of about 83.74%, and an F1-score of 78.03. According to these scores, this classifier demonstrates a fair understanding of the objectives of the ML problem and can accurately generate the true label for a number of test cases with a small margin of error. The difference between the sensitivity and precision scores implies some C2 predictions might be wrong but from the F1-score, we can say that for most cases it will be confident about the final prediction decision.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Accuracy\\\":{\\\"Model A\\\":76.8},\\\"F1-score\\\":{\\\"Model A\\\":78.03},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F1-score\":\"3\",\"Accuracy\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"3\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "German Credit Evaluation",
        "id": 197,
        "narration": "The classifier was trained with the objective of grouping or classifying the test examples under the class label either C1 or C2.  The scores achieved across the metrics are 72.4% (accuracy), 75.2% (AUC), 43.04% (precision) and 58.62% (recall/sensitivity). These assessment scores are lower indicating that the model has a limited understanding of the classification problem. Consequently, it will fail to correctly identify the correct class labels of most examples especially those drawn from the label C2 which happens to be the minority class.",
        "metrics_values": "\"{\\\"AUC\\\":{\\\"Model A\\\":75.2},\\\"Accuracy\\\":{\\\"Model A\\\":72.4},\\\"Sensitivity\\\":{\\\"Model A\\\":58.62},\\\"Precision\\\":{\\\"Model A\\\":43.04}}\"",
        "deleted": false,
        "date_submitted": "14/11/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset was imbalance with about 70.0% of the data belongs to class C1, about 30.0% belonging to class C2.",
        "redeem_code": "56@KH-JJA19-UHKYW-197-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Accuracy\":\"3\",\"AUC\":\"3\",\"Precision\":\"2\",\"Sensitivity\":\"3\"}",
        "narrator": 45,
        "model_name": "Model-1",
        "narrative_question": "<li> Provide a sentence stating the evaluation metrics' scores (i.e Accuracy, AUC, Precision and Sensitivity) achieved by the model under consideration. </li> <li> In two sentences, summarize the overall performance of the model capturing the implications of achieving Sensitivity of 58.62 and Accuracy of 72.4. </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "The classifier trained on the classification task has a score of 76.8% for specificity, 83.74 for sensitivity, 73.05% for precision, and 81.36 for F2-score. The F2-score is a combination of sensitivity and precision, weighting sensitivity twice as high. Overall, according to the scores, this model is shown to be more effective at avoiding false negatives than it is at avoiding false positives.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":83.74},\\\"Specificity\\\":{\\\"Model A\\\":76.8},\\\"F2-score\\\":{\\\"Model A\\\":81.36},\\\"Precision\\\":{\\\"Model A\\\":73.05}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"F2-score\":\"4\",\"Specificity\":\"3\",\"Sensitivity\":\"4\",\"Precision\":\"2\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "For specificity, sensitivity and precision scores, the model achieved 88.52%, 70.74% and 79.07%, respectively. The specificity score means that 88.52% of those predicted as being part of class label C1 were actually part of class C1. Besides, the precision and recall scores show that the model is picky with its C2 labeling decisions hence fairly confident about the C2 predictions.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":70.74},\\\"Specificity\\\":{\\\"Model A\\\":88.52},\\\"Precision\\\":{\\\"Model A\\\":79.07}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Specificity\":\"5\",\"Sensitivity\":\"3\",\"Precision\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    },
    {
        "task_name": "Pima Classification",
        "id": 63,
        "narration": "This model scored 81.11%, 79.67%, 80.33%, and 80.4% for specificity, sensitivity, precision, and accuracy respectively. Specificity, sensitivity, and precision scores are similar at around the same figure which indicates a model that performs similarly at predicting both classes at a good level. An accuracy score indicates that of all predictions, 80.4% of them were correct.",
        "metrics_values": "\"{\\\"Sensitivity\\\":{\\\"Model A\\\":79.67},\\\"Specificity\\\":{\\\"Model A\\\":81.11},\\\"Accuracy\\\":{\\\"Model A\\\":80.4},\\\"Precision\\\":{\\\"Model A\\\":80.33}}\"",
        "deleted": false,
        "date_submitted": "11/10/2021",
        "dataset_info": "<p> Class Labels: <b>C1</b> and <b>C2</b></p>The dataset is imbalance with 65% of the data belonging to class C1 and 35% belonging to class C2",
        "redeem_code": "WN5VH-GJB@5-MJU41_63-APC",
        "nb_models": 1,
        "imetric_score_rate": "{\"Specificity\":\"4\",\"Accuracy\":\"4\",\"Sensitivity\":\"4\",\"Precision\":\"4\"}",
        "model_name": "Model-2",
        "narrator": 45,
        "narrative_question": "<li> In a single sentence, provide a summary of the scores achieved by the model across the evaluation metrics: F1-score, Accuracy, Recall and Precision </li> <li> Discuss the overall performance of the model as shown by the values of the evaluation metrics: F1-score, Accuracy, Recall and Precision. (Your answer should capture the implications of achieving such scores across the different metrics .) </li>",
        "narrative_status": 1,
        "date_approved": "01-01-1970",
        "is_paid": 2,
        "user_ip": "81.100.22.24",
        "is_dataset_balanced": 1
    }     
]